
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Helper files/functions/classes for generic PySpark processes">
      
      
        <meta name="author" content="[Chris Mahoney](mailto:chris@mahoneyconsultingservices.com)">
      
      
      
        <link rel="prev" href="../schema/">
      
      
        <link rel="next" href="../utils/exceptions/">
      
      
      <link rel="icon" href="../../assets/images/spark.svg">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.49">
    
    
      
        <title>Delta - PySpark Toolbox</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.6f8fc17f.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="../../assets/stylesheets/style.css">
    
      <link rel="stylesheet" href="../../assets/stylesheets/admonitions.css">
    
      <link rel="stylesheet" href="../../assets/stylesheets/code_chunks.css">
    
      <link rel="stylesheet" href="../../assets/stylesheets/columns.css">
    
      <link rel="stylesheet" href="../../assets/stylesheets/lists.css">
    
      <link rel="stylesheet" href="https://site-assets.fontawesome.com/releases/v6.4.2/css/all.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="blue-grey" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#toolbox_pyspark.delta" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <div data-md-color-scheme="default" data-md-component="outdated" hidden>
        
          <aside class="md-banner md-banner--warning">
            <div class="md-banner__inner md-grid md-typeset">
              
  You're not viewing the latest version.
  <a href="../../..">
    <strong>Click here to go to latest.</strong>
  </a>

            </div>
            <script>var el=document.querySelector("[data-md-component=outdated]"),outdated=__md_get("__outdated",sessionStorage);!0===outdated&&el&&(el.hidden=!1)</script>
          </aside>
        
      </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="PySpark Toolbox" class="md-header__button md-logo" aria-label="PySpark Toolbox" data-md-component="logo">
      
  <img src="../../assets/images/spark.svg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            PySpark Toolbox
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Delta
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/data-science-extensions/toolbox-pyspark" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m21.94 13.11-1.05-3.22c0-.03-.01-.06-.02-.09l-2.11-6.48a.86.86 0 0 0-.8-.57c-.36 0-.68.25-.79.58l-2 6.17H8.84L6.83 3.33a.85.85 0 0 0-.79-.58c-.37 0-.69.25-.8.58L3.13 9.82v.01l-1.07 3.28c-.16.5.01 1.04.44 1.34l9.22 6.71c.17.12.39.12.56-.01l9.22-6.7c.43-.3.6-.84.44-1.34M8.15 10.45l2.57 7.91-6.17-7.91m8.73 7.92 2.47-7.59.1-.33h3.61l-5.59 7.16m4.1-13.67 1.81 5.56h-3.62m-1.3.95-1.79 5.51L12 19.24l-2.86-8.79M6.03 3.94 7.84 9.5H4.23m-1.18 4.19c-.09-.07-.13-.19-.09-.29l.79-2.43 5.82 7.45m11.38-4.73-6.51 4.73.02-.03 5.79-7.42.79 2.43c.04.1 0 .22-.09.29"/></svg>
  </div>
  <div class="md-source__repository">
    toolbox-pyspark
  </div>
</a>
      </div>
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../.." class="md-tabs__link">
        
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../usage/overview/" class="md-tabs__link">
          
  
    
  
  Usage

        </a>
      </li>
    
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../" class="md-tabs__link">
          
  
    
  
  Modules

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="PySpark Toolbox" class="md-nav__button md-logo" aria-label="PySpark Toolbox" data-md-component="logo">
      
  <img src="../../assets/images/spark.svg" alt="logo">

    </a>
    PySpark Toolbox
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/data-science-extensions/toolbox-pyspark" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m21.94 13.11-1.05-3.22c0-.03-.01-.06-.02-.09l-2.11-6.48a.86.86 0 0 0-.8-.57c-.36 0-.68.25-.79.58l-2 6.17H8.84L6.83 3.33a.85.85 0 0 0-.79-.58c-.37 0-.69.25-.8.58L3.13 9.82v.01l-1.07 3.28c-.16.5.01 1.04.44 1.34l9.22 6.71c.17.12.39.12.56-.01l9.22-6.7c.43-.3.6-.84.44-1.34M8.15 10.45l2.57 7.91-6.17-7.91m8.73 7.92 2.47-7.59.1-.33h3.61l-5.59 7.16m4.1-13.67 1.81 5.56h-3.62m-1.3.95-1.79 5.51L12 19.24l-2.86-8.79M6.03 3.94 7.84 9.5H4.23m-1.18 4.19c-.09-.07-.13-.19-.09-.29l.79-2.43 5.82 7.45m11.38-4.73-6.51 4.73.02-.03 5.79-7.42.79 2.43c.04.1 0 .22-.09.29"/></svg>
  </div>
  <div class="md-source__repository">
    toolbox-pyspark
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Usage
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Usage
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../usage/overview/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Overview
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../usage/application/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Application
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Modules
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3" id="__nav_3_label" tabindex="">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Modules
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../constants/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Constants
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../io/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    IO
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../checks/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Checks
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../types/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Types
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../keys/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Keys
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../scale/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Scale
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../dimensions/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Dimensions
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../columns/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Columns
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../datetime/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DateTime
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../cleaning/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Cleaning
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../duplication/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Duplication
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../schema/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Schema
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Delta
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Delta
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#toolbox_pyspark.delta" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;delta
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Â delta">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#toolbox_pyspark.delta.load_table" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;load_table
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toolbox_pyspark.delta.count_rows" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;count_rows
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toolbox_pyspark.delta.get_history" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;get_history
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toolbox_pyspark.delta.is_partitioned" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;is_partitioned
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toolbox_pyspark.delta.get_partition_columns" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;get_partition_columns
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toolbox_pyspark.delta.optimise_table" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;optimise_table
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toolbox_pyspark.delta.retry_optimise_table" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;retry_optimise_table
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toolbox_pyspark.delta.merge_spark_to_delta" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;merge_spark_to_delta
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toolbox_pyspark.delta.merge_delta_to_delta" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;merge_delta_to_delta
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toolbox_pyspark.delta.retry_merge_spark_to_delta" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;retry_merge_spark_to_delta
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toolbox_pyspark.delta.DeltaLoader" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;DeltaLoader
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Â DeltaLoader">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#toolbox_pyspark.delta.DeltaLoader.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;__init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toolbox_pyspark.delta.DeltaLoader.load" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;load
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toolbox_pyspark.delta.DeltaLoader.folders" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;folders
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toolbox_pyspark.delta.DeltaLoader.inspect" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;inspect
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3_15" >
        
          
          <label class="md-nav__link" for="__nav_3_15" id="__nav_3_15_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Utils
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_15_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_15">
            <span class="md-nav__icon md-icon"></span>
            Utils
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../utils/exceptions/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Exceptions
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../utils/warnings/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Warnings
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../utils/whitespaces/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Whitespaces
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#toolbox_pyspark.delta" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-module"></code>&nbsp;delta
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Â delta">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#toolbox_pyspark.delta.load_table" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;load_table
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toolbox_pyspark.delta.count_rows" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;count_rows
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toolbox_pyspark.delta.get_history" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;get_history
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toolbox_pyspark.delta.is_partitioned" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;is_partitioned
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toolbox_pyspark.delta.get_partition_columns" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;get_partition_columns
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toolbox_pyspark.delta.optimise_table" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;optimise_table
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toolbox_pyspark.delta.retry_optimise_table" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;retry_optimise_table
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toolbox_pyspark.delta.merge_spark_to_delta" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;merge_spark_to_delta
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toolbox_pyspark.delta.merge_delta_to_delta" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;merge_delta_to_delta
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toolbox_pyspark.delta.retry_merge_spark_to_delta" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;retry_merge_spark_to_delta
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toolbox_pyspark.delta.DeltaLoader" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;DeltaLoader
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Â DeltaLoader">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#toolbox_pyspark.delta.DeltaLoader.__init__" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;__init__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toolbox_pyspark.delta.DeltaLoader.load" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;load
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toolbox_pyspark.delta.DeltaLoader.folders" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;folders
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#toolbox_pyspark.delta.DeltaLoader.inspect" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;inspect
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
    <a href="https://github.com/data-science-extensions/toolbox-pyspark/edit/main/docs/code/delta.md" title="Edit this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/data-science-extensions/toolbox-pyspark/raw/main/docs/code/delta.md" title="View source of this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"/></svg>
    </a>
  


  <h1>Delta</h1>

<div class="doc doc-object doc-module">



<h3 id="toolbox_pyspark.delta" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-module"></code>            <span class="doc doc-object-name doc-module-name">toolbox_pyspark.delta</span>


<a href="#toolbox_pyspark.delta" class="headerlink" title="Permanent link">ðŸ”—</a></h3>

    <div class="doc doc-contents first">

        <div class="admonition note">
<p class="admonition-title">Summary</p>
<p>The <code>delta</code> module is for various processes related to Delta Lake tables. Including optimising tables, merging tables, retrieving table history, and transferring between locations.</p>
</div>








  <div class="doc doc-children">



























































































<div class="doc doc-object doc-function">


<h4 id="toolbox_pyspark.delta.load_table" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">load_table</span>


<a href="#toolbox_pyspark.delta.load_table" class="headerlink" title="Permanent link">ðŸ”—</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span class="nf">load_table</span><span class="p">(</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">spark_session</span><span class="p">:</span> <span class="n">SparkSession</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DeltaTable</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <div class="admonition note">
<p class="admonition-title">Summary</p>
<p>Load a <a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable"><code>DeltaTable</code></a> from a path.</p>
</div>
<details class="abstract" open="open">
<summary>Details</summary>
<p>Under the hood, this function simply calls the <a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable.forPath"><code>.forPath()</code></a> method</p>
</details>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>name</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The name of the <a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable"><code>DeltaTable</code></a>.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>path</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The path where the <a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable"><code>DeltaTable</code></a> is found.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>spark_session</code>
            </td>
            <td>
                  <code><span title="pyspark.sql.SparkSession">SparkSession</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The SparkSession to use for loading the <a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable"><code>DeltaTable</code></a>.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code>TypeError</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If any of the inputs parsed to the parameters of this function are not the correct type. Uses the <a href="https://typeguard.readthedocs.io/en/stable/api.html#typeguard.typechecked"><code>@typeguard.typechecked</code></a> decorator.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="delta.tables.DeltaTable">DeltaTable</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The loaded <a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable"><code>DeltaTable</code></a>.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>
        <details class="tip">
<summary>See also</summary>
<ul>
<li>[<code>DeltaTable</code>](<a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable">https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable</a></li>
<li><a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable.forPath"><code>DeltaTable.forPath()</code></a></li>
</ul>
</details>

            <details class="quote">
              <summary>Source code in <code>src/toolbox_pyspark/delta.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@typechecked</span>
<span class="k">def</span> <span class="nf">load_table</span><span class="p">(</span>
    <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">spark_session</span><span class="p">:</span> <span class="n">SparkSession</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DeltaTable</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    !!! note &quot;Summary&quot;</span>
<span class="sd">        Load a [`DeltaTable`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable) from a path.</span>

<span class="sd">    ???+ abstract &quot;Details&quot;</span>
<span class="sd">        Under the hood, this function simply calls the [`.forPath()`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable.forPath) method</span>

<span class="sd">    Params:</span>
<span class="sd">        name (str):</span>
<span class="sd">            The name of the [`DeltaTable`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable).</span>
<span class="sd">        path (str):</span>
<span class="sd">            The path where the [`DeltaTable`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable) is found.</span>
<span class="sd">        spark_session (SparkSession):</span>
<span class="sd">            The SparkSession to use for loading the [`DeltaTable`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable).</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError:</span>
<span class="sd">            If any of the inputs parsed to the parameters of this function are not the correct type. Uses the [`@typeguard.typechecked`](https://typeguard.readthedocs.io/en/stable/api.html#typeguard.typechecked) decorator.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (DeltaTable):</span>
<span class="sd">            The loaded [`DeltaTable`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable).</span>

<span class="sd">    ??? tip &quot;See also&quot;</span>
<span class="sd">        - [`DeltaTable`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable</span>
<span class="sd">        - [`DeltaTable.forPath()`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable.forPath)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">DeltaTable</span><span class="o">.</span><span class="n">forPath</span><span class="p">(</span>
        <span class="n">sparkSession</span><span class="o">=</span><span class="n">spark_session</span><span class="p">,</span>
        <span class="n">path</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">path</span><span class="si">}{</span><span class="s1">&#39;/&#39;</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">path</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">&#39;/&#39;</span><span class="p">)</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="s1">&#39;&#39;</span><span class="si">}{</span><span class="n">name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>






<div class="doc doc-object doc-function">


<h4 id="toolbox_pyspark.delta.count_rows" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">count_rows</span>


<a href="#toolbox_pyspark.delta.count_rows" class="headerlink" title="Permanent link">ðŸ”—</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span class="nf">count_rows</span><span class="p">(</span>
    <span class="n">table</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">DeltaTable</span><span class="p">],</span>
    <span class="n">path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">spark_session</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">SparkSession</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <div class="admonition note">
<p class="admonition-title">Summary</p>
<p>Count the number of rows on a given <a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable"><code>DeltaTable</code></a>.</p>
</div>
<details class="abstract" open="open">
<summary>Details</summary>
<p>Under the hood, this function will convert the <a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable"><code>DeltaTable</code></a> to a Spark <a href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.html"><code>DataFrame</code></a> to then execute the <a href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.count.html"><code>.count()</code></a> method.</p>
</details>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>table</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[str, <span title="delta.tables.DeltaTable">DeltaTable</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The table to check.<br>
If it is a <a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable"><code>DeltaTable</code></a>, then it will immediately use that.<br>
If it is a <code class="highlight"><span class="nb">str</span></code>, then it will use that as the name of the table from where to load the <a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable"><code>DeltaTable</code></a> from.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>path</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[str]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If <code>table</code> is a <code class="highlight"><span class="nb">str</span></code>, then <code>path</code> is mandatory, and is used as the <code>path</code> location for where to find the <a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable"><code>DeltaTable</code></a> to load from.<br>
Defaults to <code class="highlight"><span class="kc">None</span></code>.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>spark_session</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="pyspark.sql.SparkSession">SparkSession</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If <code>table</code> is <code class="highlight"><span class="nb">str</span></code>, then <code>spark_session</code> is mandatory. This is the <a href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.SparkSession.html"><code>SparkSession</code></a> to use for loading the <a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable"><code>DeltaTable</code></a>.<br>
Defaults to <code class="highlight"><span class="kc">None</span></code>.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code>TypeError</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If any of the inputs parsed to the parameters of this function are not the correct type. Uses the <a href="https://typeguard.readthedocs.io/en/stable/api.html#typeguard.typechecked"><code>@typeguard.typechecked</code></a> decorator.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code>AssertionError</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If <code>table</code> is a <code>str</code>, then <code>path</code> and <code>spark_session</code> cannot be <code>None</code>.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The number of rows on <code>table</code>.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>
        <details class="tip">
<summary>See also</summary>
<ul>
<li><a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable"><code>DeltaTable</code></a></li>
<li><a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable.toDF"><code>DeltaTable.toDF()</code></a></li>
<li><a href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.count.html"><code>pyspark.sql.DataFrame.count()</code></a></li>
</ul>
</details>

            <details class="quote">
              <summary>Source code in <code>src/toolbox_pyspark/delta.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@typechecked</span>
<span class="k">def</span> <span class="nf">count_rows</span><span class="p">(</span>
    <span class="n">table</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">DeltaTable</span><span class="p">],</span>
    <span class="n">path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">spark_session</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">SparkSession</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    !!! note &quot;Summary&quot;</span>
<span class="sd">        Count the number of rows on a given [`DeltaTable`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable).</span>

<span class="sd">    ???+ abstract &quot;Details&quot;</span>
<span class="sd">        Under the hood, this function will convert the [`DeltaTable`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable) to a Spark [`DataFrame`](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.html) to then execute the [`.count()`](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.count.html) method.</span>

<span class="sd">    Params:</span>
<span class="sd">        table (Union[str, DeltaTable]):</span>
<span class="sd">            The table to check.&lt;br&gt;</span>
<span class="sd">            If it is a [`DeltaTable`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable), then it will immediately use that.&lt;br&gt;</span>
<span class="sd">            If it is a `#!py str`, then it will use that as the name of the table from where to load the [`DeltaTable`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable) from.</span>
<span class="sd">        path (Optional[str], optional):</span>
<span class="sd">            If `table` is a `#!py str`, then `path` is mandatory, and is used as the `path` location for where to find the [`DeltaTable`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable) to load from.&lt;br&gt;</span>
<span class="sd">            Defaults to `#!py None`.</span>
<span class="sd">        spark_session (Optional[SparkSession], optional):</span>
<span class="sd">            If `table` is `#!py str`, then `spark_session` is mandatory. This is the [`SparkSession`](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.SparkSession.html) to use for loading the [`DeltaTable`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable).&lt;br&gt;</span>
<span class="sd">            Defaults to `#!py None`.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError:</span>
<span class="sd">            If any of the inputs parsed to the parameters of this function are not the correct type. Uses the [`@typeguard.typechecked`](https://typeguard.readthedocs.io/en/stable/api.html#typeguard.typechecked) decorator.</span>
<span class="sd">        AssertionError:</span>
<span class="sd">            If `table` is a `str`, then `path` and `spark_session` cannot be `None`.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (int):</span>
<span class="sd">            The number of rows on `table`.</span>

<span class="sd">    ??? tip &quot;See also&quot;</span>
<span class="sd">        - [`DeltaTable`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable)</span>
<span class="sd">        - [`DeltaTable.toDF()`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable.toDF)</span>
<span class="sd">        - [`pyspark.sql.DataFrame.count()`](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.count.html)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">is_type</span><span class="p">(</span><span class="n">table</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="k">assert</span> <span class="n">path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;If `table` is a `str`, then `path` cannot be `None`.&quot;</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="n">spark_session</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="p">),</span> <span class="s2">&quot;If `table` is a `str`, then `spark_session` cannot be `None`.&quot;</span>
        <span class="n">table</span> <span class="o">=</span> <span class="n">load_table</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">table</span><span class="p">,</span> <span class="n">path</span><span class="o">=</span><span class="n">path</span><span class="p">,</span> <span class="n">spark_session</span><span class="o">=</span><span class="n">spark_session</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">table</span><span class="o">.</span><span class="n">toDF</span><span class="p">()</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>






<div class="doc doc-object doc-function">


<h4 id="toolbox_pyspark.delta.get_history" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">get_history</span>


<a href="#toolbox_pyspark.delta.get_history" class="headerlink" title="Permanent link">ðŸ”—</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span class="nf">get_history</span><span class="p">(</span>
    <span class="n">table</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">DeltaTable</span><span class="p">],</span>
    <span class="n">path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">spark_session</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">SparkSession</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">psDataFrame</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <div class="admonition note">
<p class="admonition-title">Summary</p>
<p>Retrieve the transaction history for a given <a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable"><code>DeltaTable</code></a>.</p>
</div>
<details class="abstract" open="open">
<summary>Details</summary>
<p>Under the hood, this function will simply call the <a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable.history"><code>.history()</code></a> method.</p>
</details>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>table</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[str, <span title="delta.tables.DeltaTable">DeltaTable</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The table to check.<br>
If it is a <a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable"><code>DeltaTable</code></a>, then it will immediately use that.<br>
If it is a <code class="highlight"><span class="nb">str</span></code>, then it will use that as the name of the table from where to load the <a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable"><code>DeltaTable</code></a> from.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>path</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[str]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If <code>table</code> is a <code class="highlight"><span class="nb">str</span></code>, then <code>path</code> is mandatory, and is used as the <code>path</code> location for where to find the <a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable"><code>DeltaTable</code></a> to load from.<br>
Defaults to <code class="highlight"><span class="kc">None</span></code>.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>spark_session</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="pyspark.sql.SparkSession">SparkSession</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If <code>table</code> is <code class="highlight"><span class="nb">str</span></code>, then <code>spark_session</code> is mandatory. This is the <a href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.SparkSession.html"><code>SparkSession</code></a> to use for loading the <a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable"><code>DeltaTable</code></a>.<br>
Defaults to <code class="highlight"><span class="kc">None</span></code>.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code>TypeError</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If any of the inputs parsed to the parameters of this function are not the correct type. Uses the <a href="https://typeguard.readthedocs.io/en/stable/api.html#typeguard.typechecked"><code>@typeguard.typechecked</code></a> decorator.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code>AssertionError</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If <code>table</code> is a <code>str</code>, then <code>path</code> and <code>spark_session</code> cannot be <code>None</code>.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="pyspark.sql.DataFrame">DataFrame</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The transaction history for a given <a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable"><code>DeltaTable</code></a>.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>
        <details class="tip">
<summary>See also</summary>
<ul>
<li><a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable"><code>DeltaTable</code></a></li>
<li><a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable.history"><code>DeltaTable.history()</code></a></li>
</ul>
</details>

            <details class="quote">
              <summary>Source code in <code>src/toolbox_pyspark/delta.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@typechecked</span>
<span class="k">def</span> <span class="nf">get_history</span><span class="p">(</span>
    <span class="n">table</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">DeltaTable</span><span class="p">],</span>
    <span class="n">path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">spark_session</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">SparkSession</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">psDataFrame</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    !!! note &quot;Summary&quot;</span>
<span class="sd">        Retrieve the transaction history for a given [`DeltaTable`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable).</span>

<span class="sd">    ???+ abstract &quot;Details&quot;</span>
<span class="sd">        Under the hood, this function will simply call the [`.history()`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable.history) method.</span>

<span class="sd">    Params:</span>
<span class="sd">        table (Union[str, DeltaTable]):</span>
<span class="sd">            The table to check.&lt;br&gt;</span>
<span class="sd">            If it is a [`DeltaTable`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable), then it will immediately use that.&lt;br&gt;</span>
<span class="sd">            If it is a `#!py str`, then it will use that as the name of the table from where to load the [`DeltaTable`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable) from.</span>
<span class="sd">        path (Optional[str], optional):</span>
<span class="sd">            If `table` is a `#!py str`, then `path` is mandatory, and is used as the `path` location for where to find the [`DeltaTable`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable) to load from.&lt;br&gt;</span>
<span class="sd">            Defaults to `#!py None`.</span>
<span class="sd">        spark_session (Optional[SparkSession], optional):</span>
<span class="sd">            If `table` is `#!py str`, then `spark_session` is mandatory. This is the [`SparkSession`](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.SparkSession.html) to use for loading the [`DeltaTable`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable).&lt;br&gt;</span>
<span class="sd">            Defaults to `#!py None`.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError:</span>
<span class="sd">            If any of the inputs parsed to the parameters of this function are not the correct type. Uses the [`@typeguard.typechecked`](https://typeguard.readthedocs.io/en/stable/api.html#typeguard.typechecked) decorator.</span>
<span class="sd">        AssertionError:</span>
<span class="sd">            If `table` is a `str`, then `path` and `spark_session` cannot be `None`.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (psDataFrame):</span>
<span class="sd">            The transaction history for a given [`DeltaTable`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable).</span>

<span class="sd">    ??? tip &quot;See also&quot;</span>
<span class="sd">        - [`DeltaTable`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable)</span>
<span class="sd">        - [`DeltaTable.history()`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable.history)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">is_type</span><span class="p">(</span><span class="n">table</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="k">assert</span> <span class="n">path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;If `table` is a `str`, then `path` cannot be `None`.&quot;</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="n">spark_session</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="p">),</span> <span class="s2">&quot;If `table` is a `str`, then `spark_session` cannot be `None`.&quot;</span>
        <span class="n">table</span> <span class="o">=</span> <span class="n">load_table</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">table</span><span class="p">,</span> <span class="n">path</span><span class="o">=</span><span class="n">path</span><span class="p">,</span> <span class="n">spark_session</span><span class="o">=</span><span class="n">spark_session</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">table</span><span class="o">.</span><span class="n">history</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>






<div class="doc doc-object doc-function">


<h4 id="toolbox_pyspark.delta.is_partitioned" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">is_partitioned</span>


<a href="#toolbox_pyspark.delta.is_partitioned" class="headerlink" title="Permanent link">ðŸ”—</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span class="nf">is_partitioned</span><span class="p">(</span>
    <span class="n">table</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">DeltaTable</span><span class="p">],</span>
    <span class="n">path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">spark_session</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">SparkSession</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <div class="admonition note">
<p class="admonition-title">Summary</p>
<p>Check whether a given <a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable"><code>DeltaTable</code></a> is partitioned.</p>
</div>
<details class="abstract" open="open">
<summary>Details</summary>
<p>Under the hood, this function will retrieve the table details and check the <code>partitionColumns</code> attribute to determine if the table is partitioned.</p>
</details>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>table</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[str, <span title="delta.tables.DeltaTable">DeltaTable</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The table to check.<br>
If it is a <a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable"><code>DeltaTable</code></a>, then it will immediately use that.<br>
If it is a <code class="highlight"><span class="nb">str</span></code>, then it will use that as the name of the table from where to load the <a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable"><code>DeltaTable</code></a> from.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>path</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[str]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If <code>table</code> is a <code class="highlight"><span class="nb">str</span></code>, then <code>path</code> is mandatory, and is used as the <code>path</code> location for where to find the <a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable"><code>DeltaTable</code></a> to load from.<br>
Defaults to <code class="highlight"><span class="kc">None</span></code>.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>spark_session</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="pyspark.sql.SparkSession">SparkSession</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If <code>table</code> is <code class="highlight"><span class="nb">str</span></code>, then <code>spark_session</code> is mandatory. This is the <a href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.SparkSession.html"><code>SparkSession</code></a> to use for loading the <a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable"><code>DeltaTable</code></a>.<br>
Defaults to <code class="highlight"><span class="kc">None</span></code>.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code>TypeError</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If any of the inputs parsed to the parameters of this function are not the correct type. Uses the <a href="https://typeguard.readthedocs.io/en/stable/api.html#typeguard.typechecked"><code>@typeguard.typechecked</code></a> decorator.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code>AssertionError</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If <code>table</code> is a <code>str</code>, then <code>path</code> and <code>spark_session</code> cannot be <code>None</code>.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code>bool</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p><code class="highlight"><span class="kc">True</span></code> if the table is partitioned, <code class="highlight"><span class="kc">False</span></code> otherwise.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>
        <details class="tip">
<summary>See also</summary>
<ul>
<li><a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable"><code>DeltaTable</code></a></li>
<li><a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable.detail"><code>DeltaTable.detail()</code></a></li>
</ul>
</details>

            <details class="quote">
              <summary>Source code in <code>src/toolbox_pyspark/delta.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@typechecked</span>
<span class="k">def</span> <span class="nf">is_partitioned</span><span class="p">(</span>
    <span class="n">table</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">DeltaTable</span><span class="p">],</span>
    <span class="n">path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">spark_session</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">SparkSession</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    !!! note &quot;Summary&quot;</span>
<span class="sd">        Check whether a given [`DeltaTable`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable) is partitioned.</span>

<span class="sd">    ???+ abstract &quot;Details&quot;</span>
<span class="sd">        Under the hood, this function will retrieve the table details and check the `partitionColumns` attribute to determine if the table is partitioned.</span>

<span class="sd">    Params:</span>
<span class="sd">        table (Union[str, DeltaTable]):</span>
<span class="sd">            The table to check.&lt;br&gt;</span>
<span class="sd">            If it is a [`DeltaTable`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable), then it will immediately use that.&lt;br&gt;</span>
<span class="sd">            If it is a `#!py str`, then it will use that as the name of the table from where to load the [`DeltaTable`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable) from.</span>
<span class="sd">        path (Optional[str], optional):</span>
<span class="sd">            If `table` is a `#!py str`, then `path` is mandatory, and is used as the `path` location for where to find the [`DeltaTable`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable) to load from.&lt;br&gt;</span>
<span class="sd">            Defaults to `#!py None`.</span>
<span class="sd">        spark_session (Optional[SparkSession], optional):</span>
<span class="sd">            If `table` is `#!py str`, then `spark_session` is mandatory. This is the [`SparkSession`](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.SparkSession.html) to use for loading the [`DeltaTable`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable).&lt;br&gt;</span>
<span class="sd">            Defaults to `#!py None`.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError:</span>
<span class="sd">            If any of the inputs parsed to the parameters of this function are not the correct type. Uses the [`@typeguard.typechecked`](https://typeguard.readthedocs.io/en/stable/api.html#typeguard.typechecked) decorator.</span>
<span class="sd">        AssertionError:</span>
<span class="sd">            If `table` is a `str`, then `path` and `spark_session` cannot be `None`.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (bool):</span>
<span class="sd">            `#!py True` if the table is partitioned, `#!py False` otherwise.</span>

<span class="sd">    ??? tip &quot;See also&quot;</span>
<span class="sd">        - [`DeltaTable`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable)</span>
<span class="sd">        - [`DeltaTable.detail()`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable.detail)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">is_type</span><span class="p">(</span><span class="n">table</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="k">assert</span> <span class="n">path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;If `table` is a `str`, then `path` cannot be `None`.&quot;</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="n">spark_session</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="p">),</span> <span class="s2">&quot;If `table` is a `str`, then `spark_session` cannot be `None`.&quot;</span>
        <span class="n">table</span> <span class="o">=</span> <span class="n">load_table</span><span class="p">(</span>
            <span class="n">name</span><span class="o">=</span><span class="n">table</span><span class="p">,</span>
            <span class="n">path</span><span class="o">=</span><span class="n">path</span><span class="p">,</span>
            <span class="n">spark_session</span><span class="o">=</span><span class="n">spark_session</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="n">table</span><span class="o">.</span><span class="n">detail</span><span class="p">()</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;partitionColumns&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">collect</span><span class="p">()[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span> <span class="o">&gt;</span> <span class="mi">0</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>






<div class="doc doc-object doc-function">


<h4 id="toolbox_pyspark.delta.get_partition_columns" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">get_partition_columns</span>


<a href="#toolbox_pyspark.delta.get_partition_columns" class="headerlink" title="Permanent link">ðŸ”—</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span class="nf">get_partition_columns</span><span class="p">(</span>
    <span class="n">table</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">DeltaTable</span><span class="p">],</span>
    <span class="n">path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">spark_session</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">SparkSession</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">str_list</span><span class="p">]</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <div class="admonition note">
<p class="admonition-title">Summary</p>
<p>Retrieve the partition columns for a given <a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable"><code>DeltaTable</code></a>.</p>
</div>
<details class="abstract" open="open">
<summary>Details</summary>
<p>Under the hood, this function will retrieve the table details and return the <code>partitionColumns</code> attribute if the table is partitioned.</p>
</details>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>table</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[str, <span title="delta.tables.DeltaTable">DeltaTable</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The table to check.<br>
If it is a <a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable"><code>DeltaTable</code></a>, then it will immediately use that.<br>
If it is a <code class="highlight"><span class="nb">str</span></code>, then it will use that as the name of the table from where to load the <a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable"><code>DeltaTable</code></a> from.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>path</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[str]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If <code>table</code> is a <code class="highlight"><span class="nb">str</span></code>, then <code>path</code> is mandatory, and is used as the <code>path</code> location for where to find the <a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable"><code>DeltaTable</code></a> to load from.<br>
Defaults to <code class="highlight"><span class="kc">None</span></code>.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>spark_session</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="pyspark.sql.SparkSession">SparkSession</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If <code>table</code> is <code class="highlight"><span class="nb">str</span></code>, then <code>spark_session</code> is mandatory. This is the <a href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.SparkSession.html"><code>SparkSession</code></a> to use for loading the <a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable"><code>DeltaTable</code></a>.<br>
Defaults to <code class="highlight"><span class="kc">None</span></code>.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code>TypeError</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If any of the inputs parsed to the parameters of this function are not the correct type. Uses the <a href="https://typeguard.readthedocs.io/en/stable/api.html#typeguard.typechecked"><code>@typeguard.typechecked</code></a> decorator.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code>AssertionError</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If <code>table</code> is a <code>str</code>, then <code>path</code> and <code>spark_session</code> cannot be <code>None</code>.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="toolbox_python.collection_types.str_list">str_list</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The list of partition columns if the table is partitioned, <code class="highlight"><span class="kc">None</span></code> otherwise.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>
        <details class="tip">
<summary>See also</summary>
<ul>
<li><a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable"><code>DeltaTable</code></a></li>
<li><a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable.detail"><code>DeltaTable.detail()</code></a></li>
</ul>
</details>

            <details class="quote">
              <summary>Source code in <code>src/toolbox_pyspark/delta.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@typechecked</span>
<span class="k">def</span> <span class="nf">get_partition_columns</span><span class="p">(</span>
    <span class="n">table</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">DeltaTable</span><span class="p">],</span>
    <span class="n">path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">spark_session</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">SparkSession</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">str_list</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    !!! note &quot;Summary&quot;</span>
<span class="sd">        Retrieve the partition columns for a given [`DeltaTable`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable).</span>

<span class="sd">    ???+ abstract &quot;Details&quot;</span>
<span class="sd">        Under the hood, this function will retrieve the table details and return the `partitionColumns` attribute if the table is partitioned.</span>

<span class="sd">    Params:</span>
<span class="sd">        table (Union[str, DeltaTable]):</span>
<span class="sd">            The table to check.&lt;br&gt;</span>
<span class="sd">            If it is a [`DeltaTable`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable), then it will immediately use that.&lt;br&gt;</span>
<span class="sd">            If it is a `#!py str`, then it will use that as the name of the table from where to load the [`DeltaTable`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable) from.</span>
<span class="sd">        path (Optional[str], optional):</span>
<span class="sd">            If `table` is a `#!py str`, then `path` is mandatory, and is used as the `path` location for where to find the [`DeltaTable`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable) to load from.&lt;br&gt;</span>
<span class="sd">            Defaults to `#!py None`.</span>
<span class="sd">        spark_session (Optional[SparkSession], optional):</span>
<span class="sd">            If `table` is `#!py str`, then `spark_session` is mandatory. This is the [`SparkSession`](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.SparkSession.html) to use for loading the [`DeltaTable`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable).&lt;br&gt;</span>
<span class="sd">            Defaults to `#!py None`.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError:</span>
<span class="sd">            If any of the inputs parsed to the parameters of this function are not the correct type. Uses the [`@typeguard.typechecked`](https://typeguard.readthedocs.io/en/stable/api.html#typeguard.typechecked) decorator.</span>
<span class="sd">        AssertionError:</span>
<span class="sd">            If `table` is a `str`, then `path` and `spark_session` cannot be `None`.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (Optional[str_list]):</span>
<span class="sd">            The list of partition columns if the table is partitioned, `#!py None` otherwise.</span>

<span class="sd">    ??? tip &quot;See also&quot;</span>
<span class="sd">        - [`DeltaTable`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable)</span>
<span class="sd">        - [`DeltaTable.detail()`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable.detail)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">is_type</span><span class="p">(</span><span class="n">table</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="k">assert</span> <span class="n">path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;If `table` is a `str`, then `path` cannot be `None`.&quot;</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="n">spark_session</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="p">),</span> <span class="s2">&quot;If `table` is a `str`, then `spark_session` cannot be `None`.&quot;</span>
        <span class="n">table</span> <span class="o">=</span> <span class="n">load_table</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">table</span><span class="p">,</span> <span class="n">path</span><span class="o">=</span><span class="n">path</span><span class="p">,</span> <span class="n">spark_session</span><span class="o">=</span><span class="n">spark_session</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">is_partitioned</span><span class="p">(</span><span class="n">table</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">table</span><span class="o">.</span><span class="n">detail</span><span class="p">()</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;partitionColumns&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">collect</span><span class="p">()[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">None</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>














<div class="doc doc-object doc-function">


<h4 id="toolbox_pyspark.delta.optimise_table" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">optimise_table</span>


<a href="#toolbox_pyspark.delta.optimise_table" class="headerlink" title="Permanent link">ðŸ”—</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span class="nf">optimise_table</span><span class="p">(</span>
    <span class="n">table_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">table_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">spark_session</span><span class="p">:</span> <span class="n">SparkSession</span><span class="p">,</span>
    <span class="n">partition_cols</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">str_collection</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">inspect</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">return_result</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">method</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;api&quot;</span><span class="p">,</span> <span class="s2">&quot;sql&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;api&quot;</span><span class="p">,</span>
    <span class="n">conditional_where_clause</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">psDataFrame</span><span class="p">]</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <div class="admonition note">
<p class="admonition-title">Summary</p>
<p>Run the <code>OPTIMIZE</code> command over a <a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable"><code>DeltaTable</code></a> table to ensure that it is structurally efficient.</p>
</div>
<details class="abstract" open="open">
<summary>Details</summary>
<p>There are fundamentally two different ways in which this optimisation process can be achieved: by SQL or by API. Under the hood, both of these two methods will be implemented the same way, over the <a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable"><code>DeltaTable</code></a> object, however the syntactic method to execute the optimisation allows for flexibility through either a Python API method or a SQL method.</p>
</details>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>table_name</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The name of the table to be optimised. Must be a valid <code>delta</code> table, and must exist in the <code>write_path</code> location.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>table_path</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The location for where the <code>delta</code> table is located.<br></p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>spark_session</code>
            </td>
            <td>
                  <code><span title="pyspark.sql.SparkSession">SparkSession</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The SparkSession to use for loading the table.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>partition_cols</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="typing.Union">Union</span>[str, List[str]]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The columns to be partitioned/clustered by.</p>
<ul>
<li>If type <code class="highlight"><span class="nb">list</span></code>, then these elements will be added to the <code class="highlight"><span class="n">OPTIMIZE</span><span class="w"> </span><span class="n">delta</span><span class="p">.</span><span class="o">`</span><span class="err">{</span><span class="n">table_path</span><span class="err">}</span><span class="o">/</span><span class="err">{</span><span class="k">table_name</span><span class="err">}</span><span class="o">`</span></code> command, like this: <code class="highlight"><span class="n">OPTIMIZE</span><span class="w"> </span><span class="n">delta</span><span class="p">.</span><span class="o">`</span><span class="err">{</span><span class="n">table_path</span><span class="err">}</span><span class="o">/</span><span class="err">{</span><span class="k">table_name</span><span class="err">}</span><span class="o">`</span><span class="w"> </span><span class="n">ZORDER</span><span class="w"> </span><span class="k">BY</span><span class="w"> </span><span class="p">(</span><span class="n">col1</span><span class="p">,</span><span class="w"> </span><span class="n">col2</span><span class="p">)</span></code>.</li>
<li>If type <code class="highlight"><span class="nb">str</span></code>, then will be coerced to list of 1 elements long, like: <code>[partition_cols]</code>, then appended to the command, like: <code class="highlight"><span class="n">OPTIMIZE</span><span class="w"> </span><span class="n">delta</span><span class="p">.</span><span class="o">`</span><span class="err">{</span><span class="n">table_path</span><span class="err">}</span><span class="o">/</span><span class="err">{</span><span class="k">table_name</span><span class="err">}</span><span class="o">`</span><span class="w"> </span><span class="n">ZORDER</span><span class="w"> </span><span class="k">BY</span><span class="w"> </span><span class="p">(</span><span class="n">col1</span><span class="p">)</span></code>.</li>
<li>If <code class="highlight"><span class="kc">None</span></code>, then nothing will be added to the <code class="highlight"><span class="n">OPTIMIZE</span><span class="w"> </span><span class="n">delta</span><span class="p">.</span><span class="o">`</span><span class="err">{</span><span class="n">table_path</span><span class="err">}</span><span class="o">/</span><span class="err">{</span><span class="k">table_name</span><span class="err">}</span><span class="o">`</span></code> command.</li>
</ul>
<p>Default: <code class="highlight"><span class="kc">None</span></code>.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>inspect</code>
            </td>
            <td>
                  <code>bool</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>For debugging.
If <code class="highlight"><span class="kc">True</span></code>, then the <code>OPTIMIZE</code> command will be printed to the terminal.<br>
Default: <code class="highlight"><span class="kc">False</span></code>.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>return_result</code>
            </td>
            <td>
                  <code>bool</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>For efficient handling of elements.
If <code class="highlight"><span class="kc">True</span></code>, then the table created by the <code>OPTIMIZE</code> command will be returned from the function.
Noting that this table will give the statistics of what/how the <code>delta</code> table is optimised.<br>
Default: <code class="highlight"><span class="kc">True</span></code>.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>method</code>
            </td>
            <td>
                  <code><span title="typing.Literal">Literal</span>[&#39;api&#39;, &#39;sql&#39;]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The method to use for the execution, either by <code>api</code> or <code>sql</code>.<br>
Using <code>api</code> is preferred.<br>
Default: <code class="highlight"><span class="s2">&quot;api&quot;</span></code>.</p>
              </div>
            </td>
            <td>
                  <code>&#39;api&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>conditional_where_clause</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[str]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>An optional conditional parameter to add to the command.<br>
Any records matching this condition will be optimised; those not matching will not be optimised.<br>
This is particularly useful for partitioned tables when you don't want to use ZORDER optimisation, or when you have huge tables.<br>
Default: <code class="highlight"><span class="kc">None</span></code>.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code>TypeError</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If any of the inputs parsed to the parameters of this function are not the correct type. Uses the <a href="https://typeguard.readthedocs.io/en/stable/api.html#typeguard.typechecked"><code>@typeguard.typechecked</code></a> decorator.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="pyspark.sql.DataFrame">DataFrame</span>, None]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Either <code class="highlight"><span class="kc">None</span></code> or the statistics/details from the optimised delta table.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>
        <details class="info" open="open">
<summary>Notes</summary>
<details class="info" open="open">
<summary>Important notes</summary>
<ul>
<li>For <code>partition_cols</code>:<ul>
<li>If it is type <code class="highlight"><span class="nb">list</span></code>, then the <code class="highlight"><span class="n">OPTIMIZE</span><span class="w"> </span><span class="n">delta</span><span class="p">.</span><span class="o">`</span><span class="err">{</span><span class="n">table_path</span><span class="err">}</span><span class="o">/</span><span class="err">{</span><span class="k">table_name</span><span class="err">}</span><span class="o">`</span></code> command will be extended to include each element in the <code>partition_cols</code> <code class="highlight"><span class="nb">list</span></code>. Like this: <code class="highlight"><span class="n">OPTIMIZE</span><span class="w"> </span><span class="n">delta</span><span class="p">.</span><span class="o">`</span><span class="err">{</span><span class="n">table_path</span><span class="err">}</span><span class="o">/</span><span class="err">{</span><span class="k">table_name</span><span class="err">}</span><span class="o">`</span><span class="w"> </span><span class="n">ZORDER</span><span class="w"> </span><span class="k">BY</span><span class="w"> </span><span class="p">(</span><span class="n">col1</span><span class="p">,</span><span class="w"> </span><span class="n">col2</span><span class="p">)</span></code>.</li>
<li>If <code>partition_cols</code> is a type <code class="highlight"><span class="nb">str</span></code>, then it will be coerced to a list of 1 elements, and then appended like mentioned above.</li>
<li>If <code>partition_cols</code> is <code class="highlight"><span class="kc">None</span></code>, then nothing will be added to the <code class="highlight"><span class="n">OPTIMIZE</span><span class="w"> </span><span class="n">delta</span><span class="p">.</span><span class="o">`</span><span class="err">{</span><span class="n">table_path</span><span class="err">}</span><span class="o">/</span><span class="err">{</span><span class="k">table_name</span><span class="err">}</span><span class="o">`</span></code> command.</li>
</ul>
</li>
<li>For <code>conditional_where_clause</code>:<ul>
<li>It must be a <code class="highlight"><span class="nb">str</span></code>.</li>
<li>It must be in the format: <code class="highlight"><span class="err">{</span><span class="k">column</span><span class="err">}</span><span class="w"> </span><span class="err">{</span><span class="n">conditional</span><span class="err">}</span><span class="w"> </span><span class="err">{</span><span class="n">value</span><span class="err">}</span></code>.</li>
<li>For example: <code class="highlight"><span class="n">editdatetime</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="s1">&#39;2023-09-01&#39;</span></code></li>
<li>This will then be coerced in to the format: <code class="highlight"><span class="k">WHERE</span><span class="w"> </span><span class="err">{</span><span class="k">where</span><span class="err">}</span></code>.</li>
<li>And then appended to the overall SQL command like this: <code class="highlight"><span class="n">OPTIMIZE</span><span class="w"> </span><span class="n">delta</span><span class="p">.</span><span class="o">`</span><span class="err">{</span><span class="n">table_path</span><span class="err">}</span><span class="o">/</span><span class="err">{</span><span class="k">table_name</span><span class="err">}</span><span class="o">`</span><span class="w"> </span><span class="k">WHERE</span><span class="w"> </span><span class="err">{</span><span class="k">where</span><span class="err">}</span></code>.</li>
</ul>
</li>
</ul>
</details>
<details class="info" open="open">
<summary>The <code>sql</code> process</summary>
<p>When <code class="highlight"><span class="n">method</span><span class="o">==</span><span class="s2">&quot;sql&quot;</span></code> then this process will:</p>
<ol>
<li>Take the table given by the param <code>table_name</code>.</li>
<li>Build the SQL command using the values in the parameters <code>partition_cols</code> and <code>conditional_where_clause</code>.</li>
<li>Will execute the <code class="highlight"><span class="n">OPTIMIZE</span><span class="w"> </span><span class="n">delta</span><span class="p">.</span><span class="o">`</span><span class="err">{</span><span class="n">table_path</span><span class="err">}</span><span class="o">/</span><span class="err">{</span><span class="k">table_name</span><span class="err">}</span><span class="o">`</span><span class="w"> </span><span class="k">WHERE</span><span class="w"> </span><span class="err">{</span><span class="k">where</span><span class="err">}</span><span class="w"> </span><span class="n">ZORDER</span><span class="w"> </span><span class="k">BY</span><span class="w"> </span><span class="err">{</span><span class="n">zorder</span><span class="err">}</span></code> command over the new table.</li>
<li>Optionally return the results.</li>
</ol>
</details>
<details class="info" open="open">
<summary>The <code>api</code> process</summary>
<p>When <code class="highlight"><span class="n">method</span><span class="o">==</span><span class="s2">&quot;api&quot;</span></code> then this process will:</p>
<ol>
<li>Take the table given by the param <code>table_name</code>.</li>
<li>Build the partition columns when the <code>partition_cols</code> is not <code class="highlight"><span class="kc">None</span></code>.</li>
<li>Load the <a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaOptimizeBuilder"><code>DeltaOptimizeBuilder</code></a> by using the syntax: <code class="highlight"><span class="n">table</span> <span class="o">=</span> <span class="n">DeltaTable</span><span class="o">.</span><span class="n">forPath</span><span class="p">(</span><span class="n">spark_session</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">table_path</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">table_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">optimize</span><span class="p">()</span></code>.</li>
<li>Optionally add a where clause using the <a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaOptimizeBuilder.where"><code>.where</code></a> when <code>conditional_where_clause</code> is not <code class="highlight"><span class="kc">None</span></code>.</li>
<li>Conditionally execute <a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaOptimizeBuilder.executeZOrderBy"><code>.executeZOrderBy</code></a> when <code>partition_cols</code> is not <code class="highlight"><span class="kc">None</span></code>, or <a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaOptimizeBuilder.executeCompaction"><code>.executeCompaction</code></a> otherwise.</li>
</ol>
</details>
</details>
<details class="question">
<summary>References</summary>
<p>For more information, please see:</p>
<ul>
<li><a href="https://docs.azuredatabricks.net/_static/notebooks/delta/optimize-python.html">https://docs.azuredatabricks.net/_static/notebooks/delta/optimize-python.html</a></li>
<li><a href="https://medium.com/@debusinha2009/cheatsheet-on-understanding-zorder-and-optimize-for-your-delta-tables-1556282221d3">https://medium.com/@debusinha2009/cheatsheet-on-understanding-zorder-and-optimize-for-your-delta-tables-1556282221d3</a></li>
<li><a href="https://www.cloudiqtech.com/partition-optimize-and-zorder-delta-tables-in-azure-databricks/">https://www.cloudiqtech.com/partition-optimize-and-zorder-delta-tables-in-azure-databricks/</a></li>
<li><a href="https://docs.databricks.com/delta/optimizations/file-mgmt.html">https://docs.databricks.com/delta/optimizations/file-mgmt.html</a></li>
<li><a href="https://docs.databricks.com/spark/latest/spark-sql/language-manual/delta-optimize.html">https://docs.databricks.com/spark/latest/spark-sql/language-manual/delta-optimize.html</a></li>
<li><a href="https://stackoverflow.com/questions/65320949/parquet-vs-delta-format-in-azure-data-lake-gen-2-store?_sm_au_=iVV4WjsV0q7WQktrJfsTkK7RqJB10">https://stackoverflow.com/questions/65320949/parquet-vs-delta-format-in-azure-data-lake-gen-2-store?_sm_au_=iVV4WjsV0q7WQktrJfsTkK7RqJB10</a></li>
<li><a href="https://www.i-programmer.info/news/197-data-mining/12582-databricks-delta-adds-faster-parquet-import.html#:~:text=Databricks%20says%20Delta%20is%2010,data%20management%2C%20and%20query%20serving">https://www.i-programmer.info/news/197-data-mining/12582-databricks-delta-adds-faster-parquet-import.html#:~:text=Databricks%20says%20Delta%20is%2010,data%20management%2C%20and%20query%20serving</a>.</li>
</ul>
</details>
<details class="tip">
<summary>See also</summary>
<ul>
<li><a href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.SparkSession.html"><code>SparkSession</code></a></li>
<li><a href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.SparkSession.sql.html"><code>SparkSession.sql()</code></a></li>
<li><a href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.html">pyspark.sql.DataFrame</a></li>
<li><a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable"><code>DeltaTable</code></a></li>
<li><a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable.forPath"><code>DeltaTable.forPath()</code></a></li>
<li><a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable.optimize"><code>DeltaTable.optimize()</code></a></li>
<li><a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable.executeZOrderBy"><code>DeltaTable.executeZOrderBy()</code></a></li>
<li><a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable.executeCompaction"><code>DeltaTable.executeCompaction()</code></a></li>
</ul>
</details>

            <details class="quote">
              <summary>Source code in <code>src/toolbox_pyspark/delta.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@typechecked</span>
<span class="k">def</span> <span class="nf">optimise_table</span><span class="p">(</span>
    <span class="n">table_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">table_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">spark_session</span><span class="p">:</span> <span class="n">SparkSession</span><span class="p">,</span>
    <span class="n">partition_cols</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">str_collection</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">inspect</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">return_result</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">method</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;api&quot;</span><span class="p">,</span> <span class="s2">&quot;sql&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;api&quot;</span><span class="p">,</span>
    <span class="n">conditional_where_clause</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">psDataFrame</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    !!! note &quot;Summary&quot;</span>
<span class="sd">        Run the `OPTIMIZE` command over a [`DeltaTable`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable) table to ensure that it is structurally efficient.</span>

<span class="sd">    ???+ abstract &quot;Details&quot;</span>
<span class="sd">        There are fundamentally two different ways in which this optimisation process can be achieved: by SQL or by API. Under the hood, both of these two methods will be implemented the same way, over the [`DeltaTable`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable) object, however the syntactic method to execute the optimisation allows for flexibility through either a Python API method or a SQL method.</span>

<span class="sd">    Params:</span>
<span class="sd">        table_name (str):</span>
<span class="sd">            The name of the table to be optimised. Must be a valid `delta` table, and must exist in the `write_path` location.</span>
<span class="sd">        table_path (str):</span>
<span class="sd">            The location for where the `delta` table is located.&lt;br&gt;</span>
<span class="sd">        spark_session (SparkSession):</span>
<span class="sd">            The SparkSession to use for loading the table.</span>
<span class="sd">        partition_cols (Optional[Union[str, List[str]]], optional):</span>
<span class="sd">            The columns to be partitioned/clustered by.</span>

<span class="sd">            - If type `#!py list`, then these elements will be added to the ``#!sql OPTIMIZE delta.`{table_path}/{table_name}` `` command, like this: ``#!sql OPTIMIZE delta.`{table_path}/{table_name}` ZORDER BY (col1, col2)``.</span>
<span class="sd">            - If type `#!py str`, then will be coerced to list of 1 elements long, like: `[partition_cols]`, then appended to the command, like: ``#!sql OPTIMIZE delta.`{table_path}/{table_name}` ZORDER BY (col1)``.</span>
<span class="sd">            - If `#!py None`, then nothing will be added to the ``#!sql OPTIMIZE delta.`{table_path}/{table_name}` `` command.</span>

<span class="sd">            Default: `#!py None`.</span>
<span class="sd">        inspect (bool, optional):</span>
<span class="sd">            For debugging.</span>
<span class="sd">            If `#!py True`, then the `OPTIMIZE` command will be printed to the terminal.&lt;br&gt;</span>
<span class="sd">            Default: `#!py False`.</span>
<span class="sd">        return_result (bool, optional):</span>
<span class="sd">            For efficient handling of elements.</span>
<span class="sd">            If `#!py True`, then the table created by the `OPTIMIZE` command will be returned from the function.</span>
<span class="sd">            Noting that this table will give the statistics of what/how the `delta` table is optimised.&lt;br&gt;</span>
<span class="sd">            Default: `#!py True`.</span>
<span class="sd">        method (Literal[&quot;api&quot;, &quot;sql&quot;], optional):</span>
<span class="sd">            The method to use for the execution, either by `api` or `sql`.&lt;br&gt;</span>
<span class="sd">            Using `api` is preferred.&lt;br&gt;</span>
<span class="sd">            Default: `#!py &quot;api&quot;`.</span>
<span class="sd">        conditional_where_clause (Optional[str], optional):</span>
<span class="sd">            An optional conditional parameter to add to the command.&lt;br&gt;</span>
<span class="sd">            Any records matching this condition will be optimised; those not matching will not be optimised.&lt;br&gt;</span>
<span class="sd">            This is particularly useful for partitioned tables when you don&#39;t want to use ZORDER optimisation, or when you have huge tables.&lt;br&gt;</span>
<span class="sd">            Default: `#!py None`.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError:</span>
<span class="sd">            If any of the inputs parsed to the parameters of this function are not the correct type. Uses the [`@typeguard.typechecked`](https://typeguard.readthedocs.io/en/stable/api.html#typeguard.typechecked) decorator.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (Union[psDataFrame, None]):</span>
<span class="sd">            Either `#!py None` or the statistics/details from the optimised delta table.</span>

<span class="sd">    ???+ info &quot;Notes&quot;</span>
<span class="sd">        ???+ info &quot;Important notes&quot;</span>
<span class="sd">            - For `partition_cols`:</span>
<span class="sd">                - If it is type `#!py list`, then the ``#!sql OPTIMIZE delta.`{table_path}/{table_name}` `` command will be extended to include each element in the `partition_cols` `#!py list`. Like this: ``#!sql OPTIMIZE delta.`{table_path}/{table_name}` ZORDER BY (col1, col2)``.</span>
<span class="sd">                - If `partition_cols` is a type `#!py str`, then it will be coerced to a list of 1 elements, and then appended like mentioned above.</span>
<span class="sd">                - If `partition_cols` is `#!py None`, then nothing will be added to the ``#!sql OPTIMIZE delta.`{table_path}/{table_name}` `` command.</span>
<span class="sd">            - For `conditional_where_clause`:</span>
<span class="sd">                - It must be a `#!py str`.</span>
<span class="sd">                - It must be in the format: `#!sql {column} {conditional} {value}`.</span>
<span class="sd">                - For example: `#!sql editdatetime &gt;= &#39;2023-09-01&#39;`</span>
<span class="sd">                - This will then be coerced in to the format: `#!sql WHERE {where}`.</span>
<span class="sd">                - And then appended to the overall SQL command like this: ``#!sql OPTIMIZE delta.`{table_path}/{table_name}` WHERE {where}``.</span>
<span class="sd">        ???+ info &quot;The `sql` process&quot;</span>
<span class="sd">            When `#!py method==&quot;sql&quot;` then this process will:</span>

<span class="sd">            1. Take the table given by the param `table_name`.</span>
<span class="sd">            1. Build the SQL command using the values in the parameters `partition_cols` and `conditional_where_clause`.</span>
<span class="sd">            1. Will execute the ``#!sql OPTIMIZE delta.`{table_path}/{table_name}` WHERE {where} ZORDER BY {zorder}`` command over the new table.</span>
<span class="sd">            1. Optionally return the results.</span>
<span class="sd">        ???+ info &quot;The `api` process&quot;</span>
<span class="sd">            When `#!py method==&quot;api&quot;` then this process will:</span>

<span class="sd">            1. Take the table given by the param `table_name`.</span>
<span class="sd">            1. Build the partition columns when the `partition_cols` is not `#!py None`.</span>
<span class="sd">            1. Load the [`DeltaOptimizeBuilder`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaOptimizeBuilder) by using the syntax: `#!py table = DeltaTable.forPath(spark_session, f&quot;{table_path}/{table_name}&quot;).optimize()`.</span>
<span class="sd">            1. Optionally add a where clause using the [`.where`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaOptimizeBuilder.where) when `conditional_where_clause` is not `#!py None`.</span>
<span class="sd">            1. Conditionally execute [`.executeZOrderBy`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaOptimizeBuilder.executeZOrderBy) when `partition_cols` is not `#!py None`, or [`.executeCompaction`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaOptimizeBuilder.executeCompaction) otherwise.</span>

<span class="sd">    ??? question &quot;References&quot;</span>
<span class="sd">        For more information, please see:</span>

<span class="sd">        - https://docs.azuredatabricks.net/_static/notebooks/delta/optimize-python.html</span>
<span class="sd">        - https://medium.com/@debusinha2009/cheatsheet-on-understanding-zorder-and-optimize-for-your-delta-tables-1556282221d3</span>
<span class="sd">        - https://www.cloudiqtech.com/partition-optimize-and-zorder-delta-tables-in-azure-databricks/</span>
<span class="sd">        - https://docs.databricks.com/delta/optimizations/file-mgmt.html</span>
<span class="sd">        - https://docs.databricks.com/spark/latest/spark-sql/language-manual/delta-optimize.html</span>
<span class="sd">        - https://stackoverflow.com/questions/65320949/parquet-vs-delta-format-in-azure-data-lake-gen-2-store?_sm_au_=iVV4WjsV0q7WQktrJfsTkK7RqJB10</span>
<span class="sd">        - https://www.i-programmer.info/news/197-data-mining/12582-databricks-delta-adds-faster-parquet-import.html#:~:text=Databricks%20says%20Delta%20is%2010,data%20management%2C%20and%20query%20serving.</span>

<span class="sd">    ??? tip &quot;See also&quot;</span>
<span class="sd">        - [`SparkSession`](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.SparkSession.html)</span>
<span class="sd">        - [`SparkSession.sql()`](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.SparkSession.sql.html)</span>
<span class="sd">        - [pyspark.sql.DataFrame](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.html)</span>
<span class="sd">        - [`DeltaTable`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable)</span>
<span class="sd">        - [`DeltaTable.forPath()`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable.forPath)</span>
<span class="sd">        - [`DeltaTable.optimize()`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable.optimize)</span>
<span class="sd">        - [`DeltaTable.executeZOrderBy()`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable.executeZOrderBy)</span>
<span class="sd">        - [`DeltaTable.executeCompaction()`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable.executeCompaction)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;api&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">_optimise_table_api</span><span class="p">(</span>
            <span class="n">table_name</span><span class="o">=</span><span class="n">table_name</span><span class="p">,</span>
            <span class="n">table_path</span><span class="o">=</span><span class="n">table_path</span><span class="p">,</span>
            <span class="n">spark_session</span><span class="o">=</span><span class="n">spark_session</span><span class="p">,</span>
            <span class="n">partition_cols</span><span class="o">=</span><span class="n">partition_cols</span><span class="p">,</span>
            <span class="n">inspect</span><span class="o">=</span><span class="n">inspect</span><span class="p">,</span>
            <span class="n">return_result</span><span class="o">=</span><span class="n">return_result</span><span class="p">,</span>
            <span class="n">conditional_where_clause</span><span class="o">=</span><span class="n">conditional_where_clause</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">elif</span> <span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;sql&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">_optimise_table_sql</span><span class="p">(</span>
            <span class="n">table_name</span><span class="o">=</span><span class="n">table_name</span><span class="p">,</span>
            <span class="n">table_path</span><span class="o">=</span><span class="n">table_path</span><span class="p">,</span>
            <span class="n">spark_session</span><span class="o">=</span><span class="n">spark_session</span><span class="p">,</span>
            <span class="n">partition_cols</span><span class="o">=</span><span class="n">partition_cols</span><span class="p">,</span>
            <span class="n">inspect</span><span class="o">=</span><span class="n">inspect</span><span class="p">,</span>
            <span class="n">return_result</span><span class="o">=</span><span class="n">return_result</span><span class="p">,</span>
            <span class="n">conditional_where_clause</span><span class="o">=</span><span class="n">conditional_where_clause</span><span class="p">,</span>
        <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>






<div class="doc doc-object doc-function">


<h4 id="toolbox_pyspark.delta.retry_optimise_table" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">retry_optimise_table</span>


<a href="#toolbox_pyspark.delta.retry_optimise_table" class="headerlink" title="Permanent link">ðŸ”—</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span class="nf">retry_optimise_table</span><span class="p">(</span>
    <span class="n">table_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">table_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">spark_session</span><span class="p">:</span> <span class="n">SparkSession</span><span class="p">,</span>
    <span class="n">partition_cols</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">str_collection</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">inspect</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">return_result</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">method</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;api&quot;</span><span class="p">,</span> <span class="s2">&quot;sql&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;api&quot;</span><span class="p">,</span>
    <span class="n">conditional_where_clause</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">retry_exceptions</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span>
        <span class="nb">type</span><span class="p">[</span><span class="ne">Exception</span><span class="p">],</span>
        <span class="nb">list</span><span class="p">[</span><span class="n">Type</span><span class="p">[</span><span class="ne">Exception</span><span class="p">]],</span>
        <span class="nb">tuple</span><span class="p">[</span><span class="n">Type</span><span class="p">[</span><span class="ne">Exception</span><span class="p">],</span> <span class="o">...</span><span class="p">],</span>
    <span class="p">]</span> <span class="o">=</span> <span class="ne">Exception</span><span class="p">,</span>
    <span class="n">retry_attempts</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">psDataFrame</span><span class="p">]</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <div class="admonition note">
<p class="admonition-title">Summary</p>
<p>Retry the execution of <a class="autorefs autorefs-internal" href="#toolbox_pyspark.delta.optimise_table"><code>optimise_table</code></a> a number of times when a given error exception is met.</p>
</div>
<details class="abstract" open="open">
<summary>Details</summary>
<p>Particularly useful for when you are trying to run this optimisation over a cluster, and when parallelisaiton is causing multiple processes to occur over the same DeltaTable at the same time.</p>
<p>For more info on the Retry process, see: <a href="https://stamina.hynek.me/en/stable/"><code>stamina.retry()</code></a>.</p>
</details>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>table_name</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The name of the table to be optimised. Must be a valid <code>delta</code> table, and must exist in the <code>write_path</code> location.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>table_path</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The location for where the <code>delta</code> table is located.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>spark_session</code>
            </td>
            <td>
                  <code><span title="pyspark.sql.SparkSession">SparkSession</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The SparkSession to use for loading the table.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>partition_cols</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="typing.Union">Union</span>[str, List[str]]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The columns to be partitioned/clustered by.</p>
<ul>
<li>If type <code class="highlight"><span class="nb">list</span></code>, then these elements will be added to the <code class="highlight"><span class="n">OPTIMIZE</span><span class="w"> </span><span class="n">delta</span><span class="p">.</span><span class="o">`</span><span class="err">{</span><span class="n">table_path</span><span class="err">}</span><span class="o">/</span><span class="err">{</span><span class="k">table_name</span><span class="err">}</span><span class="o">`</span></code> command, like this: <code class="highlight"><span class="n">OPTIMIZE</span><span class="w"> </span><span class="n">delta</span><span class="p">.</span><span class="o">`</span><span class="err">{</span><span class="n">table_path</span><span class="err">}</span><span class="o">/</span><span class="err">{</span><span class="k">table_name</span><span class="err">}</span><span class="o">`</span><span class="w"> </span><span class="n">ZORDER</span><span class="w"> </span><span class="k">BY</span><span class="w"> </span><span class="p">(</span><span class="n">col1</span><span class="p">,</span><span class="w"> </span><span class="n">col2</span><span class="p">)</span></code>.</li>
<li>If type <code class="highlight"><span class="nb">str</span></code>, then will be coerced to list of 1 elements long, like: <code>[partition_cols]</code>, then appended to the command, like: <code class="highlight"><span class="n">OPTIMIZE</span><span class="w"> </span><span class="n">delta</span><span class="p">.</span><span class="o">`</span><span class="err">{</span><span class="n">table_path</span><span class="err">}</span><span class="o">/</span><span class="err">{</span><span class="k">table_name</span><span class="err">}</span><span class="o">`</span><span class="w"> </span><span class="n">ZORDER</span><span class="w"> </span><span class="k">BY</span><span class="w"> </span><span class="p">(</span><span class="n">col1</span><span class="p">)</span></code>.</li>
<li>If <code class="highlight"><span class="kc">None</span></code>, then nothing will be added to the <code class="highlight"><span class="n">OPTIMIZE</span><span class="w"> </span><span class="n">delta</span><span class="p">.</span><span class="o">`</span><span class="err">{</span><span class="n">table_path</span><span class="err">}</span><span class="o">/</span><span class="err">{</span><span class="k">table_name</span><span class="err">}</span><span class="o">`</span></code> command.</li>
</ul>
<p>Default: <code class="highlight"><span class="kc">None</span></code>.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>inspect</code>
            </td>
            <td>
                  <code>bool</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>For debugging.
If <code class="highlight"><span class="kc">True</span></code>, then the <code>OPTIMIZE</code> command will be printed to the terminal.<br>
Default: <code class="highlight"><span class="kc">False</span></code>.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>return_result</code>
            </td>
            <td>
                  <code>bool</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>For efficient handling of elements.
If <code class="highlight"><span class="kc">True</span></code>, then the table created by the <code>OPTIMIZE</code> command will be returned from the function.
Noting that this table will give the statistics of what/how the <code>delta</code> table is optimised.<br>
Default: <code class="highlight"><span class="kc">True</span></code>.</p>
              </div>
            </td>
            <td>
                  <code>True</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>method</code>
            </td>
            <td>
                  <code><span title="typing.Literal">Literal</span>[&#39;api&#39;, &#39;sql&#39;]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The method to use for the execution, either by <code>api</code> or <code>sql</code>.<br>
Using <code>api</code> is preferred.<br>
Default: <code class="highlight"><span class="s2">&quot;api&quot;</span></code>.</p>
              </div>
            </td>
            <td>
                  <code>&#39;api&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>conditional_where_clause</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[str]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>An optional conditional parameter to add to the command.<br>
Any records matching this condition will be optimised; those not matching will not be optimised.<br>
This is particularly useful for partitioned tables when you don't want to use ZORDER optimisation, or when you have huge tables.<br>
Default: <code class="highlight"><span class="kc">None</span></code>.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>retry_exceptions</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="typing.Type">Type</span>[Exception], List[<span title="typing.Type">Type</span>[Exception]], Tuple[<span title="typing.Type">Type</span>[Exception], ...]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A given single or collection of expected exceptions for which to catch and retry for.<br>
Defaults to <code class="highlight"><span class="ne">Exception</span></code>.</p>
              </div>
            </td>
            <td>
                  <code>Exception</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>retry_attempts</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The number of retries to attempt. If the underlying process is still failing after this number of attempts, then throw a hard error and alert the user.<br>
Defaults to <code class="highlight"><span class="mi">10</span></code>.</p>
              </div>
            </td>
            <td>
                  <code>10</code>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code>TypeError</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If any of the inputs parsed to the parameters of this function are not the correct type. Uses the <a href="https://typeguard.readthedocs.io/en/stable/api.html#typeguard.typechecked"><code>@typeguard.typechecked</code></a> decorator.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="pyspark.sql.DataFrame">DataFrame</span>, None]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Either <code class="highlight"><span class="kc">None</span></code> or the statistics/details from the optimised delta table.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>
        <details class="tip">
<summary>See also</summary>
<ul>
<li><a href="https://stamina.hynek.me/en/stable/"><code>stamina.retry()</code></a></li>
<li><a class="autorefs autorefs-internal" href="#toolbox_pyspark.delta.optimise_table"><code>optimise_table()</code></a></li>
<li><a href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.SparkSession.html"><code>SparkSession</code></a></li>
<li><a href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.SparkSession.sql.html"><code>SparkSession.sql()</code></a></li>
<li><a href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.html">pyspark.sql.DataFrame</a></li>
<li><a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable"><code>DeltaTable</code></a></li>
<li><a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable.forPath"><code>DeltaTable.forPath()</code></a></li>
<li><a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable.optimize"><code>DeltaTable.optimize()</code></a></li>
<li><a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable.executeZOrderBy"><code>DeltaTable.executeZOrderBy()</code></a></li>
<li><a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable.executeCompaction"><code>DeltaTable.executeCompaction()</code></a></li>
</ul>
</details>

            <details class="quote">
              <summary>Source code in <code>src/toolbox_pyspark/delta.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span>
<span class="normal">587</span>
<span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span>
<span class="normal">611</span>
<span class="normal">612</span>
<span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span>
<span class="normal">616</span>
<span class="normal">617</span>
<span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span>
<span class="normal">625</span>
<span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span>
<span class="normal">633</span>
<span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span>
<span class="normal">637</span>
<span class="normal">638</span>
<span class="normal">639</span>
<span class="normal">640</span>
<span class="normal">641</span>
<span class="normal">642</span>
<span class="normal">643</span>
<span class="normal">644</span>
<span class="normal">645</span>
<span class="normal">646</span>
<span class="normal">647</span>
<span class="normal">648</span>
<span class="normal">649</span>
<span class="normal">650</span>
<span class="normal">651</span>
<span class="normal">652</span>
<span class="normal">653</span>
<span class="normal">654</span>
<span class="normal">655</span>
<span class="normal">656</span>
<span class="normal">657</span>
<span class="normal">658</span>
<span class="normal">659</span>
<span class="normal">660</span>
<span class="normal">661</span>
<span class="normal">662</span>
<span class="normal">663</span>
<span class="normal">664</span>
<span class="normal">665</span>
<span class="normal">666</span>
<span class="normal">667</span>
<span class="normal">668</span>
<span class="normal">669</span>
<span class="normal">670</span>
<span class="normal">671</span>
<span class="normal">672</span>
<span class="normal">673</span>
<span class="normal">674</span>
<span class="normal">675</span>
<span class="normal">676</span>
<span class="normal">677</span>
<span class="normal">678</span>
<span class="normal">679</span>
<span class="normal">680</span>
<span class="normal">681</span>
<span class="normal">682</span>
<span class="normal">683</span>
<span class="normal">684</span>
<span class="normal">685</span>
<span class="normal">686</span>
<span class="normal">687</span>
<span class="normal">688</span>
<span class="normal">689</span>
<span class="normal">690</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@typechecked</span>
<span class="k">def</span> <span class="nf">retry_optimise_table</span><span class="p">(</span>
    <span class="n">table_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">table_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">spark_session</span><span class="p">:</span> <span class="n">SparkSession</span><span class="p">,</span>
    <span class="n">partition_cols</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">str_collection</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">inspect</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">return_result</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">method</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;api&quot;</span><span class="p">,</span> <span class="s2">&quot;sql&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;api&quot;</span><span class="p">,</span>
    <span class="n">conditional_where_clause</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">retry_exceptions</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span>
        <span class="nb">type</span><span class="p">[</span><span class="ne">Exception</span><span class="p">],</span>
        <span class="nb">list</span><span class="p">[</span><span class="n">Type</span><span class="p">[</span><span class="ne">Exception</span><span class="p">]],</span>
        <span class="nb">tuple</span><span class="p">[</span><span class="n">Type</span><span class="p">[</span><span class="ne">Exception</span><span class="p">],</span> <span class="o">...</span><span class="p">],</span>
    <span class="p">]</span> <span class="o">=</span> <span class="ne">Exception</span><span class="p">,</span>
    <span class="n">retry_attempts</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">psDataFrame</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    !!! note &quot;Summary&quot;</span>
<span class="sd">        Retry the execution of [`optimise_table`][toolbox_pyspark.delta.optimise_table] a number of times when a given error exception is met.</span>

<span class="sd">    ???+ abstract &quot;Details&quot;</span>

<span class="sd">        Particularly useful for when you are trying to run this optimisation over a cluster, and when parallelisaiton is causing multiple processes to occur over the same DeltaTable at the same time.</span>

<span class="sd">        For more info on the Retry process, see: [`stamina.retry()`](https://stamina.hynek.me/en/stable/).</span>

<span class="sd">    Params:</span>
<span class="sd">        table_name (str):</span>
<span class="sd">            The name of the table to be optimised. Must be a valid `delta` table, and must exist in the `write_path` location.</span>

<span class="sd">        table_path (str):</span>
<span class="sd">            The location for where the `delta` table is located.</span>

<span class="sd">        spark_session (SparkSession):</span>
<span class="sd">            The SparkSession to use for loading the table.</span>

<span class="sd">        partition_cols (Optional[Union[str, List[str]]], optional):</span>
<span class="sd">            The columns to be partitioned/clustered by.</span>

<span class="sd">            - If type `#!py list`, then these elements will be added to the ``#!sql OPTIMIZE delta.`{table_path}/{table_name}` `` command, like this: ``#!sql OPTIMIZE delta.`{table_path}/{table_name}` ZORDER BY (col1, col2)``.</span>
<span class="sd">            - If type `#!py str`, then will be coerced to list of 1 elements long, like: `[partition_cols]`, then appended to the command, like: ``#!sql OPTIMIZE delta.`{table_path}/{table_name}` ZORDER BY (col1)``.</span>
<span class="sd">            - If `#!py None`, then nothing will be added to the ``#!sql OPTIMIZE delta.`{table_path}/{table_name}` `` command.</span>

<span class="sd">            Default: `#!py None`.</span>

<span class="sd">        inspect (bool, optional):</span>
<span class="sd">            For debugging.</span>
<span class="sd">            If `#!py True`, then the `OPTIMIZE` command will be printed to the terminal.&lt;br&gt;</span>
<span class="sd">            Default: `#!py False`.</span>

<span class="sd">        return_result (bool, optional):</span>
<span class="sd">            For efficient handling of elements.</span>
<span class="sd">            If `#!py True`, then the table created by the `OPTIMIZE` command will be returned from the function.</span>
<span class="sd">            Noting that this table will give the statistics of what/how the `delta` table is optimised.&lt;br&gt;</span>
<span class="sd">            Default: `#!py True`.</span>

<span class="sd">        method (Literal[&quot;api&quot;, &quot;sql&quot;], optional):</span>
<span class="sd">            The method to use for the execution, either by `api` or `sql`.&lt;br&gt;</span>
<span class="sd">            Using `api` is preferred.&lt;br&gt;</span>
<span class="sd">            Default: `#!py &quot;api&quot;`.</span>

<span class="sd">        conditional_where_clause (Optional[str], optional):</span>
<span class="sd">            An optional conditional parameter to add to the command.&lt;br&gt;</span>
<span class="sd">            Any records matching this condition will be optimised; those not matching will not be optimised.&lt;br&gt;</span>
<span class="sd">            This is particularly useful for partitioned tables when you don&#39;t want to use ZORDER optimisation, or when you have huge tables.&lt;br&gt;</span>
<span class="sd">            Default: `#!py None`.</span>

<span class="sd">        retry_exceptions (Union[ Type[Exception], List[Type[Exception]], Tuple[Type[Exception], ...], ], optional):</span>
<span class="sd">            A given single or collection of expected exceptions for which to catch and retry for.&lt;br&gt;</span>
<span class="sd">            Defaults to `#!py Exception`.</span>

<span class="sd">        retry_attempts (int, optional):</span>
<span class="sd">            The number of retries to attempt. If the underlying process is still failing after this number of attempts, then throw a hard error and alert the user.&lt;br&gt;</span>
<span class="sd">            Defaults to `#!py 10`.</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError:</span>
<span class="sd">            If any of the inputs parsed to the parameters of this function are not the correct type. Uses the [`@typeguard.typechecked`](https://typeguard.readthedocs.io/en/stable/api.html#typeguard.typechecked) decorator.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (Union[psDataFrame, None]):</span>
<span class="sd">            Either `#!py None` or the statistics/details from the optimised delta table.</span>

<span class="sd">    ??? tip &quot;See also&quot;</span>
<span class="sd">        - [`stamina.retry()`](https://stamina.hynek.me/en/stable/)</span>
<span class="sd">        - [`optimise_table()`][toolbox_pyspark.delta.optimise_table]</span>
<span class="sd">        - [`SparkSession`](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.SparkSession.html)</span>
<span class="sd">        - [`SparkSession.sql()`](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.SparkSession.sql.html)</span>
<span class="sd">        - [pyspark.sql.DataFrame](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.html)</span>
<span class="sd">        - [`DeltaTable`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable)</span>
<span class="sd">        - [`DeltaTable.forPath()`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable.forPath)</span>
<span class="sd">        - [`DeltaTable.optimize()`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable.optimize)</span>
<span class="sd">        - [`DeltaTable.executeZOrderBy()`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable.executeZOrderBy)</span>
<span class="sd">        - [`DeltaTable.executeCompaction()`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable.executeCompaction)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@retry</span><span class="p">(</span>
        <span class="n">on</span><span class="o">=</span><span class="p">((</span><span class="o">*</span><span class="n">retry_exceptions</span><span class="p">,)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">retry_exceptions</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="k">else</span> <span class="n">retry_exceptions</span><span class="p">),</span>
        <span class="n">attempts</span><span class="o">=</span><span class="n">retry_attempts</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="nd">@typechecked</span>
    <span class="k">def</span> <span class="nf">_retry_optimise_table</span><span class="p">(</span>
        <span class="n">table_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">table_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">spark_session</span><span class="p">:</span> <span class="n">SparkSession</span><span class="p">,</span>
        <span class="n">partition_cols</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">str_collection</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">inspect</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">return_result</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">method</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;api&quot;</span><span class="p">,</span> <span class="s2">&quot;sql&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;api&quot;</span><span class="p">,</span>
        <span class="n">conditional_where_clause</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Optional</span><span class="p">[</span><span class="n">psDataFrame</span><span class="p">]:</span>
        <span class="k">return</span> <span class="n">optimise_table</span><span class="p">(</span>
            <span class="n">table_name</span><span class="o">=</span><span class="n">table_name</span><span class="p">,</span>
            <span class="n">table_path</span><span class="o">=</span><span class="n">table_path</span><span class="p">,</span>
            <span class="n">spark_session</span><span class="o">=</span><span class="n">spark_session</span><span class="p">,</span>
            <span class="n">partition_cols</span><span class="o">=</span><span class="n">partition_cols</span><span class="p">,</span>
            <span class="n">inspect</span><span class="o">=</span><span class="n">inspect</span><span class="p">,</span>
            <span class="n">return_result</span><span class="o">=</span><span class="n">return_result</span><span class="p">,</span>
            <span class="n">method</span><span class="o">=</span><span class="n">method</span><span class="p">,</span>
            <span class="n">conditional_where_clause</span><span class="o">=</span><span class="n">conditional_where_clause</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">return</span> <span class="n">_retry_optimise_table</span><span class="p">(</span>
        <span class="n">table_name</span><span class="o">=</span><span class="n">table_name</span><span class="p">,</span>
        <span class="n">table_path</span><span class="o">=</span><span class="n">table_path</span><span class="p">,</span>
        <span class="n">spark_session</span><span class="o">=</span><span class="n">spark_session</span><span class="p">,</span>
        <span class="n">partition_cols</span><span class="o">=</span><span class="n">partition_cols</span><span class="p">,</span>
        <span class="n">inspect</span><span class="o">=</span><span class="n">inspect</span><span class="p">,</span>
        <span class="n">return_result</span><span class="o">=</span><span class="n">return_result</span><span class="p">,</span>
        <span class="n">method</span><span class="o">=</span><span class="n">method</span><span class="p">,</span>
        <span class="n">conditional_where_clause</span><span class="o">=</span><span class="n">conditional_where_clause</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>






<div class="doc doc-object doc-function">


<h4 id="toolbox_pyspark.delta.merge_spark_to_delta" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">merge_spark_to_delta</span>


<a href="#toolbox_pyspark.delta.merge_spark_to_delta" class="headerlink" title="Permanent link">ðŸ”—</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span class="nf">merge_spark_to_delta</span><span class="p">(</span>
    <span class="n">from_table</span><span class="p">:</span> <span class="n">psDataFrame</span><span class="p">,</span>
    <span class="n">to_table_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">to_table_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">matching_keys</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">str_collection</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">from_keys</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">str_collection</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">to_keys</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">str_collection</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">partition_keys</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">str_dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">editdate_col_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;editdate&quot;</span><span class="p">,</span>
    <span class="n">delete_unmatched_rows</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">enable_automatic_schema_evolution</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span>
        <span class="nb">bool</span>
    <span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">return_merge_metrics</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">bool</span><span class="p">,</span> <span class="n">psDataFrame</span><span class="p">]</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <div class="admonition note">
<p class="admonition-title">Summary</p>
<p>Take one PySpark DataFrame <code>from_table</code>, and merge it with another DeltaTable at location: <code>to_table_path</code>/<code>to_table_name</code>.</p>
</div>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>from_table</code>
            </td>
            <td>
                  <code><span title="pyspark.sql.DataFrame">DataFrame</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The PySpark table. Data will be merged FROM here.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>to_table_name</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The name of the Delta table. Data will be merged TO here.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>to_table_path</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The location where the target Delta table can be found.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>matching_keys</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="typing.Union">Union</span>[str, List[str], Tuple[str, ...], Set[str]]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The list of matching columns between both the Spark table and the Delta table.<br>
If this is parsed in as a <code class="highlight"><span class="nb">str</span></code> type, then it will be coerced to a list like: <code>[matching_keys]</code>.<br>
If this is not provided, then BOTH the <code>from_keys</code> and the <code>to_keys</code> must be provided.<br>
Defaults to <code class="highlight"><span class="kc">None</span></code>.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>from_keys</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="typing.Union">Union</span>[str, List[str], Tuple[str, ...], Set[str]]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The list of keys on the <code>from_table</code> to use in the join.<br>
If this is parsed in as a <code class="highlight"><span class="nb">str</span></code> type, then it will be coerced to a list like: <code>[from_keys]</code>.<br>
Only necessary when <code>matching_keys</code> is <code class="highlight"><span class="kc">None</span></code>. When provided, the length must be the same as the <code>to_keys</code>.<br>
Defaults to <code class="highlight"><span class="kc">None</span></code>.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>to_keys</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[<span title="typing.Union">Union</span>[str, List[str], Tuple[str, ...], Set[str]]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The list of keys on the <code>to_table</code> to use in the join.<br>
If this is parsed in as a <code class="highlight"><span class="nb">str</span></code> type, then it will be coerced to a list like: <code>[to_keys]</code>.<br>
Only necessary when <code>matching_keys</code> is <code class="highlight"><span class="kc">None</span></code>. When provided, the length must be the same as the <code>from_keys</code>.<br>
Defaults to <code class="highlight"><span class="kc">None</span></code>.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>partition_keys</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[Dict[str, str]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The keys and values that the <code>to_table</code> is partitioned by.<br>
This is to improve (Concurrency Control)[<a href="https://docs.delta.io/latest/concurrency-control.html">https://docs.delta.io/latest/concurrency-control.html</a>] while performing the merges.<br>
If provided, it will enhance the internal <code>join_keys</code> variable to add new clauses for each column and value provided, to ensure it is explicit and direct.<br>
If provided, it must be a <code class="highlight"><span class="nb">dict</span></code>, where the keys are the columns and the values are the specific partition to use.<br>
For example, if <code>partition_keys</code> is <code>{'SYSTEM':'OWAU','WHSEID':'BNE04'}</code>, then the <code>join_keys</code> will be enhanced to add <code>... and TRG.SYSTEM='OWAU' and TRG.WHSEID='BNE04'. Which will then execute where the partition for</code>SYSTEM<code>will _only_ implement for the</code>OWAU<code>value, and same for</code>WHSEID<code>.
Defaults to</code>#!py None`.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>editdate_col_name</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[str]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The column to use for the <code>editdate</code> field, in case any table uses a different name for this field.<br>
If not provided (as in, the value <code class="highlight"><span class="kc">None</span></code> is parsed to this parameter), then this function will not implement any conditional logic during the <a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaMergeBuilder.whenMatchedUpdateAll"><code>.whenMatchedUpdateAll()</code></a> method.<br>
Defaults to <code class="highlight"><span class="s2">&quot;editdate&quot;</span></code>.</p>
              </div>
            </td>
            <td>
                  <code>&#39;editdate&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>delete_unmatched_rows</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[bool]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether or not to <strong>DELETE</strong> rows on the <em>target</em> table which are existing on the <em>target</em> but missing from the <em>source</em> tables.<br>
This should be used if you want to clean the target table and delete any rows which have already been deleted from the source table.<br>
If <code class="highlight"><span class="kc">True</span></code>, then this function will implement the method <a href="https://docs.delta.io/latest/api/python/spark/index.html#delta.tables.DeltaMergeBuilder.whenNotMatchedBySourceDelete"><code>.whenNoMatchedBySourceDelete()</code></a> method, with no conditionals.<br>
Defaults to <code class="highlight"><span class="kc">False</span></code>.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>enable_automatic_schema_evolution</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[bool]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Optional parameter for whether or not to automatically update the downstream <code>delta</code> table schema.<br>
As documented extensively elsewhere:</p>
<ul>
<li><a href="https://docs.delta.io/latest/delta-update.html#upsert-into-a-table-using-merge">https://docs.delta.io/latest/delta-update.html#upsert-into-a-table-using-merge</a></li>
<li><a href="https://www.databricks.com/blog/2019/09/24/diving-into-delta-lake-schema-enforcement-evolution.html">https://www.databricks.com/blog/2019/09/24/diving-into-delta-lake-schema-enforcement-evolution.html</a></li>
<li><a href="https://www.databricks.com/blog/2020/05/19/schema-evolution-in-merge-operations-and-operational-metrics-in-delta-lake.html">https://www.databricks.com/blog/2020/05/19/schema-evolution-in-merge-operations-and-operational-metrics-in-delta-lake.html</a></li>
<li><a href="https://towardsdatascience.com/delta-lake-automatic-schema-evolution-11d32bd1aa99">https://towardsdatascience.com/delta-lake-automatic-schema-evolution-11d32bd1aa99</a></li>
</ul>
<p>Defaults to <code class="highlight"><span class="kc">False</span></code>.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>return_merge_metrics</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[bool]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Set to <code class="highlight"><span class="kc">True</span></code> if you want to return the Merge metrics from this function.<br>
If <code class="highlight"><span class="kc">False</span></code>, it will only return the value: <code class="highlight"><span class="kc">True</span></code>.<br>
Defaults to <code class="highlight"><span class="kc">False</span></code>.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Union">Union</span>[bool, <span title="pyspark.sql.DataFrame">DataFrame</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Will return either:</p>
<ul>
<li>If <code>return_merge_metrics</code> is <code class="highlight"><span class="kc">True</span></code>: Will return the Merge metrics, which is calculated by:<ol>
<li>Extracting the history from DeltaTable (at the <code>to_table_path</code> location),</li>
<li>Coercing that history object to a <code>pyspark</code> DataFrame,</li>
<li>Filtering to only extract the <code class="highlight"><span class="n">MERGE</span></code> operations,</li>
<li>Limiting to the top <code class="highlight"><span class="mi">1</span></code> lines, which is the most recent info.</li>
</ol>
</li>
<li>If <code>return_merge_metrics</code> is <code class="highlight"><span class="kc">False</span></code>: The value <code class="highlight"><span class="kc">True</span></code> is returned when the function runs successfully.</li>
</ul>
<p>If an error is thrown, then obviously it will not reach this far.
Unfortunately, the DeltaTable Merge process does not return any data or statistics from it's execution... So therefore, we need to use the DeltaTable history to fetch the metrics. For more info, see: <a href="https://github.com/delta-io/delta/issues/1361">Show key metrics after running <code>.merge(...)....execute()</code></a></p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code>TypeError</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If any of the inputs parsed to the parameters of this function are not the correct type. Uses the <a href="https://typeguard.readthedocs.io/en/stable/api.html#typeguard.typechecked"><code>@typeguard.typechecked</code></a> decorator.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code>AttributeError</code>
            </td>
            <td>
              <div class="doc-md-description">
                <ul>
<li>If any of <code>matching_keys</code> do not exist in the Spark table</li>
<li>If any of <code>matching_keys</code> do not exist in the Delta table</li>
<li>If any of <code>from_keys</code> do not exist in the Spark table</li>
<li>If any of <code>to_keys</code> do not exist in the Delta table</li>
</ul>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code>AssertionError</code>
            </td>
            <td>
              <div class="doc-md-description">
                <ul>
<li>If <code>matching_keys</code> is None AND <code>from_keys</code> is None</li>
<li>If <code>matching_keys</code> is None AND <code>to_keys</code> is None</li>
<li>If length of <code>from_keys</code> does not match the length of <code>to_keys</code></li>
</ul>
              </div>
            </td>
          </tr>
      </tbody>
    </table>
        <details class="info" open="open">
<summary>Notes</summary>
<p>The main objective of this function is to:</p>
<ol>
<li>For any records <em>existing</em> in Spark but <em>missing</em> in Delta, then INSERT those records from Spark to Delta. Using the <a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaMergeBuilder.whenNotMatchedInsertAll"><code>.whenNotMatchedInsertAll()</code></a> method.</li>
<li>For any records <em>existing</em> in both Spark and Delta, check if they have been <em>updated</em> in Spark and if so then UPDATE those matching records in the Delta. Using the <a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaMergeBuilder.whenMatchedUpdateAll"><code>.whenMatchedUpdateAll()</code></a> method.</li>
<li>Conditionally, check whether or not to actually apply #2 above by comparing the <code>editdate_col_name</code> field between the two tables.</li>
</ol>
<p>Note:</p>
<ol>
<li>The <code>from_keys</code> and the <code>to_keys</code> will logically be the same values MOST of the time.<ul>
<li>Very rarely will they ever be different; however, they are added here as separate parameters to facilitate this future functionality.</li>
</ul>
</li>
<li>If <code>from_keys</code> and <code>to_keys</code> are type <code class="highlight"><span class="nb">list</span></code>, then their length must be the same.</li>
<li>Conditional logic is applied during the <a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaMergeBuilder.whenMatchedUpdateAll"><code>.whenMatchedUpdateAll()</code></a> method to avoid re-updating data in the Delta location which has actually updated from the SpSpark table.</li>
<li>There is an additional <code class="highlight"><span class="n">ifnull</span><span class="p">()</span></code> conditional check added to the <a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaMergeBuilder.whenMatchedUpdateAll"><code>.whenMatchedUpdateAll()</code></a> method for converting any values in the <em>target</em> table to <code class="highlight"><span class="n">timestamp</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span></code> when their value is actually <code class="highlight"><span class="k">null</span></code>.<ul>
<li>The history to this check is that when these data were originally added to BigDaS, the column <code>EditDate</code> did not exist.</li>
<li>Therefore, when they were first inserted, all the values in <code>EditDate</code> were <code class="highlight"><span class="k">null</span></code>.</li>
<li>As time progressed, the records have slowly been updating, and therefore the <code>EditDate</code> values have been changing.</li>
<li>Due to nuances and semantics around how Spark handles <code>null</code> values, whenever this previous check was run including columns with values <code class="highlight"><span class="k">null</span></code>, it would inevitably return <code class="highlight"><span class="k">null</span></code>.</li>
<li>As such, these rows were not identified as able to be matched, therefore the optimiser skipped them.</li>
<li>However, we actually did want them to be matched; because the rows had actually been updated on the <em>source</em> table.</li>
<li>Therefore, we add this <code class="highlight"><span class="n">ifnull</span><span class="p">()</span></code> check to capture this edge case, and then push through and update the record on the <em>target</em> table.</li>
</ul>
</li>
<li>The parameter <code>enable_automatic_schema_evolution</code> was added because it is possible for the upstream tables to be adding new columns as they evolve. Therefore, it is necessary for this function to handle schema evolution automatically.</li>
</ol>
</details>
<details class="question" open="open">
<summary>References</summary>
<ul>
<li><a href="https://docs.databricks.com/delta/delta-update.html#language-python">https://docs.databricks.com/delta/delta-update.html#language-python</a></li>
<li><a href="https://docs.delta.io/latest/delta-update.html#upsert-into-a-table-using-merge&amp;language-python">https://docs.delta.io/latest/delta-update.html#upsert-into-a-table-using-merge&amp;language-python</a></li>
<li><a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaMergeBuilder">https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaMergeBuilder</a></li>
<li><a href="https://spark.apache.org/docs/3.0.0-preview/sql-ref-null-semantics.html">https://spark.apache.org/docs/3.0.0-preview/sql-ref-null-semantics.html</a></li>
<li><a href="https://docs.delta.io/latest/delta-update.html#upsert-into-a-table-using-merge">https://docs.delta.io/latest/delta-update.html#upsert-into-a-table-using-merge</a></li>
</ul>
</details>
<details class="tip" open="open">
<summary>See also</summary>
<ul>
<li><a class="autorefs autorefs-internal" href="#toolbox_pyspark.delta.load_table"><code>load_table()</code></a></li>
<li><a class="autorefs autorefs-internal" href="../checks/#toolbox_pyspark.checks.assert_columns_exists"><code>assert_columns_exists()</code></a></li>
<li><a class="autorefs autorefs-internal" href="../columns/#toolbox_pyspark.columns.get_columns"><code>get_columns()</code></a></li>
<li><a href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.SparkSession.html"><code>SparkSession</code></a></li>
<li><a href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.SparkSession.sql.html"><code>SparkSession.sql()</code></a></li>
<li><a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaMergeBuilder"><code>DeltaMergeBuilder</code></a></li>
<li><a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable"><code>DeltaTable</code></a></li>
<li><a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable.history"><code>DeltaTable.history()</code></a></li>
</ul>
</details>

            <details class="quote">
              <summary>Source code in <code>src/toolbox_pyspark/delta.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">698</span>
<span class="normal">699</span>
<span class="normal">700</span>
<span class="normal">701</span>
<span class="normal">702</span>
<span class="normal">703</span>
<span class="normal">704</span>
<span class="normal">705</span>
<span class="normal">706</span>
<span class="normal">707</span>
<span class="normal">708</span>
<span class="normal">709</span>
<span class="normal">710</span>
<span class="normal">711</span>
<span class="normal">712</span>
<span class="normal">713</span>
<span class="normal">714</span>
<span class="normal">715</span>
<span class="normal">716</span>
<span class="normal">717</span>
<span class="normal">718</span>
<span class="normal">719</span>
<span class="normal">720</span>
<span class="normal">721</span>
<span class="normal">722</span>
<span class="normal">723</span>
<span class="normal">724</span>
<span class="normal">725</span>
<span class="normal">726</span>
<span class="normal">727</span>
<span class="normal">728</span>
<span class="normal">729</span>
<span class="normal">730</span>
<span class="normal">731</span>
<span class="normal">732</span>
<span class="normal">733</span>
<span class="normal">734</span>
<span class="normal">735</span>
<span class="normal">736</span>
<span class="normal">737</span>
<span class="normal">738</span>
<span class="normal">739</span>
<span class="normal">740</span>
<span class="normal">741</span>
<span class="normal">742</span>
<span class="normal">743</span>
<span class="normal">744</span>
<span class="normal">745</span>
<span class="normal">746</span>
<span class="normal">747</span>
<span class="normal">748</span>
<span class="normal">749</span>
<span class="normal">750</span>
<span class="normal">751</span>
<span class="normal">752</span>
<span class="normal">753</span>
<span class="normal">754</span>
<span class="normal">755</span>
<span class="normal">756</span>
<span class="normal">757</span>
<span class="normal">758</span>
<span class="normal">759</span>
<span class="normal">760</span>
<span class="normal">761</span>
<span class="normal">762</span>
<span class="normal">763</span>
<span class="normal">764</span>
<span class="normal">765</span>
<span class="normal">766</span>
<span class="normal">767</span>
<span class="normal">768</span>
<span class="normal">769</span>
<span class="normal">770</span>
<span class="normal">771</span>
<span class="normal">772</span>
<span class="normal">773</span>
<span class="normal">774</span>
<span class="normal">775</span>
<span class="normal">776</span>
<span class="normal">777</span>
<span class="normal">778</span>
<span class="normal">779</span>
<span class="normal">780</span>
<span class="normal">781</span>
<span class="normal">782</span>
<span class="normal">783</span>
<span class="normal">784</span>
<span class="normal">785</span>
<span class="normal">786</span>
<span class="normal">787</span>
<span class="normal">788</span>
<span class="normal">789</span>
<span class="normal">790</span>
<span class="normal">791</span>
<span class="normal">792</span>
<span class="normal">793</span>
<span class="normal">794</span>
<span class="normal">795</span>
<span class="normal">796</span>
<span class="normal">797</span>
<span class="normal">798</span>
<span class="normal">799</span>
<span class="normal">800</span>
<span class="normal">801</span>
<span class="normal">802</span>
<span class="normal">803</span>
<span class="normal">804</span>
<span class="normal">805</span>
<span class="normal">806</span>
<span class="normal">807</span>
<span class="normal">808</span>
<span class="normal">809</span>
<span class="normal">810</span>
<span class="normal">811</span>
<span class="normal">812</span>
<span class="normal">813</span>
<span class="normal">814</span>
<span class="normal">815</span>
<span class="normal">816</span>
<span class="normal">817</span>
<span class="normal">818</span>
<span class="normal">819</span>
<span class="normal">820</span>
<span class="normal">821</span>
<span class="normal">822</span>
<span class="normal">823</span>
<span class="normal">824</span>
<span class="normal">825</span>
<span class="normal">826</span>
<span class="normal">827</span>
<span class="normal">828</span>
<span class="normal">829</span>
<span class="normal">830</span>
<span class="normal">831</span>
<span class="normal">832</span>
<span class="normal">833</span>
<span class="normal">834</span>
<span class="normal">835</span>
<span class="normal">836</span>
<span class="normal">837</span>
<span class="normal">838</span>
<span class="normal">839</span>
<span class="normal">840</span>
<span class="normal">841</span>
<span class="normal">842</span>
<span class="normal">843</span>
<span class="normal">844</span>
<span class="normal">845</span>
<span class="normal">846</span>
<span class="normal">847</span>
<span class="normal">848</span>
<span class="normal">849</span>
<span class="normal">850</span>
<span class="normal">851</span>
<span class="normal">852</span>
<span class="normal">853</span>
<span class="normal">854</span>
<span class="normal">855</span>
<span class="normal">856</span>
<span class="normal">857</span>
<span class="normal">858</span>
<span class="normal">859</span>
<span class="normal">860</span>
<span class="normal">861</span>
<span class="normal">862</span>
<span class="normal">863</span>
<span class="normal">864</span>
<span class="normal">865</span>
<span class="normal">866</span>
<span class="normal">867</span>
<span class="normal">868</span>
<span class="normal">869</span>
<span class="normal">870</span>
<span class="normal">871</span>
<span class="normal">872</span>
<span class="normal">873</span>
<span class="normal">874</span>
<span class="normal">875</span>
<span class="normal">876</span>
<span class="normal">877</span>
<span class="normal">878</span>
<span class="normal">879</span>
<span class="normal">880</span>
<span class="normal">881</span>
<span class="normal">882</span>
<span class="normal">883</span>
<span class="normal">884</span>
<span class="normal">885</span>
<span class="normal">886</span>
<span class="normal">887</span>
<span class="normal">888</span>
<span class="normal">889</span>
<span class="normal">890</span>
<span class="normal">891</span>
<span class="normal">892</span>
<span class="normal">893</span>
<span class="normal">894</span>
<span class="normal">895</span>
<span class="normal">896</span>
<span class="normal">897</span>
<span class="normal">898</span>
<span class="normal">899</span>
<span class="normal">900</span>
<span class="normal">901</span>
<span class="normal">902</span>
<span class="normal">903</span>
<span class="normal">904</span>
<span class="normal">905</span>
<span class="normal">906</span>
<span class="normal">907</span>
<span class="normal">908</span>
<span class="normal">909</span>
<span class="normal">910</span>
<span class="normal">911</span>
<span class="normal">912</span>
<span class="normal">913</span>
<span class="normal">914</span>
<span class="normal">915</span>
<span class="normal">916</span>
<span class="normal">917</span>
<span class="normal">918</span>
<span class="normal">919</span>
<span class="normal">920</span>
<span class="normal">921</span>
<span class="normal">922</span>
<span class="normal">923</span>
<span class="normal">924</span>
<span class="normal">925</span>
<span class="normal">926</span>
<span class="normal">927</span>
<span class="normal">928</span>
<span class="normal">929</span>
<span class="normal">930</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@typechecked</span>
<span class="k">def</span> <span class="nf">merge_spark_to_delta</span><span class="p">(</span>
    <span class="n">from_table</span><span class="p">:</span> <span class="n">psDataFrame</span><span class="p">,</span>
    <span class="n">to_table_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">to_table_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">matching_keys</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">str_collection</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">from_keys</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">str_collection</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">to_keys</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">str_collection</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">partition_keys</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">str_dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">editdate_col_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;editdate&quot;</span><span class="p">,</span>
    <span class="n">delete_unmatched_rows</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">enable_automatic_schema_evolution</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">return_merge_metrics</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">bool</span><span class="p">,</span> <span class="n">psDataFrame</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    !!! note &quot;Summary&quot;</span>
<span class="sd">        Take one PySpark DataFrame `from_table`, and merge it with another DeltaTable at location: `to_table_path`/`to_table_name`.</span>

<span class="sd">    Params:</span>
<span class="sd">        from_table (psDataFrame):</span>
<span class="sd">            The PySpark table. Data will be merged FROM here.</span>
<span class="sd">        to_table_name (str):</span>
<span class="sd">            The name of the Delta table. Data will be merged TO here.</span>
<span class="sd">        to_table_path (str):</span>
<span class="sd">            The location where the target Delta table can be found.</span>
<span class="sd">        matching_keys (Optional[Union[str, List[str], Tuple[str, ...], Set[str]]], optional):</span>
<span class="sd">            The list of matching columns between both the Spark table and the Delta table.&lt;br&gt;</span>
<span class="sd">            If this is parsed in as a `#!py str` type, then it will be coerced to a list like: `[matching_keys]`.&lt;br&gt;</span>
<span class="sd">            If this is not provided, then BOTH the `from_keys` and the `to_keys` must be provided.&lt;br&gt;</span>
<span class="sd">            Defaults to `#!py None`.</span>
<span class="sd">        from_keys (Optional[Union[str, List[str], Tuple[str, ...], Set[str]]], optional):</span>
<span class="sd">            The list of keys on the `from_table` to use in the join.&lt;br&gt;</span>
<span class="sd">            If this is parsed in as a `#!py str` type, then it will be coerced to a list like: `[from_keys]`.&lt;br&gt;</span>
<span class="sd">            Only necessary when `matching_keys` is `#!py None`. When provided, the length must be the same as the `to_keys`.&lt;br&gt;</span>
<span class="sd">            Defaults to `#!py None`.</span>
<span class="sd">        to_keys (Optional[Union[str, List[str], Tuple[str, ...], Set[str]]], optional):</span>
<span class="sd">            The list of keys on the `to_table` to use in the join.&lt;br&gt;</span>
<span class="sd">            If this is parsed in as a `#!py str` type, then it will be coerced to a list like: `[to_keys]`.&lt;br&gt;</span>
<span class="sd">            Only necessary when `matching_keys` is `#!py None`. When provided, the length must be the same as the `from_keys`.&lt;br&gt;</span>
<span class="sd">            Defaults to `#!py None`.</span>
<span class="sd">        partition_keys (Optional[Dict[str, str]], optional):</span>
<span class="sd">            The keys and values that the `to_table` is partitioned by.&lt;br&gt;</span>
<span class="sd">            This is to improve (Concurrency Control)[https://docs.delta.io/latest/concurrency-control.html] while performing the merges.&lt;br&gt;</span>
<span class="sd">            If provided, it will enhance the internal `join_keys` variable to add new clauses for each column and value provided, to ensure it is explicit and direct.&lt;br&gt;</span>
<span class="sd">            If provided, it must be a `#!py dict`, where the keys are the columns and the values are the specific partition to use.&lt;br&gt;</span>
<span class="sd">            For example, if `partition_keys` is `{&#39;SYSTEM&#39;:&#39;OWAU&#39;,&#39;WHSEID&#39;:&#39;BNE04&#39;}`, then the `join_keys` will be enhanced to add `... and TRG.SYSTEM=&#39;OWAU&#39; and TRG.WHSEID=&#39;BNE04&#39;. Which will then execute where the partition for `SYSTEM` will _only_ implement for the `OWAU` value, and same for `WHSEID`.</span>
<span class="sd">            Defaults to `#!py None`.</span>
<span class="sd">        editdate_col_name (Optional[str], optional):</span>
<span class="sd">            The column to use for the `editdate` field, in case any table uses a different name for this field.&lt;br&gt;</span>
<span class="sd">            If not provided (as in, the value `#!py None` is parsed to this parameter), then this function will not implement any conditional logic during the [`.whenMatchedUpdateAll()`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaMergeBuilder.whenMatchedUpdateAll) method.&lt;br&gt;</span>
<span class="sd">            Defaults to `#!py &quot;editdate&quot;`.</span>
<span class="sd">        delete_unmatched_rows (Optional[bool], optional):</span>
<span class="sd">            Whether or not to **DELETE** rows on the _target_ table which are existing on the _target_ but missing from the _source_ tables.&lt;br&gt;</span>
<span class="sd">            This should be used if you want to clean the target table and delete any rows which have already been deleted from the source table.&lt;br&gt;</span>
<span class="sd">            If `#!py True`, then this function will implement the method [`.whenNoMatchedBySourceDelete()`](https://docs.delta.io/latest/api/python/spark/index.html#delta.tables.DeltaMergeBuilder.whenNotMatchedBySourceDelete) method, with no conditionals.&lt;br&gt;</span>
<span class="sd">            Defaults to `#!py False`.</span>
<span class="sd">        enable_automatic_schema_evolution (Optional[bool], optional):</span>
<span class="sd">            Optional parameter for whether or not to automatically update the downstream `delta` table schema.&lt;br&gt;</span>
<span class="sd">            As documented extensively elsewhere:</span>

<span class="sd">            - https://docs.delta.io/latest/delta-update.html#upsert-into-a-table-using-merge</span>
<span class="sd">            - https://www.databricks.com/blog/2019/09/24/diving-into-delta-lake-schema-enforcement-evolution.html</span>
<span class="sd">            - https://www.databricks.com/blog/2020/05/19/schema-evolution-in-merge-operations-and-operational-metrics-in-delta-lake.html</span>
<span class="sd">            - https://towardsdatascience.com/delta-lake-automatic-schema-evolution-11d32bd1aa99</span>

<span class="sd">            Defaults to `#!py False`.</span>
<span class="sd">        return_merge_metrics (Optional[bool], optional):</span>
<span class="sd">            Set to `#!py True` if you want to return the Merge metrics from this function.&lt;br&gt;</span>
<span class="sd">            If `#!py False`, it will only return the value: `#!py True`.&lt;br&gt;</span>
<span class="sd">            Defaults to `#!py False`.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (Union[bool, psDataFrame]):</span>
<span class="sd">            Will return either:</span>

<span class="sd">            - If `return_merge_metrics` is `#!py True`: Will return the Merge metrics, which is calculated by:</span>
<span class="sd">                1. Extracting the history from DeltaTable (at the `to_table_path` location),</span>
<span class="sd">                1. Coercing that history object to a `pyspark` DataFrame,</span>
<span class="sd">                1. Filtering to only extract the `#!sql MERGE` operations,</span>
<span class="sd">                1. Limiting to the top `#!py 1` lines, which is the most recent info.</span>
<span class="sd">            - If `return_merge_metrics` is `#!py False`: The value `#!py True` is returned when the function runs successfully.</span>

<span class="sd">            If an error is thrown, then obviously it will not reach this far.</span>
<span class="sd">            Unfortunately, the DeltaTable Merge process does not return any data or statistics from it&#39;s execution... So therefore, we need to use the DeltaTable history to fetch the metrics. For more info, see: [Show key metrics after running `.merge(...)....execute()`](https://github.com/delta-io/delta/issues/1361)</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError:</span>
<span class="sd">            If any of the inputs parsed to the parameters of this function are not the correct type. Uses the [`@typeguard.typechecked`](https://typeguard.readthedocs.io/en/stable/api.html#typeguard.typechecked) decorator.</span>
<span class="sd">        AttributeError:</span>
<span class="sd">            - If any of `matching_keys` do not exist in the Spark table</span>
<span class="sd">            - If any of `matching_keys` do not exist in the Delta table</span>
<span class="sd">            - If any of `from_keys` do not exist in the Spark table</span>
<span class="sd">            - If any of `to_keys` do not exist in the Delta table</span>
<span class="sd">        AssertionError:</span>
<span class="sd">            - If `matching_keys` is None AND `from_keys` is None</span>
<span class="sd">            - If `matching_keys` is None AND `to_keys` is None</span>
<span class="sd">            - If length of `from_keys` does not match the length of `to_keys`</span>

<span class="sd">    ???+ info &quot;Notes&quot;</span>
<span class="sd">        The main objective of this function is to:</span>

<span class="sd">        1. For any records _existing_ in Spark but _missing_ in Delta, then INSERT those records from Spark to Delta. Using the [`.whenNotMatchedInsertAll()`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaMergeBuilder.whenNotMatchedInsertAll) method.</span>
<span class="sd">        1. For any records _existing_ in both Spark and Delta, check if they have been _updated_ in Spark and if so then UPDATE those matching records in the Delta. Using the [`.whenMatchedUpdateAll()`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaMergeBuilder.whenMatchedUpdateAll) method.</span>
<span class="sd">        1. Conditionally, check whether or not to actually apply #2 above by comparing the `editdate_col_name` field between the two tables.</span>

<span class="sd">        Note:</span>

<span class="sd">        1. The `from_keys` and the `to_keys` will logically be the same values MOST of the time.</span>
<span class="sd">            - Very rarely will they ever be different; however, they are added here as separate parameters to facilitate this future functionality.</span>
<span class="sd">        1. If `from_keys` and `to_keys` are type `#!py list`, then their length must be the same.</span>
<span class="sd">        1. Conditional logic is applied during the [`.whenMatchedUpdateAll()`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaMergeBuilder.whenMatchedUpdateAll) method to avoid re-updating data in the Delta location which has actually updated from the SpSpark table.</span>
<span class="sd">        1. There is an additional `#!sql ifnull()` conditional check added to the [`.whenMatchedUpdateAll()`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaMergeBuilder.whenMatchedUpdateAll) method for converting any values in the _target_ table to `#!py timestamp(0)` when their value is actually `#!sql null`.</span>
<span class="sd">            - The history to this check is that when these data were originally added to BigDaS, the column `EditDate` did not exist.</span>
<span class="sd">            - Therefore, when they were first inserted, all the values in `EditDate` were `#!sql null`.</span>
<span class="sd">            - As time progressed, the records have slowly been updating, and therefore the `EditDate` values have been changing.</span>
<span class="sd">            - Due to nuances and semantics around how Spark handles `null` values, whenever this previous check was run including columns with values `#!sql null`, it would inevitably return `#!sql null`.</span>
<span class="sd">            - As such, these rows were not identified as able to be matched, therefore the optimiser skipped them.</span>
<span class="sd">            - However, we actually did want them to be matched; because the rows had actually been updated on the _source_ table.</span>
<span class="sd">            - Therefore, we add this `#!sql ifnull()` check to capture this edge case, and then push through and update the record on the _target_ table.</span>
<span class="sd">        1. The parameter `enable_automatic_schema_evolution` was added because it is possible for the upstream tables to be adding new columns as they evolve. Therefore, it is necessary for this function to handle schema evolution automatically.</span>

<span class="sd">    ???+ question &quot;References&quot;</span>
<span class="sd">        - https://docs.databricks.com/delta/delta-update.html#language-python</span>
<span class="sd">        - https://docs.delta.io/latest/delta-update.html#upsert-into-a-table-using-merge&amp;language-python</span>
<span class="sd">        - https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaMergeBuilder</span>
<span class="sd">        - https://spark.apache.org/docs/3.0.0-preview/sql-ref-null-semantics.html</span>
<span class="sd">        - https://docs.delta.io/latest/delta-update.html#upsert-into-a-table-using-merge</span>

<span class="sd">    ???+ tip &quot;See also&quot;</span>
<span class="sd">        - [`load_table()`][toolbox_pyspark.delta.load_table]</span>
<span class="sd">        - [`assert_columns_exists()`][toolbox_pyspark.delta.assert_columns_exists]</span>
<span class="sd">        - [`get_columns()`][toolbox_pyspark.delta.get_columns]</span>
<span class="sd">        - [`SparkSession`](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.SparkSession.html)</span>
<span class="sd">        - [`SparkSession.sql()`](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.SparkSession.sql.html)</span>
<span class="sd">        - [`DeltaMergeBuilder`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaMergeBuilder)</span>
<span class="sd">        - [`DeltaTable`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable)</span>
<span class="sd">        - [`DeltaTable.history()`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable.history)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># Set up</span>
    <span class="n">SRC_ALIAS</span> <span class="o">=</span> <span class="s2">&quot;src&quot;</span>
    <span class="n">TRG_ALIAS</span> <span class="o">=</span> <span class="s2">&quot;dlt&quot;</span>
    <span class="n">spark_session</span><span class="p">:</span> <span class="n">SparkSession</span> <span class="o">=</span> <span class="n">from_table</span><span class="o">.</span><span class="n">sparkSession</span>

    <span class="c1"># Enable automatic Schema Evolution</span>
    <span class="k">if</span> <span class="n">enable_automatic_schema_evolution</span><span class="p">:</span>
        <span class="n">current_conf</span> <span class="o">=</span> <span class="n">spark_session</span><span class="o">.</span><span class="n">conf</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
            <span class="s2">&quot;spark.databricks.delta.schema.autoMerge.enabled&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">_</span> <span class="o">=</span> <span class="n">spark_session</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="s2">&quot;SET spark.databricks.delta.schema.autoMerge.enabled = true&quot;</span><span class="p">)</span>

    <span class="c1"># Define target table</span>
    <span class="n">to_table</span> <span class="o">=</span> <span class="n">load_table</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="n">to_table_name</span><span class="p">,</span>
        <span class="n">path</span><span class="o">=</span><span class="n">to_table_path</span><span class="p">,</span>
        <span class="n">spark_session</span><span class="o">=</span><span class="n">spark_session</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># Check keys</span>
    <span class="k">if</span> <span class="n">matching_keys</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">matching_keys</span> <span class="o">=</span> <span class="n">get_columns</span><span class="p">(</span><span class="n">from_table</span><span class="p">,</span> <span class="n">matching_keys</span><span class="p">)</span>
        <span class="n">assert_columns_exists</span><span class="p">(</span><span class="n">from_table</span><span class="p">,</span> <span class="n">matching_keys</span><span class="p">,</span> <span class="n">match_case</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">assert_columns_exists</span><span class="p">(</span><span class="n">to_table</span><span class="o">.</span><span class="n">toDF</span><span class="p">(),</span> <span class="n">matching_keys</span><span class="p">,</span> <span class="n">match_case</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">join_keys</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot; and &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
            <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">SRC_ALIAS</span><span class="si">}</span><span class="s2">.</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">=</span><span class="si">{</span><span class="n">TRG_ALIAS</span><span class="si">}</span><span class="s2">.</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">matching_keys</span><span class="p">]</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">from_keys</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Cannot be `None`: &#39;</span><span class="si">{</span><span class="n">from_keys</span><span class="si">=}</span><span class="s2">&#39;&quot;</span>
        <span class="k">assert</span> <span class="n">to_keys</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Cannot be `None`: &#39;</span><span class="si">{</span><span class="n">to_keys</span><span class="si">=}</span><span class="s2">&#39;&quot;</span>
        <span class="n">from_keys</span> <span class="o">=</span> <span class="n">get_columns</span><span class="p">(</span><span class="n">from_table</span><span class="p">,</span> <span class="n">from_keys</span><span class="p">)</span>
        <span class="n">to_keys</span> <span class="o">=</span> <span class="n">get_columns</span><span class="p">(</span><span class="n">to_table</span><span class="o">.</span><span class="n">toDF</span><span class="p">(),</span> <span class="n">to_keys</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">len</span><span class="p">(</span><span class="n">from_keys</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">to_keys</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;`from_keys` &amp; `to_keys` must be the same length.&quot;</span><span class="p">)</span>
        <span class="n">assert_columns_exists</span><span class="p">(</span><span class="n">from_table</span><span class="p">,</span> <span class="n">from_keys</span><span class="p">,</span> <span class="n">match_case</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">assert_columns_exists</span><span class="p">(</span><span class="n">to_table</span><span class="o">.</span><span class="n">toDF</span><span class="p">(),</span> <span class="n">to_keys</span><span class="p">,</span> <span class="n">match_case</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">combined_keys</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="n">from_keys</span><span class="p">,</span> <span class="n">to_keys</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">from_key</span><span class="p">,</span> <span class="n">to_key</span> <span class="ow">in</span> <span class="n">combined_keys</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">from_key</span> <span class="o">==</span> <span class="n">to_key</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Must be same: &#39;</span><span class="si">{</span><span class="n">from_key</span><span class="si">=}</span><span class="s2">&#39; &amp; &#39;</span><span class="si">{</span><span class="n">to_key</span><span class="si">=}</span><span class="s2">&#39;&quot;</span>
        <span class="n">join_keys</span> <span class="o">=</span> <span class="s2">&quot; and &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">SRC_ALIAS</span><span class="si">}</span><span class="s2">.</span><span class="si">{</span><span class="n">from_key</span><span class="si">}</span><span class="s2">=</span><span class="si">{</span><span class="n">TRG_ALIAS</span><span class="si">}</span><span class="s2">.</span><span class="si">{</span><span class="n">to_key</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="k">for</span> <span class="n">from_key</span><span class="p">,</span> <span class="n">to_key</span> <span class="ow">in</span> <span class="n">combined_keys</span>
            <span class="p">]</span>
        <span class="p">)</span>
    <span class="k">if</span> <span class="n">partition_keys</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">assert_columns_exists</span><span class="p">(</span><span class="n">to_table</span><span class="o">.</span><span class="n">toDF</span><span class="p">(),</span> <span class="nb">list</span><span class="p">(</span><span class="n">partition_keys</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>
        <span class="c1"># TODO: Add a check for the `values`??</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">partition_keys</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">join_keys</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot; and </span><span class="si">{</span><span class="n">TRG_ALIAS</span><span class="si">}</span><span class="s2">.</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">=&#39;</span><span class="si">{</span><span class="n">value</span><span class="si">}</span><span class="s2">&#39;&quot;</span>

    <span class="c1"># Run</span>
    <span class="n">merger</span><span class="p">:</span> <span class="n">DeltaMergeBuilder</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">to_table</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="n">TRG_ALIAS</span><span class="p">)</span>
        <span class="o">.</span><span class="n">merge</span><span class="p">(</span>
            <span class="n">source</span><span class="o">=</span><span class="n">from_table</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="n">SRC_ALIAS</span><span class="p">),</span>
            <span class="n">condition</span><span class="o">=</span><span class="n">join_keys</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="o">.</span><span class="n">whenMatchedUpdateAll</span><span class="p">(</span>
            <span class="n">condition</span><span class="o">=</span><span class="p">(</span>
                <span class="kc">None</span>
                <span class="k">if</span> <span class="n">editdate_col_name</span> <span class="ow">is</span> <span class="kc">None</span>
                <span class="k">else</span> <span class="sa">f</span><span class="s2">&quot;ifnull(</span><span class="si">{</span><span class="n">TRG_ALIAS</span><span class="si">}</span><span class="s2">.</span><span class="si">{</span><span class="n">editdate_col_name</span><span class="si">}</span><span class="s2">, timestamp(0))&lt;</span><span class="si">{</span><span class="n">SRC_ALIAS</span><span class="si">}</span><span class="s2">.</span><span class="si">{</span><span class="n">editdate_col_name</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="p">)</span>
        <span class="o">.</span><span class="n">whenNotMatchedInsertAll</span><span class="p">()</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="n">delete_unmatched_rows</span><span class="p">:</span>
        <span class="n">merger</span> <span class="o">=</span> <span class="n">merger</span><span class="o">.</span><span class="n">whenNotMatchedBySourceDelete</span><span class="p">()</span>
    <span class="n">merger</span><span class="o">.</span><span class="n">execute</span><span class="p">()</span>

    <span class="c1"># Return settings</span>
    <span class="k">if</span> <span class="n">enable_automatic_schema_evolution</span> <span class="ow">and</span> <span class="n">current_conf</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">_</span> <span class="o">=</span> <span class="n">spark_session</span><span class="o">.</span><span class="n">conf</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
            <span class="s2">&quot;spark.databricks.delta.schema.autoMerge.enabled&quot;</span><span class="p">,</span>
            <span class="n">current_conf</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="c1"># Return</span>
    <span class="k">if</span> <span class="n">return_merge_metrics</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="n">to_table</span><span class="o">.</span><span class="n">history</span><span class="p">()</span>
            <span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="s2">&quot;operation=&#39;MERGE&#39;&quot;</span><span class="p">)</span>
            <span class="o">.</span><span class="n">limit</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="o">.</span><span class="n">select</span><span class="p">(</span>
                <span class="s2">&quot;version&quot;</span><span class="p">,</span>
                <span class="s2">&quot;timestamp&quot;</span><span class="p">,</span>
                <span class="s2">&quot;operation&quot;</span><span class="p">,</span>
                <span class="s2">&quot;operationParameters&quot;</span><span class="p">,</span>
                <span class="s2">&quot;operationMetrics&quot;</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">True</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>






<div class="doc doc-object doc-function">


<h4 id="toolbox_pyspark.delta.merge_delta_to_delta" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">merge_delta_to_delta</span>


<a href="#toolbox_pyspark.delta.merge_delta_to_delta" class="headerlink" title="Permanent link">ðŸ”—</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span class="nf">merge_delta_to_delta</span><span class="p">(</span>
    <span class="n">from_table_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">from_table_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">to_table_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">to_table_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">spark_session</span><span class="p">:</span> <span class="n">SparkSession</span><span class="p">,</span>
    <span class="n">matching_keys</span><span class="p">:</span> <span class="n">str_collection</span><span class="p">,</span>
    <span class="n">partition_keys</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">str_dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">editdate_col_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;editdate&quot;</span><span class="p">,</span>
    <span class="n">delete_unmatched_rows</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">enable_automatic_schema_evolution</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span>
        <span class="nb">bool</span>
    <span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">return_merge_metrics</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">bool</span><span class="p">,</span> <span class="n">psDataFrame</span><span class="p">]</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <div class="admonition note">
<p class="admonition-title">Summary</p>
<p>Take one DeltaTable at location<code>from_table_path</code>/<code>from_table_name</code>, and merge it with another DeltaTable at location: <code>to_table_path</code>/<code>to_table_name</code>.</p>
</div>
<details class="abstract" open="open">
<summary>Details</summary>
<p>This function is fundamentally the same as the <a class="autorefs autorefs-internal" href="#toolbox_pyspark.delta.merge_spark_to_delta"><code>merge_spark_to_delta()</code></a> function, except it defines the <code>from_table</code> as a DeltaTable instead of a Spark DataFrame.</p>
</details>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>from_table_name</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The name of the Delta table. Data will be merged FROM here.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>from_table_path</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The location where the source Delta table can be found.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>to_table_name</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The name of the Delta table. Data will be merged TO here.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>to_table_path</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The location where the target Delta table can be found.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>spark_session</code>
            </td>
            <td>
                  <code><span title="pyspark.sql.SparkSession">SparkSession</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The Spark session to use for the merging.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>matching_keys</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[str, List[str], Tuple[str, ...]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The list of matching columns between both the Spark table and the Delta table.<br>
If this is parsed in as a <code class="highlight"><span class="nb">str</span></code> type, then it will be coerced to a list like: <code>[matching_keys]</code>.<br>
If this is not provided, then BOTH the <code>from_keys</code> and the <code>to_keys</code> must be provided.<br>
Defaults to <code class="highlight"><span class="kc">None</span></code>.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>editdate_col_name</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[str]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The column to use for the <code>editdate</code> field, in case any table uses a different name for this field.<br>
If not provided (as in, the value <code class="highlight"><span class="kc">None</span></code> is parsed to this parameter), then this function will not implement any conditional logic during the <a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaMergeBuilder.whenMatchedUpdateAll"><code>.whenMatchedUpdateAll()</code></a> method.<br>
Defaults to <code class="highlight"><span class="s2">&quot;editdate&quot;</span></code>.</p>
              </div>
            </td>
            <td>
                  <code>&#39;editdate&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>delete_unmatched_rows</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[bool]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether or not to <strong>DELETE</strong> rows on the <em>target</em> table which are existing on the <em>target</em> but missing from the <em>source</em> tables.<br>
This should be used if you want to clean the target table and delete any rows which have already been deleted from the source table.<br>
If <code class="highlight"><span class="kc">True</span></code>, then this function will implement the method <a href="https://docs.delta.io/latest/api/python/spark/index.html#delta.tables.DeltaMergeBuilder.whenNotMatchedBySourceDelete"><code>.whenNoMatchedBySourceDelete()</code></a> method, with no conditionals.<br>
Defaults to <code class="highlight"><span class="kc">False</span></code>.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>enable_automatic_schema_evolution</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[bool]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Optional parameter for whether or not to automatically update the downstream <code>delta</code> table schema.<br>
As documented extensively elsewhere:</p>
<ul>
<li><a href="https://docs.delta.io/latest/delta-update.html#upsert-into-a-table-using-merge">https://docs.delta.io/latest/delta-update.html#upsert-into-a-table-using-merge</a></li>
<li><a href="https://www.databricks.com/blog/2019/09/24/diving-into-delta-lake-schema-enforcement-evolution.html">https://www.databricks.com/blog/2019/09/24/diving-into-delta-lake-schema-enforcement-evolution.html</a></li>
<li><a href="https://www.databricks.com/blog/2020/05/19/schema-evolution-in-merge-operations-and-operational-metrics-in-delta-lake.html">https://www.databricks.com/blog/2020/05/19/schema-evolution-in-merge-operations-and-operational-metrics-in-delta-lake.html</a></li>
<li><a href="https://towardsdatascience.com/delta-lake-automatic-schema-evolution-11d32bd1aa99">https://towardsdatascience.com/delta-lake-automatic-schema-evolution-11d32bd1aa99</a></li>
</ul>
<p>Defaults to <code class="highlight"><span class="kc">False</span></code>.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>return_merge_metrics</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[bool]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Set to <code class="highlight"><span class="kc">True</span></code> if you want to return the Merge metrics from this function.<br>
If <code class="highlight"><span class="kc">False</span></code>, it will only return the value: <code class="highlight"><span class="kc">True</span></code>.<br>
Defaults to <code class="highlight"><span class="kc">False</span></code>.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Union">Union</span>[bool, <span title="pyspark.sql.DataFrame">DataFrame</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Will return either:</p>
<ul>
<li>If <code>return_merge_metrics</code> is <code class="highlight"><span class="kc">True</span></code>: Will return the Merge metrics, which is calculated by:<ol>
<li>Extracting the history from DeltaTable (at the <code>to_table_path</code> location),</li>
<li>Coercing that history object to a <code>pyspark</code> DataFrame,</li>
<li>Filtering to only extract the <code class="highlight"><span class="n">MERGE</span></code> operations,</li>
<li>Limiting to the top <code class="highlight"><span class="mi">1</span></code> lines, which is the most recent info.</li>
</ol>
</li>
<li>If <code>return_merge_metrics</code> is <code class="highlight"><span class="kc">False</span></code>: The value <code class="highlight"><span class="kc">True</span></code> is returned when the function runs successfully.</li>
</ul>
<p>If an error is thrown, then obviously it will not reach this far.
Unfortunately, the DeltaTable Merge process does not return any data or statistics from it's execution... So therefore, we need to use the DeltaTable history to fetch the metrics. For more info, see: <a href="https://github.com/delta-io/delta/issues/1361">Show key metrics after running <code>.merge(...)....execute()</code></a></p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code>TypeError</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If any of the inputs parsed to the parameters of this function are not the correct type. Uses the <a href="https://typeguard.readthedocs.io/en/stable/api.html#typeguard.typechecked"><code>@typeguard.typechecked</code></a> decorator.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code>AttributeError</code>
            </td>
            <td>
              <div class="doc-md-description">
                <ul>
<li>If any of <code>matching_keys</code> do not exist in the Spark table</li>
<li>If any of <code>matching_keys</code> do not exist in the Delta table</li>
<li>If any of <code>from_keys</code> do not exist in the Spark table</li>
<li>If any of <code>to_keys</code> do not exist in the Delta table</li>
</ul>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code>AssertionError</code>
            </td>
            <td>
              <div class="doc-md-description">
                <ul>
<li>If <code>matching_keys</code> is None AND <code>from_keys</code> is None</li>
<li>If <code>matching_keys</code> is None AND <code>to_keys</code> is None</li>
<li>If length of <code>from_keys</code> does not match the length of <code>to_keys</code></li>
</ul>
              </div>
            </td>
          </tr>
      </tbody>
    </table>
        <details class="info">
<summary>Notes</summary>
<p>The main objective of this function is to:</p>
<ol>
<li>For any records <em>existing</em> in Spark but <em>missing</em> in Delta, then INSERT those records from Spark to Delta. Using the <a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaMergeBuilder.whenNotMatchedInsertAll"><code>.whenNotMatchedInsertAll()</code></a> method.</li>
<li>For any records <em>existing</em> in both Spark and Delta, check if they have been <em>updated</em> in Spark and if so then UPDATE those matching records in the Delta. Using the <a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaMergeBuilder.whenMatchedUpdateAll"><code>.whenMatchedUpdateAll()</code></a> method.</li>
<li>Conditionally, check whether or not to actually apply #2 above by comparing the <code>editdate_col_name</code> field between the two tables.</li>
</ol>
<p>Note:</p>
<ol>
<li>The <code>from_keys</code> and the <code>to_keys</code> will logically be the same values MOST of the time.<ul>
<li>Very rarely will they ever be different; however, they are added here as separate parameters to facilitate this future functionality.</li>
</ul>
</li>
<li>If <code>from_keys</code> and <code>to_keys</code> are type <code class="highlight"><span class="nb">list</span></code>, then their length must be the same.</li>
<li>Conditional logic is applied during the <a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaMergeBuilder.whenMatchedUpdateAll"><code>.whenMatchedUpdateAll()</code></a> method to avoid re-updating data in the Delta location which has actually updated from the SpSpark table.</li>
<li>There is an additional <code class="highlight"><span class="n">ifnull</span><span class="p">()</span></code> conditional check added to the <a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaMergeBuilder.whenMatchedUpdateAll"><code>.whenMatchedUpdateAll()</code></a> method for converting any values in the <em>target</em> table to <code class="highlight"><span class="n">timestamp</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span></code> when their value is actually <code class="highlight"><span class="k">null</span></code>.<ul>
<li>The history to this check is that when these data were originally added to BigDaS, the column <code>EditDate</code> did not exist.</li>
<li>Therefore, when they were first inserted, all the values in <code>EditDate</code> were <code class="highlight"><span class="k">null</span></code>.</li>
<li>As time progressed, the records have slowly been updating, and therefore the <code>EditDate</code> values have been changing.</li>
<li>Due to nuances and semantics around how Spark handles <code>null</code> values, whenever this previous check was run including columns with values <code class="highlight"><span class="k">null</span></code>, it would inevitably return <code class="highlight"><span class="k">null</span></code>.</li>
<li>As such, these rows were not identified as able to be matched, therefore the optimiser skipped them.</li>
<li>However, we actually did want them to be matched; because the rows had actually been updated on the <em>source</em> table.</li>
<li>Therefore, we add this <code class="highlight"><span class="n">ifnull</span><span class="p">()</span></code> check to capture this edge case, and then push through and update the record on the <em>target</em> table.</li>
</ul>
</li>
<li>The parameter <code>enable_automatic_schema_evolution</code> was added because it is possible for the upstream tables to be adding new columns as they evolve. Therefore, it is necessary for this function to handle schema evolution automatically.</li>
</ol>
</details>
<details class="question">
<summary>References</summary>
<ul>
<li><a href="https://docs.databricks.com/delta/delta-update.html#language-python">https://docs.databricks.com/delta/delta-update.html#language-python</a></li>
<li><a href="https://docs.delta.io/latest/delta-update.html#upsert-into-a-table-using-merge&amp;language-python">https://docs.delta.io/latest/delta-update.html#upsert-into-a-table-using-merge&amp;language-python</a></li>
<li><a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaMergeBuilder">https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaMergeBuilder</a></li>
<li><a href="https://spark.apache.org/docs/3.0.0-preview/sql-ref-null-semantics.html">https://spark.apache.org/docs/3.0.0-preview/sql-ref-null-semantics.html</a></li>
<li><a href="https://docs.delta.io/latest/delta-update.html#upsert-into-a-table-using-merge">https://docs.delta.io/latest/delta-update.html#upsert-into-a-table-using-merge</a></li>
</ul>
</details>
<details class="tip">
<summary>See Also</summary>
<ul>
<li><a class="autorefs autorefs-internal" href="#toolbox_pyspark.delta.merge_spark_to_delta"><code>merge_spark_to_delta()</code></a></li>
<li><a class="autorefs autorefs-internal" href="#toolbox_pyspark.delta.load_table"><code>load_table()</code></a></li>
<li><a class="autorefs autorefs-internal" href="../checks/#toolbox_pyspark.checks.assert_columns_exists"><code>assert_columns_exists()</code></a></li>
<li><a class="autorefs autorefs-internal" href="../columns/#toolbox_pyspark.columns.get_columns"><code>get_columns()</code></a></li>
<li><a href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.SparkSession.html"><code>SparkSession</code></a></li>
<li><a href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.SparkSession.sql.html"><code>SparkSession.sql()</code></a></li>
<li><a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaMergeBuilder"><code>DeltaMergeBuilder</code></a></li>
<li><a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable"><code>DeltaTable</code></a></li>
<li><a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable.history"><code>DeltaTable.history()</code></a></li>
</ul>
</details>

            <details class="quote">
              <summary>Source code in <code>src/toolbox_pyspark/delta.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 933</span>
<span class="normal"> 934</span>
<span class="normal"> 935</span>
<span class="normal"> 936</span>
<span class="normal"> 937</span>
<span class="normal"> 938</span>
<span class="normal"> 939</span>
<span class="normal"> 940</span>
<span class="normal"> 941</span>
<span class="normal"> 942</span>
<span class="normal"> 943</span>
<span class="normal"> 944</span>
<span class="normal"> 945</span>
<span class="normal"> 946</span>
<span class="normal"> 947</span>
<span class="normal"> 948</span>
<span class="normal"> 949</span>
<span class="normal"> 950</span>
<span class="normal"> 951</span>
<span class="normal"> 952</span>
<span class="normal"> 953</span>
<span class="normal"> 954</span>
<span class="normal"> 955</span>
<span class="normal"> 956</span>
<span class="normal"> 957</span>
<span class="normal"> 958</span>
<span class="normal"> 959</span>
<span class="normal"> 960</span>
<span class="normal"> 961</span>
<span class="normal"> 962</span>
<span class="normal"> 963</span>
<span class="normal"> 964</span>
<span class="normal"> 965</span>
<span class="normal"> 966</span>
<span class="normal"> 967</span>
<span class="normal"> 968</span>
<span class="normal"> 969</span>
<span class="normal"> 970</span>
<span class="normal"> 971</span>
<span class="normal"> 972</span>
<span class="normal"> 973</span>
<span class="normal"> 974</span>
<span class="normal"> 975</span>
<span class="normal"> 976</span>
<span class="normal"> 977</span>
<span class="normal"> 978</span>
<span class="normal"> 979</span>
<span class="normal"> 980</span>
<span class="normal"> 981</span>
<span class="normal"> 982</span>
<span class="normal"> 983</span>
<span class="normal"> 984</span>
<span class="normal"> 985</span>
<span class="normal"> 986</span>
<span class="normal"> 987</span>
<span class="normal"> 988</span>
<span class="normal"> 989</span>
<span class="normal"> 990</span>
<span class="normal"> 991</span>
<span class="normal"> 992</span>
<span class="normal"> 993</span>
<span class="normal"> 994</span>
<span class="normal"> 995</span>
<span class="normal"> 996</span>
<span class="normal"> 997</span>
<span class="normal"> 998</span>
<span class="normal"> 999</span>
<span class="normal">1000</span>
<span class="normal">1001</span>
<span class="normal">1002</span>
<span class="normal">1003</span>
<span class="normal">1004</span>
<span class="normal">1005</span>
<span class="normal">1006</span>
<span class="normal">1007</span>
<span class="normal">1008</span>
<span class="normal">1009</span>
<span class="normal">1010</span>
<span class="normal">1011</span>
<span class="normal">1012</span>
<span class="normal">1013</span>
<span class="normal">1014</span>
<span class="normal">1015</span>
<span class="normal">1016</span>
<span class="normal">1017</span>
<span class="normal">1018</span>
<span class="normal">1019</span>
<span class="normal">1020</span>
<span class="normal">1021</span>
<span class="normal">1022</span>
<span class="normal">1023</span>
<span class="normal">1024</span>
<span class="normal">1025</span>
<span class="normal">1026</span>
<span class="normal">1027</span>
<span class="normal">1028</span>
<span class="normal">1029</span>
<span class="normal">1030</span>
<span class="normal">1031</span>
<span class="normal">1032</span>
<span class="normal">1033</span>
<span class="normal">1034</span>
<span class="normal">1035</span>
<span class="normal">1036</span>
<span class="normal">1037</span>
<span class="normal">1038</span>
<span class="normal">1039</span>
<span class="normal">1040</span>
<span class="normal">1041</span>
<span class="normal">1042</span>
<span class="normal">1043</span>
<span class="normal">1044</span>
<span class="normal">1045</span>
<span class="normal">1046</span>
<span class="normal">1047</span>
<span class="normal">1048</span>
<span class="normal">1049</span>
<span class="normal">1050</span>
<span class="normal">1051</span>
<span class="normal">1052</span>
<span class="normal">1053</span>
<span class="normal">1054</span>
<span class="normal">1055</span>
<span class="normal">1056</span>
<span class="normal">1057</span>
<span class="normal">1058</span>
<span class="normal">1059</span>
<span class="normal">1060</span>
<span class="normal">1061</span>
<span class="normal">1062</span>
<span class="normal">1063</span>
<span class="normal">1064</span>
<span class="normal">1065</span>
<span class="normal">1066</span>
<span class="normal">1067</span>
<span class="normal">1068</span>
<span class="normal">1069</span>
<span class="normal">1070</span>
<span class="normal">1071</span>
<span class="normal">1072</span>
<span class="normal">1073</span>
<span class="normal">1074</span>
<span class="normal">1075</span>
<span class="normal">1076</span>
<span class="normal">1077</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@typechecked</span>
<span class="k">def</span> <span class="nf">merge_delta_to_delta</span><span class="p">(</span>
    <span class="n">from_table_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">from_table_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">to_table_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">to_table_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">spark_session</span><span class="p">:</span> <span class="n">SparkSession</span><span class="p">,</span>
    <span class="n">matching_keys</span><span class="p">:</span> <span class="n">str_collection</span><span class="p">,</span>
    <span class="n">partition_keys</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">str_dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">editdate_col_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;editdate&quot;</span><span class="p">,</span>
    <span class="n">delete_unmatched_rows</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">enable_automatic_schema_evolution</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">return_merge_metrics</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">bool</span><span class="p">,</span> <span class="n">psDataFrame</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    !!! note &quot;Summary&quot;</span>
<span class="sd">        Take one DeltaTable at location`from_table_path`/`from_table_name`, and merge it with another DeltaTable at location: `to_table_path`/`to_table_name`.</span>

<span class="sd">    ???+ abstract &quot;Details&quot;</span>
<span class="sd">        This function is fundamentally the same as the [`merge_spark_to_delta()`][toolbox_pyspark.delta.merge_spark_to_delta] function, except it defines the `from_table` as a DeltaTable instead of a Spark DataFrame.</span>

<span class="sd">    Params:</span>
<span class="sd">        from_table_name (str):</span>
<span class="sd">            The name of the Delta table. Data will be merged FROM here.</span>
<span class="sd">        from_table_path (str):</span>
<span class="sd">            The location where the source Delta table can be found.</span>
<span class="sd">        to_table_name (str):</span>
<span class="sd">            The name of the Delta table. Data will be merged TO here.</span>
<span class="sd">        to_table_path (str):</span>
<span class="sd">            The location where the target Delta table can be found.</span>
<span class="sd">        spark_session (SparkSession):</span>
<span class="sd">            The Spark session to use for the merging.</span>
<span class="sd">        matching_keys (Union[str, List[str], Tuple[str, ...]]):</span>
<span class="sd">            The list of matching columns between both the Spark table and the Delta table.&lt;br&gt;</span>
<span class="sd">            If this is parsed in as a `#!py str` type, then it will be coerced to a list like: `[matching_keys]`.&lt;br&gt;</span>
<span class="sd">            If this is not provided, then BOTH the `from_keys` and the `to_keys` must be provided.&lt;br&gt;</span>
<span class="sd">            Defaults to `#!py None`.</span>
<span class="sd">        editdate_col_name (Optional[str], optional):</span>
<span class="sd">            The column to use for the `editdate` field, in case any table uses a different name for this field.&lt;br&gt;</span>
<span class="sd">            If not provided (as in, the value `#!py None` is parsed to this parameter), then this function will not implement any conditional logic during the [`.whenMatchedUpdateAll()`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaMergeBuilder.whenMatchedUpdateAll) method.&lt;br&gt;</span>
<span class="sd">            Defaults to `#!py &quot;editdate&quot;`.</span>
<span class="sd">        delete_unmatched_rows (Optional[bool], optional):</span>
<span class="sd">            Whether or not to **DELETE** rows on the _target_ table which are existing on the _target_ but missing from the _source_ tables.&lt;br&gt;</span>
<span class="sd">            This should be used if you want to clean the target table and delete any rows which have already been deleted from the source table.&lt;br&gt;</span>
<span class="sd">            If `#!py True`, then this function will implement the method [`.whenNoMatchedBySourceDelete()`](https://docs.delta.io/latest/api/python/spark/index.html#delta.tables.DeltaMergeBuilder.whenNotMatchedBySourceDelete) method, with no conditionals.&lt;br&gt;</span>
<span class="sd">            Defaults to `#!py False`.</span>
<span class="sd">        enable_automatic_schema_evolution (Optional[bool], optional):</span>
<span class="sd">            Optional parameter for whether or not to automatically update the downstream `delta` table schema.&lt;br&gt;</span>
<span class="sd">            As documented extensively elsewhere:</span>

<span class="sd">            - https://docs.delta.io/latest/delta-update.html#upsert-into-a-table-using-merge</span>
<span class="sd">            - https://www.databricks.com/blog/2019/09/24/diving-into-delta-lake-schema-enforcement-evolution.html</span>
<span class="sd">            - https://www.databricks.com/blog/2020/05/19/schema-evolution-in-merge-operations-and-operational-metrics-in-delta-lake.html</span>
<span class="sd">            - https://towardsdatascience.com/delta-lake-automatic-schema-evolution-11d32bd1aa99</span>

<span class="sd">            Defaults to `#!py False`.</span>
<span class="sd">        return_merge_metrics (Optional[bool], optional):</span>
<span class="sd">            Set to `#!py True` if you want to return the Merge metrics from this function.&lt;br&gt;</span>
<span class="sd">            If `#!py False`, it will only return the value: `#!py True`.&lt;br&gt;</span>
<span class="sd">            Defaults to `#!py False`.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (Union[bool, psDataFrame]):</span>
<span class="sd">            Will return either:</span>

<span class="sd">            - If `return_merge_metrics` is `#!py True`: Will return the Merge metrics, which is calculated by:</span>
<span class="sd">                1. Extracting the history from DeltaTable (at the `to_table_path` location),</span>
<span class="sd">                1. Coercing that history object to a `pyspark` DataFrame,</span>
<span class="sd">                1. Filtering to only extract the `#!sql MERGE` operations,</span>
<span class="sd">                1. Limiting to the top `#!py 1` lines, which is the most recent info.</span>
<span class="sd">            - If `return_merge_metrics` is `#!py False`: The value `#!py True` is returned when the function runs successfully.</span>

<span class="sd">            If an error is thrown, then obviously it will not reach this far.</span>
<span class="sd">            Unfortunately, the DeltaTable Merge process does not return any data or statistics from it&#39;s execution... So therefore, we need to use the DeltaTable history to fetch the metrics. For more info, see: [Show key metrics after running `.merge(...)....execute()`](https://github.com/delta-io/delta/issues/1361)</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError:</span>
<span class="sd">            If any of the inputs parsed to the parameters of this function are not the correct type. Uses the [`@typeguard.typechecked`](https://typeguard.readthedocs.io/en/stable/api.html#typeguard.typechecked) decorator.</span>
<span class="sd">        AttributeError:</span>
<span class="sd">            - If any of `matching_keys` do not exist in the Spark table</span>
<span class="sd">            - If any of `matching_keys` do not exist in the Delta table</span>
<span class="sd">            - If any of `from_keys` do not exist in the Spark table</span>
<span class="sd">            - If any of `to_keys` do not exist in the Delta table</span>
<span class="sd">        AssertionError:</span>
<span class="sd">            - If `matching_keys` is None AND `from_keys` is None</span>
<span class="sd">            - If `matching_keys` is None AND `to_keys` is None</span>
<span class="sd">            - If length of `from_keys` does not match the length of `to_keys`</span>

<span class="sd">    ??? info &quot;Notes&quot;</span>
<span class="sd">        The main objective of this function is to:</span>

<span class="sd">        1. For any records _existing_ in Spark but _missing_ in Delta, then INSERT those records from Spark to Delta. Using the [`.whenNotMatchedInsertAll()`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaMergeBuilder.whenNotMatchedInsertAll) method.</span>
<span class="sd">        1. For any records _existing_ in both Spark and Delta, check if they have been _updated_ in Spark and if so then UPDATE those matching records in the Delta. Using the [`.whenMatchedUpdateAll()`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaMergeBuilder.whenMatchedUpdateAll) method.</span>
<span class="sd">        1. Conditionally, check whether or not to actually apply #2 above by comparing the `editdate_col_name` field between the two tables.</span>

<span class="sd">        Note:</span>

<span class="sd">        1. The `from_keys` and the `to_keys` will logically be the same values MOST of the time.</span>
<span class="sd">            - Very rarely will they ever be different; however, they are added here as separate parameters to facilitate this future functionality.</span>
<span class="sd">        1. If `from_keys` and `to_keys` are type `#!py list`, then their length must be the same.</span>
<span class="sd">        1. Conditional logic is applied during the [`.whenMatchedUpdateAll()`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaMergeBuilder.whenMatchedUpdateAll) method to avoid re-updating data in the Delta location which has actually updated from the SpSpark table.</span>
<span class="sd">        1. There is an additional `#!sql ifnull()` conditional check added to the [`.whenMatchedUpdateAll()`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaMergeBuilder.whenMatchedUpdateAll) method for converting any values in the _target_ table to `#!py timestamp(0)` when their value is actually `#!sql null`.</span>
<span class="sd">            - The history to this check is that when these data were originally added to BigDaS, the column `EditDate` did not exist.</span>
<span class="sd">            - Therefore, when they were first inserted, all the values in `EditDate` were `#!sql null`.</span>
<span class="sd">            - As time progressed, the records have slowly been updating, and therefore the `EditDate` values have been changing.</span>
<span class="sd">            - Due to nuances and semantics around how Spark handles `null` values, whenever this previous check was run including columns with values `#!sql null`, it would inevitably return `#!sql null`.</span>
<span class="sd">            - As such, these rows were not identified as able to be matched, therefore the optimiser skipped them.</span>
<span class="sd">            - However, we actually did want them to be matched; because the rows had actually been updated on the _source_ table.</span>
<span class="sd">            - Therefore, we add this `#!sql ifnull()` check to capture this edge case, and then push through and update the record on the _target_ table.</span>
<span class="sd">        1. The parameter `enable_automatic_schema_evolution` was added because it is possible for the upstream tables to be adding new columns as they evolve. Therefore, it is necessary for this function to handle schema evolution automatically.</span>

<span class="sd">    ??? question &quot;References&quot;</span>
<span class="sd">        - https://docs.databricks.com/delta/delta-update.html#language-python</span>
<span class="sd">        - https://docs.delta.io/latest/delta-update.html#upsert-into-a-table-using-merge&amp;language-python</span>
<span class="sd">        - https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaMergeBuilder</span>
<span class="sd">        - https://spark.apache.org/docs/3.0.0-preview/sql-ref-null-semantics.html</span>
<span class="sd">        - https://docs.delta.io/latest/delta-update.html#upsert-into-a-table-using-merge</span>

<span class="sd">    ??? tip &quot;See Also&quot;</span>
<span class="sd">        - [`merge_spark_to_delta()`][toolbox_pyspark.delta.merge_spark_to_delta]</span>
<span class="sd">        - [`load_table()`][toolbox_pyspark.delta.load_table]</span>
<span class="sd">        - [`assert_columns_exists()`][toolbox_pyspark.delta.assert_columns_exists]</span>
<span class="sd">        - [`get_columns()`][toolbox_pyspark.delta.get_columns]</span>
<span class="sd">        - [`SparkSession`](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.SparkSession.html)</span>
<span class="sd">        - [`SparkSession.sql()`](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.SparkSession.sql.html)</span>
<span class="sd">        - [`DeltaMergeBuilder`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaMergeBuilder)</span>
<span class="sd">        - [`DeltaTable`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable)</span>
<span class="sd">        - [`DeltaTable.history()`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable.history)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">from_table</span><span class="p">:</span> <span class="n">DeltaTable</span> <span class="o">=</span> <span class="n">load_table</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="n">from_table_name</span><span class="p">,</span>
        <span class="n">path</span><span class="o">=</span><span class="n">from_table_path</span><span class="p">,</span>
        <span class="n">spark_session</span><span class="o">=</span><span class="n">spark_session</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">merge_spark_to_delta</span><span class="p">(</span>
        <span class="n">from_table</span><span class="o">=</span><span class="n">from_table</span><span class="o">.</span><span class="n">toDF</span><span class="p">(),</span>
        <span class="n">to_table_name</span><span class="o">=</span><span class="n">to_table_name</span><span class="p">,</span>
        <span class="n">to_table_path</span><span class="o">=</span><span class="n">to_table_path</span><span class="p">,</span>
        <span class="n">matching_keys</span><span class="o">=</span><span class="n">matching_keys</span><span class="p">,</span>
        <span class="n">partition_keys</span><span class="o">=</span><span class="n">partition_keys</span><span class="p">,</span>
        <span class="n">editdate_col_name</span><span class="o">=</span><span class="n">editdate_col_name</span><span class="p">,</span>
        <span class="n">delete_unmatched_rows</span><span class="o">=</span><span class="n">delete_unmatched_rows</span><span class="p">,</span>
        <span class="n">enable_automatic_schema_evolution</span><span class="o">=</span><span class="n">enable_automatic_schema_evolution</span><span class="p">,</span>
        <span class="n">return_merge_metrics</span><span class="o">=</span><span class="n">return_merge_metrics</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>






<div class="doc doc-object doc-function">


<h4 id="toolbox_pyspark.delta.retry_merge_spark_to_delta" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <span class="doc doc-object-name doc-function-name">retry_merge_spark_to_delta</span>


<a href="#toolbox_pyspark.delta.retry_merge_spark_to_delta" class="headerlink" title="Permanent link">ðŸ”—</a></h4>
<div class="doc-signature highlight"><pre><span></span><code><span class="nf">retry_merge_spark_to_delta</span><span class="p">(</span>
    <span class="n">from_table</span><span class="p">:</span> <span class="n">psDataFrame</span><span class="p">,</span>
    <span class="n">to_table_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">to_table_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">matching_keys</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">str_collection</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">from_keys</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">str_collection</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">to_keys</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">str_collection</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">partition_keys</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">str_dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">editdate_col_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;editdate&quot;</span><span class="p">,</span>
    <span class="n">delete_unmatched_rows</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">enable_automatic_schema_evolution</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span>
        <span class="nb">bool</span>
    <span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">return_merge_metrics</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">retry_exceptions</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span>
        <span class="nb">type</span><span class="p">[</span><span class="ne">Exception</span><span class="p">],</span>
        <span class="nb">list</span><span class="p">[</span><span class="n">Type</span><span class="p">[</span><span class="ne">Exception</span><span class="p">]],</span>
        <span class="nb">tuple</span><span class="p">[</span><span class="n">Type</span><span class="p">[</span><span class="ne">Exception</span><span class="p">],</span> <span class="o">...</span><span class="p">],</span>
    <span class="p">]</span> <span class="o">=</span> <span class="ne">Exception</span><span class="p">,</span>
    <span class="n">retry_attempts</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">bool</span><span class="p">,</span> <span class="n">psDataFrame</span><span class="p">]</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <div class="admonition note">
<p class="admonition-title">Summary</p>
<p>Take one PySpark DataFrame <code>from_table</code>, and merge it with another DeltaTable at location: <code>to_table_path</code>/<code>to_table_name</code>.</p>
</div>
<details class="abstract" open="open">
<summary>Details</summary>
<p>This function is fundamentally the same as the <a class="autorefs autorefs-internal" href="#toolbox_pyspark.delta.merge_spark_to_delta"><code>merge_spark_to_delta()</code></a> function, except that it will automatically retry the merge function a number of times if it meets an error.</p>
<p>Particularly useful for when you are trying to run this optimisation over a cluster, and when parallelisaiton is causing multiple processes to occur over the same DeltaTable at the same time.</p>
<p>For more info on the Retry process, see: <a href="https://stamina.hynek.me/en/stable/"><code>stamina.retry()</code></a>.</p>
</details>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>from_table</code>
            </td>
            <td>
                  <code><span title="pyspark.sql.DataFrame">DataFrame</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The PySpark table. Data will be merged FROM here.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>to_table_name</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The name of the Delta table. Data will be merged TO here.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>to_table_path</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The location where the target Delta table can be found.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>matching_keys</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[List[str], str]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The list of matching columns between both the Spark table and the Delta table.<br>
If this is parsed in as a <code class="highlight"><span class="nb">str</span></code> type, then it will be coerced to a list like: <code>[matching_keys]</code>.<br>
If this is not provided, then BOTH the <code>from_keys</code> and the <code>to_keys</code> must be provided.<br>
Defaults to <code class="highlight"><span class="kc">None</span></code>.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>from_keys</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[List[str], str]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The list of keys on the <code>from_table</code> to use in the join.<br>
If this is parsed in as a <code class="highlight"><span class="nb">str</span></code> type, then it will be coerced to a list like: <code>[from_keys]</code>.<br>
Only necessary when <code>matching_keys</code> is <code class="highlight"><span class="kc">None</span></code>. When provided, the length must be the same as the <code>to_keys</code>.<br>
Defaults to <code class="highlight"><span class="kc">None</span></code>.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>to_keys</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[List[str], str]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The list of keys on the <code>to_table</code> to use in the join.<br>
If this is parsed in as a <code class="highlight"><span class="nb">str</span></code> type, then it will be coerced to a list like: <code>[to_keys]</code>.<br>
Only necessary when <code>matching_keys</code> is <code class="highlight"><span class="kc">None</span></code>. When provided, the length must be the same as the <code>from_keys</code>.<br>
Defaults to <code class="highlight"><span class="kc">None</span></code>.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>editdate_col_name</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[str]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The column to use for the <code>editdate</code> field, in case any table uses a different name for this field.<br>
If not provided (as in, the value <code class="highlight"><span class="kc">None</span></code> is parsed to this parameter), then this function will not implement any conditional logic during the <a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaMergeBuilder.whenMatchedUpdateAll"><code>.whenMatchedUpdateAll()</code></a> method.<br>
Defaults to <code class="highlight"><span class="s2">&quot;editdate&quot;</span></code>.</p>
              </div>
            </td>
            <td>
                  <code>&#39;editdate&#39;</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>delete_unmatched_rows</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[bool]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether or not to <strong>DELETE</strong> rows on the <em>target</em> table which are existing on the <em>target</em> but missing from the <em>source</em> tables.<br>
This should be used if you want to clean the target table and delete any rows which have already been deleted from the source table.<br>
If <code class="highlight"><span class="kc">True</span></code>, then this function will implement the method <a href="https://docs.delta.io/latest/api/python/spark/index.html#delta.tables.DeltaMergeBuilder.whenNotMatchedBySourceDelete"><code>.whenNoMatchedBySourceDelete()</code></a> method, with no conditionals.<br>
Defaults to <code class="highlight"><span class="kc">False</span></code>.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>enable_automatic_schema_evolution</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[bool]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Optional parameter for whether or not to automatically update the downstream <code>delta</code> table schema.<br>
As documented extensively elsewhere:</p>
<ul>
<li><a href="https://docs.delta.io/latest/delta-update.html#upsert-into-a-table-using-merge">https://docs.delta.io/latest/delta-update.html#upsert-into-a-table-using-merge</a></li>
<li><a href="https://www.databricks.com/blog/2019/09/24/diving-into-delta-lake-schema-enforcement-evolution.html">https://www.databricks.com/blog/2019/09/24/diving-into-delta-lake-schema-enforcement-evolution.html</a></li>
<li><a href="https://www.databricks.com/blog/2020/05/19/schema-evolution-in-merge-operations-and-operational-metrics-in-delta-lake.html">https://www.databricks.com/blog/2020/05/19/schema-evolution-in-merge-operations-and-operational-metrics-in-delta-lake.html</a></li>
<li><a href="https://towardsdatascience.com/delta-lake-automatic-schema-evolution-11d32bd1aa99">https://towardsdatascience.com/delta-lake-automatic-schema-evolution-11d32bd1aa99</a></li>
</ul>
<p>Defaults to <code class="highlight"><span class="kc">False</span></code>.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>return_merge_metrics</code>
            </td>
            <td>
                  <code><span title="typing.Optional">Optional</span>[bool]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Set to <code class="highlight"><span class="kc">True</span></code> if you want to return the Merge metrics from this function.<br>
If <code class="highlight"><span class="kc">False</span></code>, it will only return the value: <code class="highlight"><span class="kc">True</span></code>.<br>
Defaults to <code class="highlight"><span class="kc">False</span></code>.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>retry_exceptions</code>
            </td>
            <td>
                  <code><span title="typing.Union">Union</span>[<span title="typing.Type">Type</span>[Exception], List[<span title="typing.Type">Type</span>[Exception]], Tuple[<span title="typing.Type">Type</span>[Exception], ...]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A given single or collection of expected exceptions for which to catch and retry for.<br>
Defaults to <code class="highlight"><span class="ne">Exception</span></code>.</p>
              </div>
            </td>
            <td>
                  <code>Exception</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>retry_attempts</code>
            </td>
            <td>
                  <code>int</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The number of retries to attempt. If the underlying process is still failing after this number of attempts, then throw a hard error and alert the user.<br>
Defaults to <code class="highlight"><span class="mi">10</span></code>.</p>
              </div>
            </td>
            <td>
                  <code>10</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="typing.Union">Union</span>[bool, <span title="pyspark.sql.DataFrame">DataFrame</span>]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Will return either:</p>
<ul>
<li>If <code>return_merge_metrics</code> is <code class="highlight"><span class="kc">True</span></code>: Will return the Merge metrics, which is calculated by:<ol>
<li>Extracting the history from DeltaTable (at the <code>to_table_path</code> location),</li>
<li>Coercing that history object to a <code>pyspark</code> DataFrame,</li>
<li>Filtering to only extract the <code class="highlight"><span class="n">MERGE</span></code> operations,</li>
<li>Limiting to the top <code class="highlight"><span class="mi">1</span></code> lines, which is the most recent info.</li>
</ol>
</li>
<li>If <code>return_merge_metrics</code> is <code class="highlight"><span class="kc">False</span></code>: The value <code class="highlight"><span class="kc">True</span></code> is returned when the function runs successfully.</li>
</ul>
<p>If an error is thrown, then obviously it will not reach this far.
Unfortunately, the DeltaTable Merge process does not return any data or statistics from it's execution... So therefore, we need to use the DeltaTable history to fetch the metrics. For more info, see: <a href="https://github.com/delta-io/delta/issues/1361">Show key metrics after running <code>.merge(...)....execute()</code></a></p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Raises:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code>TypeError</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If any of the inputs parsed to the parameters of this function are not the correct type. Uses the <a href="https://typeguard.readthedocs.io/en/stable/api.html#typeguard.typechecked"><code>@typeguard.typechecked</code></a> decorator.</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code>AttributeError</code>
            </td>
            <td>
              <div class="doc-md-description">
                <ul>
<li>If any of <code>matching_keys</code> do not exist in the Spark table</li>
<li>If any of <code>matching_keys</code> do not exist in the Delta table</li>
<li>If any of <code>from_keys</code> do not exist in the Spark table</li>
<li>If any of <code>to_keys</code> do not exist in the Delta table</li>
</ul>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                  <code>AssertionError</code>
            </td>
            <td>
              <div class="doc-md-description">
                <ul>
<li>If <code>matching_keys</code> is None AND <code>from_keys</code> is None</li>
<li>If <code>matching_keys</code> is None AND <code>to_keys</code> is None</li>
<li>If length of <code>from_keys</code> does not match the length of <code>to_keys</code></li>
</ul>
              </div>
            </td>
          </tr>
      </tbody>
    </table>
        <details class="info" open="open">
<summary>Notes</summary>
<details class="info" open="open">
<summary>The main objective of this function is to:</summary>
<ol>
<li>For any records <em>existing</em> in Spark but <em>missing</em> in Delta, then INSERT those records from Spark to Delta. Using the <a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaMergeBuilder.whenNotMatchedInsertAll"><code>.whenNotMatchedInsertAll()</code></a> method.</li>
<li>For any records <em>existing</em> in both Spark and Delta, check if they have been <em>updated</em> in Spark and if so then UPDATE those matching records in the Delta. Using the <a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaMergeBuilder.whenMatchedUpdateAll"><code>.whenMatchedUpdateAll()</code></a> method.</li>
<li>Conditionally, check whether or not to actually apply #2 above by comparing the <code>editdate_col_name</code> field between the two tables.</li>
</ol>
</details>
<details class="info" open="open">
<summary>Pay particular attention to:</summary>
<ol>
<li>The <code>from_keys</code> and the <code>to_keys</code> will logically be the same values MOST of the time.<ul>
<li>Very rarely will they ever be different; however, they are added here as separate parameters to facilitate this future functionality.</li>
</ul>
</li>
<li>If <code>from_keys</code> and <code>to_keys</code> are type <code class="highlight"><span class="nb">list</span></code>, then their length must be the same.</li>
<li>Conditional logic is applied during the <a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaMergeBuilder.whenMatchedUpdateAll"><code>.whenMatchedUpdateAll()</code></a> method to avoid re-updating data in the Delta location which has actually updated from the SpSpark table.</li>
<li>There is an additional <code class="highlight"><span class="n">ifnull</span><span class="p">()</span></code> conditional check added to the <a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaMergeBuilder.whenMatchedUpdateAll"><code>.whenMatchedUpdateAll()</code></a> method for converting any values in the <em>target</em> table to <code class="highlight"><span class="n">timestamp</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span></code> when their value is actually <code class="highlight"><span class="k">null</span></code>.<ul>
<li>The history to this check is that when these data were originally added to BigDaS, the column <code>EditDate</code> did not exist.</li>
<li>Therefore, when they were first inserted, all the values in <code>EditDate</code> were <code class="highlight"><span class="k">null</span></code>.</li>
<li>As time progressed, the records have slowly been updating, and therefore the <code>EditDate</code> values have been changing.</li>
<li>Due to nuances and semantics around how Spark handles <code>null</code> values, whenever this previous check was run including columns with values <code class="highlight"><span class="k">null</span></code>, it would inevitably return <code class="highlight"><span class="k">null</span></code>.</li>
<li>As such, these rows were not identified as able to be matched, therefore the optimiser skipped them.</li>
<li>However, we actually did want them to be matched; because the rows had actually been updated on the <em>source</em> table.</li>
<li>Therefore, we add this <code class="highlight"><span class="n">ifnull</span><span class="p">()</span></code> check to capture this edge case, and then push through and update the record on the <em>target</em> table.</li>
</ul>
</li>
<li>The parameter <code>enable_automatic_schema_evolution</code> was added because it is possible for the upstream tables to be adding new columns as they evolve. Therefore, it is necessary for this function to handle schema evolution automatically.</li>
</ol>
</details>
</details>
<details class="question" open="open">
<summary>References</summary>
<ul>
<li><a href="https://docs.databricks.com/delta/delta-update.html#language-python">https://docs.databricks.com/delta/delta-update.html#language-python</a></li>
<li><a href="https://docs.delta.io/latest/delta-update.html#upsert-into-a-table-using-merge&amp;language-python">https://docs.delta.io/latest/delta-update.html#upsert-into-a-table-using-merge&amp;language-python</a></li>
<li><a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaMergeBuilder">https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaMergeBuilder</a></li>
<li><a href="https://spark.apache.org/docs/3.0.0-preview/sql-ref-null-semantics.html">https://spark.apache.org/docs/3.0.0-preview/sql-ref-null-semantics.html</a></li>
<li><a href="https://docs.delta.io/latest/delta-update.html#upsert-into-a-table-using-merge">https://docs.delta.io/latest/delta-update.html#upsert-into-a-table-using-merge</a></li>
</ul>
</details>
<details class="tip" open="open">
<summary>See also</summary>
<ul>
<li><a href="https://stamina.hynek.me/en/stable/"><code>stamina.retry()</code></a></li>
<li><a class="autorefs autorefs-internal" href="#toolbox_pyspark.delta.merge_spark_to_delta"><code>merge_spark_to_delta()</code></a></li>
<li><a class="autorefs autorefs-internal" href="#toolbox_pyspark.delta.load_table"><code>load_table()</code></a></li>
<li><a class="autorefs autorefs-internal" href="../checks/#toolbox_pyspark.checks.assert_columns_exists"><code>assert_columns_exists()</code></a></li>
<li><a class="autorefs autorefs-internal" href="../columns/#toolbox_pyspark.columns.get_columns"><code>get_columns()</code></a></li>
<li><a href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.SparkSession.html"><code>SparkSession</code></a></li>
<li><a href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.SparkSession.sql.html"><code>SparkSession.sql()</code></a></li>
<li><a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaMergeBuilder"><code>DeltaMergeBuilder</code></a></li>
<li><a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable"><code>DeltaTable</code></a></li>
<li><a href="https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable.history"><code>DeltaTable.history()</code></a></li>
</ul>
</details>

            <details class="quote">
              <summary>Source code in <code>src/toolbox_pyspark/delta.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1080</span>
<span class="normal">1081</span>
<span class="normal">1082</span>
<span class="normal">1083</span>
<span class="normal">1084</span>
<span class="normal">1085</span>
<span class="normal">1086</span>
<span class="normal">1087</span>
<span class="normal">1088</span>
<span class="normal">1089</span>
<span class="normal">1090</span>
<span class="normal">1091</span>
<span class="normal">1092</span>
<span class="normal">1093</span>
<span class="normal">1094</span>
<span class="normal">1095</span>
<span class="normal">1096</span>
<span class="normal">1097</span>
<span class="normal">1098</span>
<span class="normal">1099</span>
<span class="normal">1100</span>
<span class="normal">1101</span>
<span class="normal">1102</span>
<span class="normal">1103</span>
<span class="normal">1104</span>
<span class="normal">1105</span>
<span class="normal">1106</span>
<span class="normal">1107</span>
<span class="normal">1108</span>
<span class="normal">1109</span>
<span class="normal">1110</span>
<span class="normal">1111</span>
<span class="normal">1112</span>
<span class="normal">1113</span>
<span class="normal">1114</span>
<span class="normal">1115</span>
<span class="normal">1116</span>
<span class="normal">1117</span>
<span class="normal">1118</span>
<span class="normal">1119</span>
<span class="normal">1120</span>
<span class="normal">1121</span>
<span class="normal">1122</span>
<span class="normal">1123</span>
<span class="normal">1124</span>
<span class="normal">1125</span>
<span class="normal">1126</span>
<span class="normal">1127</span>
<span class="normal">1128</span>
<span class="normal">1129</span>
<span class="normal">1130</span>
<span class="normal">1131</span>
<span class="normal">1132</span>
<span class="normal">1133</span>
<span class="normal">1134</span>
<span class="normal">1135</span>
<span class="normal">1136</span>
<span class="normal">1137</span>
<span class="normal">1138</span>
<span class="normal">1139</span>
<span class="normal">1140</span>
<span class="normal">1141</span>
<span class="normal">1142</span>
<span class="normal">1143</span>
<span class="normal">1144</span>
<span class="normal">1145</span>
<span class="normal">1146</span>
<span class="normal">1147</span>
<span class="normal">1148</span>
<span class="normal">1149</span>
<span class="normal">1150</span>
<span class="normal">1151</span>
<span class="normal">1152</span>
<span class="normal">1153</span>
<span class="normal">1154</span>
<span class="normal">1155</span>
<span class="normal">1156</span>
<span class="normal">1157</span>
<span class="normal">1158</span>
<span class="normal">1159</span>
<span class="normal">1160</span>
<span class="normal">1161</span>
<span class="normal">1162</span>
<span class="normal">1163</span>
<span class="normal">1164</span>
<span class="normal">1165</span>
<span class="normal">1166</span>
<span class="normal">1167</span>
<span class="normal">1168</span>
<span class="normal">1169</span>
<span class="normal">1170</span>
<span class="normal">1171</span>
<span class="normal">1172</span>
<span class="normal">1173</span>
<span class="normal">1174</span>
<span class="normal">1175</span>
<span class="normal">1176</span>
<span class="normal">1177</span>
<span class="normal">1178</span>
<span class="normal">1179</span>
<span class="normal">1180</span>
<span class="normal">1181</span>
<span class="normal">1182</span>
<span class="normal">1183</span>
<span class="normal">1184</span>
<span class="normal">1185</span>
<span class="normal">1186</span>
<span class="normal">1187</span>
<span class="normal">1188</span>
<span class="normal">1189</span>
<span class="normal">1190</span>
<span class="normal">1191</span>
<span class="normal">1192</span>
<span class="normal">1193</span>
<span class="normal">1194</span>
<span class="normal">1195</span>
<span class="normal">1196</span>
<span class="normal">1197</span>
<span class="normal">1198</span>
<span class="normal">1199</span>
<span class="normal">1200</span>
<span class="normal">1201</span>
<span class="normal">1202</span>
<span class="normal">1203</span>
<span class="normal">1204</span>
<span class="normal">1205</span>
<span class="normal">1206</span>
<span class="normal">1207</span>
<span class="normal">1208</span>
<span class="normal">1209</span>
<span class="normal">1210</span>
<span class="normal">1211</span>
<span class="normal">1212</span>
<span class="normal">1213</span>
<span class="normal">1214</span>
<span class="normal">1215</span>
<span class="normal">1216</span>
<span class="normal">1217</span>
<span class="normal">1218</span>
<span class="normal">1219</span>
<span class="normal">1220</span>
<span class="normal">1221</span>
<span class="normal">1222</span>
<span class="normal">1223</span>
<span class="normal">1224</span>
<span class="normal">1225</span>
<span class="normal">1226</span>
<span class="normal">1227</span>
<span class="normal">1228</span>
<span class="normal">1229</span>
<span class="normal">1230</span>
<span class="normal">1231</span>
<span class="normal">1232</span>
<span class="normal">1233</span>
<span class="normal">1234</span>
<span class="normal">1235</span>
<span class="normal">1236</span>
<span class="normal">1237</span>
<span class="normal">1238</span>
<span class="normal">1239</span>
<span class="normal">1240</span>
<span class="normal">1241</span>
<span class="normal">1242</span>
<span class="normal">1243</span>
<span class="normal">1244</span>
<span class="normal">1245</span>
<span class="normal">1246</span>
<span class="normal">1247</span>
<span class="normal">1248</span>
<span class="normal">1249</span>
<span class="normal">1250</span>
<span class="normal">1251</span>
<span class="normal">1252</span>
<span class="normal">1253</span>
<span class="normal">1254</span>
<span class="normal">1255</span>
<span class="normal">1256</span>
<span class="normal">1257</span>
<span class="normal">1258</span>
<span class="normal">1259</span>
<span class="normal">1260</span>
<span class="normal">1261</span>
<span class="normal">1262</span>
<span class="normal">1263</span>
<span class="normal">1264</span>
<span class="normal">1265</span>
<span class="normal">1266</span>
<span class="normal">1267</span>
<span class="normal">1268</span>
<span class="normal">1269</span>
<span class="normal">1270</span>
<span class="normal">1271</span>
<span class="normal">1272</span>
<span class="normal">1273</span>
<span class="normal">1274</span>
<span class="normal">1275</span>
<span class="normal">1276</span>
<span class="normal">1277</span>
<span class="normal">1278</span>
<span class="normal">1279</span>
<span class="normal">1280</span>
<span class="normal">1281</span>
<span class="normal">1282</span>
<span class="normal">1283</span>
<span class="normal">1284</span>
<span class="normal">1285</span>
<span class="normal">1286</span>
<span class="normal">1287</span>
<span class="normal">1288</span>
<span class="normal">1289</span>
<span class="normal">1290</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">retry_merge_spark_to_delta</span><span class="p">(</span>
    <span class="n">from_table</span><span class="p">:</span> <span class="n">psDataFrame</span><span class="p">,</span>
    <span class="n">to_table_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">to_table_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">matching_keys</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">str_collection</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">from_keys</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">str_collection</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">to_keys</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">str_collection</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">partition_keys</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">str_dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">editdate_col_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;editdate&quot;</span><span class="p">,</span>
    <span class="n">delete_unmatched_rows</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">enable_automatic_schema_evolution</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">return_merge_metrics</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">retry_exceptions</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span>
        <span class="nb">type</span><span class="p">[</span><span class="ne">Exception</span><span class="p">],</span>
        <span class="nb">list</span><span class="p">[</span><span class="n">Type</span><span class="p">[</span><span class="ne">Exception</span><span class="p">]],</span>
        <span class="nb">tuple</span><span class="p">[</span><span class="n">Type</span><span class="p">[</span><span class="ne">Exception</span><span class="p">],</span> <span class="o">...</span><span class="p">],</span>
    <span class="p">]</span> <span class="o">=</span> <span class="ne">Exception</span><span class="p">,</span>
    <span class="n">retry_attempts</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">bool</span><span class="p">,</span> <span class="n">psDataFrame</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    !!! note &quot;Summary&quot;</span>

<span class="sd">        Take one PySpark DataFrame `from_table`, and merge it with another DeltaTable at location: `to_table_path`/`to_table_name`.</span>

<span class="sd">    ???+ abstract &quot;Details&quot;</span>

<span class="sd">        This function is fundamentally the same as the [`merge_spark_to_delta()`][toolbox_pyspark.delta.merge_spark_to_delta] function, except that it will automatically retry the merge function a number of times if it meets an error.</span>

<span class="sd">        Particularly useful for when you are trying to run this optimisation over a cluster, and when parallelisaiton is causing multiple processes to occur over the same DeltaTable at the same time.</span>

<span class="sd">        For more info on the Retry process, see: [`stamina.retry()`](https://stamina.hynek.me/en/stable/).</span>

<span class="sd">    Params:</span>
<span class="sd">        from_table (psDataFrame):</span>
<span class="sd">            The PySpark table. Data will be merged FROM here.</span>

<span class="sd">        to_table_name (str):</span>
<span class="sd">            The name of the Delta table. Data will be merged TO here.</span>

<span class="sd">        to_table_path (str):</span>
<span class="sd">            The location where the target Delta table can be found.</span>

<span class="sd">        matching_keys (Union[List[str], str], optional):</span>
<span class="sd">            The list of matching columns between both the Spark table and the Delta table.&lt;br&gt;</span>
<span class="sd">            If this is parsed in as a `#!py str` type, then it will be coerced to a list like: `[matching_keys]`.&lt;br&gt;</span>
<span class="sd">            If this is not provided, then BOTH the `from_keys` and the `to_keys` must be provided.&lt;br&gt;</span>
<span class="sd">            Defaults to `#!py None`.</span>

<span class="sd">        from_keys (Union[List[str], str], optional):</span>
<span class="sd">            The list of keys on the `from_table` to use in the join.&lt;br&gt;</span>
<span class="sd">            If this is parsed in as a `#!py str` type, then it will be coerced to a list like: `[from_keys]`.&lt;br&gt;</span>
<span class="sd">            Only necessary when `matching_keys` is `#!py None`. When provided, the length must be the same as the `to_keys`.&lt;br&gt;</span>
<span class="sd">            Defaults to `#!py None`.</span>

<span class="sd">        to_keys (Union[List[str], str], optional):</span>
<span class="sd">            The list of keys on the `to_table` to use in the join.&lt;br&gt;</span>
<span class="sd">            If this is parsed in as a `#!py str` type, then it will be coerced to a list like: `[to_keys]`.&lt;br&gt;</span>
<span class="sd">            Only necessary when `matching_keys` is `#!py None`. When provided, the length must be the same as the `from_keys`.&lt;br&gt;</span>
<span class="sd">            Defaults to `#!py None`.</span>

<span class="sd">        editdate_col_name (Optional[str], optional):</span>
<span class="sd">            The column to use for the `editdate` field, in case any table uses a different name for this field.&lt;br&gt;</span>
<span class="sd">            If not provided (as in, the value `#!py None` is parsed to this parameter), then this function will not implement any conditional logic during the [`.whenMatchedUpdateAll()`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaMergeBuilder.whenMatchedUpdateAll) method.&lt;br&gt;</span>
<span class="sd">            Defaults to `#!py &quot;editdate&quot;`.</span>

<span class="sd">        delete_unmatched_rows (Optional[bool], optional):</span>
<span class="sd">            Whether or not to **DELETE** rows on the _target_ table which are existing on the _target_ but missing from the _source_ tables.&lt;br&gt;</span>
<span class="sd">            This should be used if you want to clean the target table and delete any rows which have already been deleted from the source table.&lt;br&gt;</span>
<span class="sd">            If `#!py True`, then this function will implement the method [`.whenNoMatchedBySourceDelete()`](https://docs.delta.io/latest/api/python/spark/index.html#delta.tables.DeltaMergeBuilder.whenNotMatchedBySourceDelete) method, with no conditionals.&lt;br&gt;</span>
<span class="sd">            Defaults to `#!py False`.</span>

<span class="sd">        enable_automatic_schema_evolution (Optional[bool], optional):</span>
<span class="sd">            Optional parameter for whether or not to automatically update the downstream `delta` table schema.&lt;br&gt;</span>
<span class="sd">            As documented extensively elsewhere:</span>

<span class="sd">            - https://docs.delta.io/latest/delta-update.html#upsert-into-a-table-using-merge</span>
<span class="sd">            - https://www.databricks.com/blog/2019/09/24/diving-into-delta-lake-schema-enforcement-evolution.html</span>
<span class="sd">            - https://www.databricks.com/blog/2020/05/19/schema-evolution-in-merge-operations-and-operational-metrics-in-delta-lake.html</span>
<span class="sd">            - https://towardsdatascience.com/delta-lake-automatic-schema-evolution-11d32bd1aa99</span>

<span class="sd">            Defaults to `#!py False`.</span>

<span class="sd">        return_merge_metrics (Optional[bool], optional):</span>
<span class="sd">            Set to `#!py True` if you want to return the Merge metrics from this function.&lt;br&gt;</span>
<span class="sd">            If `#!py False`, it will only return the value: `#!py True`.&lt;br&gt;</span>
<span class="sd">            Defaults to `#!py False`.</span>

<span class="sd">        retry_exceptions (Union[ Type[Exception], List[Type[Exception]], Tuple[Type[Exception], ...], ], optional):</span>
<span class="sd">            A given single or collection of expected exceptions for which to catch and retry for.&lt;br&gt;</span>
<span class="sd">            Defaults to `#!py Exception`.</span>

<span class="sd">        retry_attempts (int, optional):</span>
<span class="sd">            The number of retries to attempt. If the underlying process is still failing after this number of attempts, then throw a hard error and alert the user.&lt;br&gt;</span>
<span class="sd">            Defaults to `#!py 10`.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (Union[bool, psDataFrame]):</span>
<span class="sd">            Will return either:</span>

<span class="sd">            - If `return_merge_metrics` is `#!py True`: Will return the Merge metrics, which is calculated by:</span>
<span class="sd">                1. Extracting the history from DeltaTable (at the `to_table_path` location),</span>
<span class="sd">                1. Coercing that history object to a `pyspark` DataFrame,</span>
<span class="sd">                1. Filtering to only extract the `#!sql MERGE` operations,</span>
<span class="sd">                1. Limiting to the top `#!py 1` lines, which is the most recent info.</span>
<span class="sd">            - If `return_merge_metrics` is `#!py False`: The value `#!py True` is returned when the function runs successfully.</span>

<span class="sd">            If an error is thrown, then obviously it will not reach this far.</span>
<span class="sd">            Unfortunately, the DeltaTable Merge process does not return any data or statistics from it&#39;s execution... So therefore, we need to use the DeltaTable history to fetch the metrics. For more info, see: [Show key metrics after running `.merge(...)....execute()`](https://github.com/delta-io/delta/issues/1361)</span>

<span class="sd">    Raises:</span>
<span class="sd">        TypeError:</span>
<span class="sd">            If any of the inputs parsed to the parameters of this function are not the correct type. Uses the [`@typeguard.typechecked`](https://typeguard.readthedocs.io/en/stable/api.html#typeguard.typechecked) decorator.</span>
<span class="sd">        AttributeError:</span>
<span class="sd">            - If any of `matching_keys` do not exist in the Spark table</span>
<span class="sd">            - If any of `matching_keys` do not exist in the Delta table</span>
<span class="sd">            - If any of `from_keys` do not exist in the Spark table</span>
<span class="sd">            - If any of `to_keys` do not exist in the Delta table</span>
<span class="sd">        AssertionError:</span>
<span class="sd">            - If `matching_keys` is None AND `from_keys` is None</span>
<span class="sd">            - If `matching_keys` is None AND `to_keys` is None</span>
<span class="sd">            - If length of `from_keys` does not match the length of `to_keys`</span>

<span class="sd">    ???+ info &quot;Notes&quot;</span>

<span class="sd">        ???+ info &quot;The main objective of this function is to:&quot;</span>

<span class="sd">            1. For any records _existing_ in Spark but _missing_ in Delta, then INSERT those records from Spark to Delta. Using the [`.whenNotMatchedInsertAll()`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaMergeBuilder.whenNotMatchedInsertAll) method.</span>
<span class="sd">            1. For any records _existing_ in both Spark and Delta, check if they have been _updated_ in Spark and if so then UPDATE those matching records in the Delta. Using the [`.whenMatchedUpdateAll()`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaMergeBuilder.whenMatchedUpdateAll) method.</span>
<span class="sd">            1. Conditionally, check whether or not to actually apply #2 above by comparing the `editdate_col_name` field between the two tables.</span>

<span class="sd">        ???+ info &quot;Pay particular attention to:&quot;</span>

<span class="sd">            1. The `from_keys` and the `to_keys` will logically be the same values MOST of the time.</span>
<span class="sd">                - Very rarely will they ever be different; however, they are added here as separate parameters to facilitate this future functionality.</span>
<span class="sd">            1. If `from_keys` and `to_keys` are type `#!py list`, then their length must be the same.</span>
<span class="sd">            1. Conditional logic is applied during the [`.whenMatchedUpdateAll()`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaMergeBuilder.whenMatchedUpdateAll) method to avoid re-updating data in the Delta location which has actually updated from the SpSpark table.</span>
<span class="sd">            1. There is an additional `#!sql ifnull()` conditional check added to the [`.whenMatchedUpdateAll()`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaMergeBuilder.whenMatchedUpdateAll) method for converting any values in the _target_ table to `#!py timestamp(0)` when their value is actually `#!sql null`.</span>
<span class="sd">                - The history to this check is that when these data were originally added to BigDaS, the column `EditDate` did not exist.</span>
<span class="sd">                - Therefore, when they were first inserted, all the values in `EditDate` were `#!sql null`.</span>
<span class="sd">                - As time progressed, the records have slowly been updating, and therefore the `EditDate` values have been changing.</span>
<span class="sd">                - Due to nuances and semantics around how Spark handles `null` values, whenever this previous check was run including columns with values `#!sql null`, it would inevitably return `#!sql null`.</span>
<span class="sd">                - As such, these rows were not identified as able to be matched, therefore the optimiser skipped them.</span>
<span class="sd">                - However, we actually did want them to be matched; because the rows had actually been updated on the _source_ table.</span>
<span class="sd">                - Therefore, we add this `#!sql ifnull()` check to capture this edge case, and then push through and update the record on the _target_ table.</span>
<span class="sd">            1. The parameter `enable_automatic_schema_evolution` was added because it is possible for the upstream tables to be adding new columns as they evolve. Therefore, it is necessary for this function to handle schema evolution automatically.</span>

<span class="sd">    ???+ question &quot;References&quot;</span>
<span class="sd">        - https://docs.databricks.com/delta/delta-update.html#language-python</span>
<span class="sd">        - https://docs.delta.io/latest/delta-update.html#upsert-into-a-table-using-merge&amp;language-python</span>
<span class="sd">        - https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaMergeBuilder</span>
<span class="sd">        - https://spark.apache.org/docs/3.0.0-preview/sql-ref-null-semantics.html</span>
<span class="sd">        - https://docs.delta.io/latest/delta-update.html#upsert-into-a-table-using-merge</span>

<span class="sd">    ???+ tip &quot;See also&quot;</span>
<span class="sd">        - [`stamina.retry()`](https://stamina.hynek.me/en/stable/)</span>
<span class="sd">        - [`merge_spark_to_delta()`][toolbox_pyspark.delta.merge_spark_to_delta]</span>
<span class="sd">        - [`load_table()`][toolbox_pyspark.delta.load_table]</span>
<span class="sd">        - [`assert_columns_exists()`][toolbox_pyspark.delta.assert_columns_exists]</span>
<span class="sd">        - [`get_columns()`][toolbox_pyspark.delta.get_columns]</span>
<span class="sd">        - [`SparkSession`](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.SparkSession.html)</span>
<span class="sd">        - [`SparkSession.sql()`](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.SparkSession.sql.html)</span>
<span class="sd">        - [`DeltaMergeBuilder`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaMergeBuilder)</span>
<span class="sd">        - [`DeltaTable`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable)</span>
<span class="sd">        - [`DeltaTable.history()`](https://docs.delta.io/latest/api/python/index.html#delta.tables.DeltaTable.history)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@retry</span><span class="p">(</span>
        <span class="n">on</span><span class="o">=</span><span class="p">((</span><span class="o">*</span><span class="n">retry_exceptions</span><span class="p">,)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">retry_exceptions</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="k">else</span> <span class="n">retry_exceptions</span><span class="p">),</span>
        <span class="n">attempts</span><span class="o">=</span><span class="n">retry_attempts</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="nd">@typechecked</span>
    <span class="k">def</span> <span class="nf">_retry_merge_spark_to_delta</span><span class="p">(</span>
        <span class="n">from_table</span><span class="p">:</span> <span class="n">psDataFrame</span><span class="p">,</span>
        <span class="n">to_table_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">to_table_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">matching_keys</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">str_collection</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">from_keys</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">str_collection</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">to_keys</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">str_collection</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">partition_keys</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">str_dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">editdate_col_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;editdate&quot;</span><span class="p">,</span>
        <span class="n">delete_unmatched_rows</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">enable_automatic_schema_evolution</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">return_merge_metrics</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">bool</span><span class="p">,</span> <span class="n">psDataFrame</span><span class="p">]:</span>
        <span class="k">return</span> <span class="n">merge_spark_to_delta</span><span class="p">(</span>
            <span class="n">from_table</span><span class="o">=</span><span class="n">from_table</span><span class="p">,</span>
            <span class="n">to_table_name</span><span class="o">=</span><span class="n">to_table_name</span><span class="p">,</span>
            <span class="n">to_table_path</span><span class="o">=</span><span class="n">to_table_path</span><span class="p">,</span>
            <span class="n">matching_keys</span><span class="o">=</span><span class="n">matching_keys</span><span class="p">,</span>
            <span class="n">from_keys</span><span class="o">=</span><span class="n">from_keys</span><span class="p">,</span>
            <span class="n">to_keys</span><span class="o">=</span><span class="n">to_keys</span><span class="p">,</span>
            <span class="n">partition_keys</span><span class="o">=</span><span class="n">partition_keys</span><span class="p">,</span>
            <span class="n">editdate_col_name</span><span class="o">=</span><span class="n">editdate_col_name</span><span class="p">,</span>
            <span class="n">delete_unmatched_rows</span><span class="o">=</span><span class="n">delete_unmatched_rows</span><span class="p">,</span>
            <span class="n">enable_automatic_schema_evolution</span><span class="o">=</span><span class="n">enable_automatic_schema_evolution</span><span class="p">,</span>
            <span class="n">return_merge_metrics</span><span class="o">=</span><span class="n">return_merge_metrics</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">return</span> <span class="n">_retry_merge_spark_to_delta</span><span class="p">(</span>
        <span class="n">from_table</span><span class="o">=</span><span class="n">from_table</span><span class="p">,</span>
        <span class="n">to_table_name</span><span class="o">=</span><span class="n">to_table_name</span><span class="p">,</span>
        <span class="n">to_table_path</span><span class="o">=</span><span class="n">to_table_path</span><span class="p">,</span>
        <span class="n">matching_keys</span><span class="o">=</span><span class="n">matching_keys</span><span class="p">,</span>
        <span class="n">from_keys</span><span class="o">=</span><span class="n">from_keys</span><span class="p">,</span>
        <span class="n">to_keys</span><span class="o">=</span><span class="n">to_keys</span><span class="p">,</span>
        <span class="n">partition_keys</span><span class="o">=</span><span class="n">partition_keys</span><span class="p">,</span>
        <span class="n">editdate_col_name</span><span class="o">=</span><span class="n">editdate_col_name</span><span class="p">,</span>
        <span class="n">delete_unmatched_rows</span><span class="o">=</span><span class="n">delete_unmatched_rows</span><span class="p">,</span>
        <span class="n">enable_automatic_schema_evolution</span><span class="o">=</span><span class="n">enable_automatic_schema_evolution</span><span class="p">,</span>
        <span class="n">return_merge_metrics</span><span class="o">=</span><span class="n">return_merge_metrics</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>






<div class="doc doc-object doc-class">



<h4 id="toolbox_pyspark.delta.DeltaLoader" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <span class="doc doc-object-name doc-class-name">DeltaLoader</span>


<a href="#toolbox_pyspark.delta.DeltaLoader" class="headerlink" title="Permanent link">ðŸ”—</a></h4>


    <div class="doc doc-contents ">


        <div class="admonition note">
<p class="admonition-title">Summary</p>
<p>A class to load and inspect Delta Lake tables from a specified root directory.</p>
</div>
<details class="abstract" open="open">
<summary>Details</summary>
<p>The <code>DeltaLoader</code> class provides methods to load Delta Lake tables from a specified root directory and inspect the contents of these tables. It uses the <code>dbutils</code> library if available to list folders, otherwise it falls back to using the <code>os</code> library.</p>
</details>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>root</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The root directory where the Delta Lake tables are stored.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>spark</code>
            </td>
            <td>
                  <code><span title="pyspark.sql.SparkSession">SparkSession</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The Spark session to use for loading the Delta Lake tables.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>dbutils</code>
            </td>
            <td>
                  <code>optional</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The <code>dbutils</code> library to use for listing folders. If not provided, the <code>os</code> library will be used.<br>
Defaults to <code>None</code>.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


<p><span class="doc-section-title">Methods:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
            <tr class="doc-section-item">
              <td><code><a class="autorefs autorefs-internal" title="toolbox_pyspark.delta.DeltaLoader.load" href="#toolbox_pyspark.delta.DeltaLoader.load">load</a></code></td>
              <td>
                <div class="doc-md-description">
                  <p>str) -&gt; psDataFrame:
Load a Delta Lake table from the specified folder.</p>
                </div>
              </td>
            </tr>
            <tr class="doc-section-item">
              <td><code><a class="autorefs autorefs-internal" title="toolbox_pyspark.delta.DeltaLoader.folders" href="#toolbox_pyspark.delta.DeltaLoader.folders">folders</a></code></td>
              <td>
                <div class="doc-md-description">
                  <p>List the folders in the root directory.</p>
                </div>
              </td>
            </tr>
            <tr class="doc-section-item">
              <td><code><a class="autorefs autorefs-internal" title="toolbox_pyspark.delta.DeltaLoader.inspect" href="#toolbox_pyspark.delta.DeltaLoader.inspect">inspect</a></code></td>
              <td>
                <div class="doc-md-description">
                  <p>Inspect the Delta Lake tables in the root directory and return a DataFrame with information about each table.</p>
                </div>
              </td>
            </tr>
      </tbody>
    </table>
        <details class="example" open="open">
<summary>Examples</summary>
<div class="python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Set up</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span>
<span class="normal">6</span>
<span class="normal">7</span>
<span class="normal">8</span>
<span class="normal">9</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="c1"># Imports</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">toolbox_pyspark.delta</span> <span class="kn">import</span> <span class="n">DeltaLoader</span>
<span class="o">&gt;&gt;&gt;</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># Instantiate Spark</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="o">.</span><span class="n">builder</span><span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># Create DeltaLoader instance</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">delta_loader</span> <span class="o">=</span> <span class="n">DeltaLoader</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s2">&quot;/path/to/delta/tables&quot;</span><span class="p">,</span> <span class="n">spark</span><span class="o">=</span><span class="n">spark</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<p><div class="python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Example 1: Load a table</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">df</span> <span class="o">=</span> <span class="n">delta_loader</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;folder_name&quot;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">df</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
<div class="result" markdown>
<div class="text highlight"><span class="filename">Terminal</span><pre><span></span><code>+---+---+---+
| a | b | c |
+---+---+---+
| 1 | 2 | 3 |
| 4 | 5 | 6 |
+---+---+---+
</code></pre></div></p>
<div class="admonition success">
<p class="admonition-title">Conclusion: Successfully loaded the table from the specified folder.</p>
</div>
</div>
<p><div class="python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Example 2: List folders</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">folders</span> <span class="o">=</span> <span class="n">delta_loader</span><span class="o">.</span><span class="n">folders</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">folders</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<div class="result" markdown>
<div class="text highlight"><span class="filename">Terminal</span><pre><span></span><code>[&#39;folder1&#39;, &#39;folder2&#39;, &#39;folder3&#39;]
</code></pre></div></p>
<div class="admonition success">
<p class="admonition-title">Conclusion: Successfully listed the folders in the root directory.</p>
</div>
</div>
<p><div class="python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Example 3: Inspect tables</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">inspection_df</span> <span class="o">=</span> <span class="n">delta_loader</span><span class="o">.</span><span class="n">inspect</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">inspection_df</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
<div class="result" markdown>
<div class="text highlight"><span class="filename">Terminal</span><pre><span></span><code>+---------+-------------+---------------------+-------+
| Folder  | TimeElement | TimeStamp           | Count |
+---------+-------------+---------------------+-------+
| folder1 | EDITDATE    | 2023-01-01 00:00:00 |   100 |
| folder2 | ADDDATE     | 2023-01-02 00:00:00 |   200 |
| folder3 | None        | None                |   300 |
+---------+-------------+---------------------+-------+
</code></pre></div></p>
<div class="admonition success">
<p class="admonition-title">Conclusion: Successfully inspected the Delta Lake tables.</p>
</div>
</div>
</details>






              <details class="quote">
                <summary>Source code in <code>src/toolbox_pyspark/delta.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1305</span>
<span class="normal">1306</span>
<span class="normal">1307</span>
<span class="normal">1308</span>
<span class="normal">1309</span>
<span class="normal">1310</span>
<span class="normal">1311</span>
<span class="normal">1312</span>
<span class="normal">1313</span>
<span class="normal">1314</span>
<span class="normal">1315</span>
<span class="normal">1316</span>
<span class="normal">1317</span>
<span class="normal">1318</span>
<span class="normal">1319</span>
<span class="normal">1320</span>
<span class="normal">1321</span>
<span class="normal">1322</span>
<span class="normal">1323</span>
<span class="normal">1324</span>
<span class="normal">1325</span>
<span class="normal">1326</span>
<span class="normal">1327</span>
<span class="normal">1328</span>
<span class="normal">1329</span>
<span class="normal">1330</span>
<span class="normal">1331</span>
<span class="normal">1332</span>
<span class="normal">1333</span>
<span class="normal">1334</span>
<span class="normal">1335</span>
<span class="normal">1336</span>
<span class="normal">1337</span>
<span class="normal">1338</span>
<span class="normal">1339</span>
<span class="normal">1340</span>
<span class="normal">1341</span>
<span class="normal">1342</span>
<span class="normal">1343</span>
<span class="normal">1344</span>
<span class="normal">1345</span>
<span class="normal">1346</span>
<span class="normal">1347</span>
<span class="normal">1348</span>
<span class="normal">1349</span>
<span class="normal">1350</span>
<span class="normal">1351</span>
<span class="normal">1352</span>
<span class="normal">1353</span>
<span class="normal">1354</span>
<span class="normal">1355</span>
<span class="normal">1356</span>
<span class="normal">1357</span>
<span class="normal">1358</span>
<span class="normal">1359</span>
<span class="normal">1360</span>
<span class="normal">1361</span>
<span class="normal">1362</span>
<span class="normal">1363</span>
<span class="normal">1364</span>
<span class="normal">1365</span>
<span class="normal">1366</span>
<span class="normal">1367</span>
<span class="normal">1368</span>
<span class="normal">1369</span>
<span class="normal">1370</span>
<span class="normal">1371</span>
<span class="normal">1372</span>
<span class="normal">1373</span>
<span class="normal">1374</span>
<span class="normal">1375</span>
<span class="normal">1376</span>
<span class="normal">1377</span>
<span class="normal">1378</span>
<span class="normal">1379</span>
<span class="normal">1380</span>
<span class="normal">1381</span>
<span class="normal">1382</span>
<span class="normal">1383</span>
<span class="normal">1384</span>
<span class="normal">1385</span>
<span class="normal">1386</span>
<span class="normal">1387</span>
<span class="normal">1388</span>
<span class="normal">1389</span>
<span class="normal">1390</span>
<span class="normal">1391</span>
<span class="normal">1392</span>
<span class="normal">1393</span>
<span class="normal">1394</span>
<span class="normal">1395</span>
<span class="normal">1396</span>
<span class="normal">1397</span>
<span class="normal">1398</span>
<span class="normal">1399</span>
<span class="normal">1400</span>
<span class="normal">1401</span>
<span class="normal">1402</span>
<span class="normal">1403</span>
<span class="normal">1404</span>
<span class="normal">1405</span>
<span class="normal">1406</span>
<span class="normal">1407</span>
<span class="normal">1408</span>
<span class="normal">1409</span>
<span class="normal">1410</span>
<span class="normal">1411</span>
<span class="normal">1412</span>
<span class="normal">1413</span>
<span class="normal">1414</span>
<span class="normal">1415</span>
<span class="normal">1416</span>
<span class="normal">1417</span>
<span class="normal">1418</span>
<span class="normal">1419</span>
<span class="normal">1420</span>
<span class="normal">1421</span>
<span class="normal">1422</span>
<span class="normal">1423</span>
<span class="normal">1424</span>
<span class="normal">1425</span>
<span class="normal">1426</span>
<span class="normal">1427</span>
<span class="normal">1428</span>
<span class="normal">1429</span>
<span class="normal">1430</span>
<span class="normal">1431</span>
<span class="normal">1432</span>
<span class="normal">1433</span>
<span class="normal">1434</span>
<span class="normal">1435</span>
<span class="normal">1436</span>
<span class="normal">1437</span>
<span class="normal">1438</span>
<span class="normal">1439</span>
<span class="normal">1440</span>
<span class="normal">1441</span>
<span class="normal">1442</span>
<span class="normal">1443</span>
<span class="normal">1444</span>
<span class="normal">1445</span>
<span class="normal">1446</span>
<span class="normal">1447</span>
<span class="normal">1448</span>
<span class="normal">1449</span>
<span class="normal">1450</span>
<span class="normal">1451</span>
<span class="normal">1452</span>
<span class="normal">1453</span>
<span class="normal">1454</span>
<span class="normal">1455</span>
<span class="normal">1456</span>
<span class="normal">1457</span>
<span class="normal">1458</span>
<span class="normal">1459</span>
<span class="normal">1460</span>
<span class="normal">1461</span>
<span class="normal">1462</span>
<span class="normal">1463</span>
<span class="normal">1464</span>
<span class="normal">1465</span>
<span class="normal">1466</span>
<span class="normal">1467</span>
<span class="normal">1468</span>
<span class="normal">1469</span>
<span class="normal">1470</span>
<span class="normal">1471</span>
<span class="normal">1472</span>
<span class="normal">1473</span>
<span class="normal">1474</span>
<span class="normal">1475</span>
<span class="normal">1476</span>
<span class="normal">1477</span>
<span class="normal">1478</span>
<span class="normal">1479</span>
<span class="normal">1480</span>
<span class="normal">1481</span>
<span class="normal">1482</span>
<span class="normal">1483</span>
<span class="normal">1484</span>
<span class="normal">1485</span>
<span class="normal">1486</span>
<span class="normal">1487</span>
<span class="normal">1488</span>
<span class="normal">1489</span>
<span class="normal">1490</span>
<span class="normal">1491</span>
<span class="normal">1492</span>
<span class="normal">1493</span>
<span class="normal">1494</span>
<span class="normal">1495</span>
<span class="normal">1496</span>
<span class="normal">1497</span>
<span class="normal">1498</span>
<span class="normal">1499</span>
<span class="normal">1500</span>
<span class="normal">1501</span>
<span class="normal">1502</span>
<span class="normal">1503</span>
<span class="normal">1504</span>
<span class="normal">1505</span>
<span class="normal">1506</span>
<span class="normal">1507</span>
<span class="normal">1508</span>
<span class="normal">1509</span>
<span class="normal">1510</span>
<span class="normal">1511</span>
<span class="normal">1512</span>
<span class="normal">1513</span>
<span class="normal">1514</span>
<span class="normal">1515</span>
<span class="normal">1516</span>
<span class="normal">1517</span>
<span class="normal">1518</span>
<span class="normal">1519</span>
<span class="normal">1520</span>
<span class="normal">1521</span>
<span class="normal">1522</span>
<span class="normal">1523</span>
<span class="normal">1524</span>
<span class="normal">1525</span>
<span class="normal">1526</span>
<span class="normal">1527</span>
<span class="normal">1528</span>
<span class="normal">1529</span>
<span class="normal">1530</span>
<span class="normal">1531</span>
<span class="normal">1532</span>
<span class="normal">1533</span>
<span class="normal">1534</span>
<span class="normal">1535</span>
<span class="normal">1536</span>
<span class="normal">1537</span>
<span class="normal">1538</span>
<span class="normal">1539</span>
<span class="normal">1540</span>
<span class="normal">1541</span>
<span class="normal">1542</span>
<span class="normal">1543</span>
<span class="normal">1544</span>
<span class="normal">1545</span>
<span class="normal">1546</span>
<span class="normal">1547</span>
<span class="normal">1548</span>
<span class="normal">1549</span>
<span class="normal">1550</span>
<span class="normal">1551</span>
<span class="normal">1552</span>
<span class="normal">1553</span>
<span class="normal">1554</span>
<span class="normal">1555</span>
<span class="normal">1556</span>
<span class="normal">1557</span>
<span class="normal">1558</span>
<span class="normal">1559</span>
<span class="normal">1560</span>
<span class="normal">1561</span>
<span class="normal">1562</span>
<span class="normal">1563</span>
<span class="normal">1564</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">DeltaLoader</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    !!! note &quot;Summary&quot;</span>
<span class="sd">        A class to load and inspect Delta Lake tables from a specified root directory.</span>

<span class="sd">    ???+ abstract &quot;Details&quot;</span>
<span class="sd">        The `DeltaLoader` class provides methods to load Delta Lake tables from a specified root directory and inspect the contents of these tables. It uses the `dbutils` library if available to list folders, otherwise it falls back to using the `os` library.</span>

<span class="sd">    Params:</span>
<span class="sd">        root (str):</span>
<span class="sd">            The root directory where the Delta Lake tables are stored.</span>
<span class="sd">        spark (SparkSession):</span>
<span class="sd">            The Spark session to use for loading the Delta Lake tables.</span>
<span class="sd">        dbutils (optional):</span>
<span class="sd">            The `dbutils` library to use for listing folders. If not provided, the `os` library will be used.&lt;br&gt;</span>
<span class="sd">            Defaults to `None`.</span>

<span class="sd">    Methods:</span>
<span class="sd">        load(folder_name: str) -&gt; psDataFrame:</span>
<span class="sd">            Load a Delta Lake table from the specified folder.</span>

<span class="sd">        folders() -&gt; str_list:</span>
<span class="sd">            List the folders in the root directory.</span>

<span class="sd">        inspect() -&gt; psDataFrame:</span>
<span class="sd">            Inspect the Delta Lake tables in the root directory and return a DataFrame with information about each table.</span>

<span class="sd">    ???+ example &quot;Examples&quot;</span>

<span class="sd">        ```{.py .python linenums=&quot;1&quot; title=&quot;Set up&quot;}</span>
<span class="sd">        &gt;&gt;&gt; # Imports</span>
<span class="sd">        &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">        &gt;&gt;&gt; from toolbox_pyspark.delta import DeltaLoader</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Instantiate Spark</span>
<span class="sd">        &gt;&gt;&gt; spark = SparkSession.builder.getOrCreate()</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Create DeltaLoader instance</span>
<span class="sd">        &gt;&gt;&gt; delta_loader = DeltaLoader(root=&quot;/path/to/delta/tables&quot;, spark=spark)</span>
<span class="sd">        ```</span>

<span class="sd">        ```{.py .python linenums=&quot;1&quot; title=&quot;Example 1: Load a table&quot;}</span>
<span class="sd">        &gt;&gt;&gt; df = delta_loader.load(&quot;folder_name&quot;)</span>
<span class="sd">        &gt;&gt;&gt; df.show()</span>
<span class="sd">        ```</span>
<span class="sd">        &lt;div class=&quot;result&quot; markdown&gt;</span>
<span class="sd">        ```{.txt .text title=&quot;Terminal&quot;}</span>
<span class="sd">        +---+---+---+</span>
<span class="sd">        | a | b | c |</span>
<span class="sd">        +---+---+---+</span>
<span class="sd">        | 1 | 2 | 3 |</span>
<span class="sd">        | 4 | 5 | 6 |</span>
<span class="sd">        +---+---+---+</span>
<span class="sd">        ```</span>
<span class="sd">        !!! success &quot;Conclusion: Successfully loaded the table from the specified folder.&quot;</span>
<span class="sd">        &lt;/div&gt;</span>

<span class="sd">        ```{.py .python linenums=&quot;1&quot; title=&quot;Example 2: List folders&quot;}</span>
<span class="sd">        &gt;&gt;&gt; folders = delta_loader.folders</span>
<span class="sd">        &gt;&gt;&gt; print(folders)</span>
<span class="sd">        ```</span>
<span class="sd">        &lt;div class=&quot;result&quot; markdown&gt;</span>
<span class="sd">        ```{.txt .text title=&quot;Terminal&quot;}</span>
<span class="sd">        [&#39;folder1&#39;, &#39;folder2&#39;, &#39;folder3&#39;]</span>
<span class="sd">        ```</span>
<span class="sd">        !!! success &quot;Conclusion: Successfully listed the folders in the root directory.&quot;</span>
<span class="sd">        &lt;/div&gt;</span>

<span class="sd">        ```{.py .python linenums=&quot;1&quot; title=&quot;Example 3: Inspect tables&quot;}</span>
<span class="sd">        &gt;&gt;&gt; inspection_df = delta_loader.inspect()</span>
<span class="sd">        &gt;&gt;&gt; inspection_df.show()</span>
<span class="sd">        ```</span>
<span class="sd">        &lt;div class=&quot;result&quot; markdown&gt;</span>
<span class="sd">        ```{.txt .text title=&quot;Terminal&quot;}</span>
<span class="sd">        +---------+-------------+---------------------+-------+</span>
<span class="sd">        | Folder  | TimeElement | TimeStamp           | Count |</span>
<span class="sd">        +---------+-------------+---------------------+-------+</span>
<span class="sd">        | folder1 | EDITDATE    | 2023-01-01 00:00:00 |   100 |</span>
<span class="sd">        | folder2 | ADDDATE     | 2023-01-02 00:00:00 |   200 |</span>
<span class="sd">        | folder3 | None        | None                |   300 |</span>
<span class="sd">        +---------+-------------+---------------------+-------+</span>
<span class="sd">        ```</span>
<span class="sd">        !!! success &quot;Conclusion: Successfully inspected the Delta Lake tables.&quot;</span>
<span class="sd">        &lt;/div&gt;</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">root</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">spark</span><span class="p">:</span> <span class="n">SparkSession</span><span class="p">,</span> <span class="n">dbutils</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_root</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">root</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_spark_session</span><span class="p">:</span> <span class="n">SparkSession</span> <span class="o">=</span> <span class="n">spark</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_dbutils</span> <span class="o">=</span> <span class="n">dbutils</span>

    <span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">folder_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">psDataFrame</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        !!! note &quot;Summary&quot;</span>
<span class="sd">            Load a Delta Lake table from the specified folder.</span>

<span class="sd">        ???+ abstract &quot;Details&quot;</span>
<span class="sd">            This method loads a Delta Lake table from the specified folder within the root directory. It uses the `read_from_path` function to read the data in Delta format.</span>

<span class="sd">        Params:</span>
<span class="sd">            folder_name (str):</span>
<span class="sd">                The name of the folder from which to load the Delta Lake table.</span>

<span class="sd">        Returns:</span>
<span class="sd">            (psDataFrame):</span>
<span class="sd">                The loaded Delta Lake table as a PySpark DataFrame.</span>

<span class="sd">        ???+ example &quot;Examples&quot;</span>

<span class="sd">            ```{.py .python linenums=&quot;1&quot; title=&quot;Set up&quot;}</span>
<span class="sd">            &gt;&gt;&gt; # Imports</span>
<span class="sd">            &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">            &gt;&gt;&gt; from toolbox_pyspark.delta import DeltaLoader</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Instantiate Spark</span>
<span class="sd">            &gt;&gt;&gt; spark = SparkSession.builder.getOrCreate()</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Create DeltaLoader instance</span>
<span class="sd">            &gt;&gt;&gt; delta_loader = DeltaLoader(root=&quot;/path/to/delta/tables&quot;, spark=spark)</span>
<span class="sd">            ```</span>

<span class="sd">            ```{.py .python linenums=&quot;1&quot; title=&quot;Example 1: Load a table&quot;}</span>
<span class="sd">            &gt;&gt;&gt; df = delta_loader.load(&quot;folder_name&quot;)</span>
<span class="sd">            &gt;&gt;&gt; df.show()</span>
<span class="sd">            ```</span>
<span class="sd">            &lt;div class=&quot;result&quot; markdown&gt;</span>
<span class="sd">            ```{.txt .text title=&quot;Terminal&quot;}</span>
<span class="sd">            +---+---+---+</span>
<span class="sd">            | a | b | c |</span>
<span class="sd">            +---+---+---+</span>
<span class="sd">            | 1 | 2 | 3 |</span>
<span class="sd">            | 4 | 5 | 6 |</span>
<span class="sd">            +---+---+---+</span>
<span class="sd">            ```</span>
<span class="sd">            !!! success &quot;Conclusion: Successfully loaded the table from the specified folder.&quot;</span>
<span class="sd">            &lt;/div&gt;</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">read_from_path</span><span class="p">(</span>
            <span class="n">folder_name</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_root</span><span class="p">,</span>
            <span class="n">spark_session</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_spark_session</span><span class="p">,</span>
            <span class="n">data_format</span><span class="o">=</span><span class="s2">&quot;delta&quot;</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">folders</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">str_list</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        !!! note &quot;Summary&quot;</span>
<span class="sd">            List the folders in the root directory.</span>

<span class="sd">        ???+ abstract &quot;Details&quot;</span>
<span class="sd">            This property lists the folders in the root directory specified during the instantiation of the `DeltaLoader` class. It uses the `dbutils` library if available to list folders, otherwise it falls back to using the `os` library.</span>

<span class="sd">        Returns:</span>
<span class="sd">            (str_list):</span>
<span class="sd">                A list of folder names in the root directory.</span>

<span class="sd">        ???+ example &quot;Examples&quot;</span>

<span class="sd">            ```{.py .python linenums=&quot;1&quot; title=&quot;Set up&quot;}</span>
<span class="sd">            &gt;&gt;&gt; # Imports</span>
<span class="sd">            &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">            &gt;&gt;&gt; from toolbox_pyspark.delta import DeltaLoader</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Instantiate Spark</span>
<span class="sd">            &gt;&gt;&gt; spark = SparkSession.builder.getOrCreate()</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Create DeltaLoader instance</span>
<span class="sd">            &gt;&gt;&gt; delta_loader = DeltaLoader(root=&quot;/path/to/delta/tables&quot;, spark=spark)</span>
<span class="sd">            ```</span>

<span class="sd">            ```{.py .python linenums=&quot;1&quot; title=&quot;Example 1: List folders&quot;}</span>
<span class="sd">            &gt;&gt;&gt; folders = delta_loader.folders</span>
<span class="sd">            &gt;&gt;&gt; print(folders)</span>
<span class="sd">            ```</span>
<span class="sd">            &lt;div class=&quot;result&quot; markdown&gt;</span>
<span class="sd">            ```{.txt .text title=&quot;Terminal&quot;}</span>
<span class="sd">            [&#39;folder1&#39;, &#39;folder2&#39;, &#39;folder3&#39;]</span>
<span class="sd">            ```</span>
<span class="sd">            !!! success &quot;Conclusion: Successfully listed the folders in the root directory.&quot;</span>
<span class="sd">            &lt;/div&gt;</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dbutils</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">[</span>
                <span class="n">folder</span><span class="o">.</span><span class="n">name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;/&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">folder</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dbutils</span><span class="o">.</span><span class="n">fs</span><span class="o">.</span><span class="n">ls</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_root</span><span class="p">)</span>  <span class="c1"># type:ignore</span>
            <span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_root</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">inspect</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">psDataFrame</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        !!! note &quot;Summary&quot;</span>
<span class="sd">            Inspect the Delta Lake tables in the root directory and return a DataFrame with information about each table.</span>

<span class="sd">        ???+ abstract &quot;Details&quot;</span>
<span class="sd">            This method inspects the Delta Lake tables in the root directory specified during the instantiation of the `DeltaLoader` class. It loads each table, checks for specific columns (`EDITDATE` and `ADDDATE`), and collects information about each table, including the folder name, the time element, the latest timestamp, and the row count.</span>

<span class="sd">        Returns:</span>
<span class="sd">            (psDataFrame):</span>
<span class="sd">                A DataFrame with information about each Delta Lake table in the root directory.</span>

<span class="sd">        ???+ example &quot;Examples&quot;</span>

<span class="sd">            ```{.py .python linenums=&quot;1&quot; title=&quot;Set up&quot;}</span>
<span class="sd">            &gt;&gt;&gt; # Imports</span>
<span class="sd">            &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">            &gt;&gt;&gt; from toolbox_pyspark.delta import DeltaLoader</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Instantiate Spark</span>
<span class="sd">            &gt;&gt;&gt; spark = SparkSession.builder.getOrCreate()</span>
<span class="sd">            &gt;&gt;&gt;</span>
<span class="sd">            &gt;&gt;&gt; # Create DeltaLoader instance</span>
<span class="sd">            &gt;&gt;&gt; delta_loader = DeltaLoader(root=&quot;/path/to/delta/tables&quot;, spark=spark)</span>
<span class="sd">            ```</span>

<span class="sd">            ```{.py .python linenums=&quot;1&quot; title=&quot;Example 1: Inspect tables&quot;}</span>
<span class="sd">            &gt;&gt;&gt; inspection_df = delta_loader.inspect()</span>
<span class="sd">            &gt;&gt;&gt; inspection_df.show()</span>
<span class="sd">            ```</span>
<span class="sd">            &lt;div class=&quot;result&quot; markdown&gt;</span>
<span class="sd">            ```{.txt .text title=&quot;Terminal&quot;}</span>
<span class="sd">            +---------+-------------+---------------------+-------+</span>
<span class="sd">            | Folder  | TimeElement | TimeStamp           | Count |</span>
<span class="sd">            +---------+-------------+---------------------+-------+</span>
<span class="sd">            | folder1 | EDITDATE    | 2023-01-01 00:00:00 |   100 |</span>
<span class="sd">            | folder2 | ADDDATE     | 2023-01-02 00:00:00 |   200 |</span>
<span class="sd">            | folder3 | None        | None                |   300 |</span>
<span class="sd">            +---------+-------------+---------------------+-------+</span>
<span class="sd">            ```</span>
<span class="sd">            !!! success &quot;Conclusion: Successfully inspected the Delta Lake tables.&quot;</span>
<span class="sd">            &lt;/div&gt;</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">data</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">folder</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">folders</span><span class="p">:</span>
            <span class="n">df</span><span class="p">:</span> <span class="n">psDataFrame</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">folder</span><span class="p">)</span>
            <span class="n">cols</span><span class="p">:</span> <span class="n">str_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">col</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">]</span>
            <span class="k">if</span> <span class="s2">&quot;EDITDATE&quot;</span> <span class="ow">in</span> <span class="n">cols</span><span class="p">:</span>
                <span class="n">data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="p">(</span>
                        <span class="n">folder</span><span class="p">,</span>
                        <span class="s2">&quot;EDITDATE&quot;</span><span class="p">,</span>
                        <span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="s2">&quot;EDITDATE&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">first</span><span class="p">()[</span><span class="s2">&quot;max(EDITDATE)&quot;</span><span class="p">],</span>
                        <span class="n">df</span><span class="o">.</span><span class="n">count</span><span class="p">(),</span>
                    <span class="p">)</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="s2">&quot;ADDDATE&quot;</span> <span class="ow">in</span> <span class="n">cols</span><span class="p">:</span>
                <span class="n">data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="p">(</span>
                        <span class="n">folder</span><span class="p">,</span>
                        <span class="s2">&quot;ADDDATE&quot;</span><span class="p">,</span>
                        <span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="s2">&quot;ADDDATE&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">first</span><span class="p">()[</span><span class="s2">&quot;max(ADDDATE)&quot;</span><span class="p">],</span>
                        <span class="n">df</span><span class="o">.</span><span class="n">count</span><span class="p">(),</span>
                    <span class="p">)</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">data</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">folder</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">count</span><span class="p">()))</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_spark_session</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span>
            <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Folder&quot;</span><span class="p">,</span> <span class="s2">&quot;TimeElement&quot;</span><span class="p">,</span> <span class="s2">&quot;TimeStamp&quot;</span><span class="p">,</span> <span class="s2">&quot;Count&quot;</span><span class="p">])</span>
        <span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">







<div class="doc doc-object doc-function">


<h5 id="toolbox_pyspark.delta.DeltaLoader.__init__" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">__init__</span>


<a href="#toolbox_pyspark.delta.DeltaLoader.__init__" class="headerlink" title="Permanent link">ðŸ”—</a></h5>
<div class="doc-signature highlight"><pre><span></span><code><span class="fm">__init__</span><span class="p">(</span>
    <span class="nf">root</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">spark</span><span class="p">:</span> <span class="n">SparkSession</span><span class="p">,</span> <span class="n">dbutils</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span>
</code></pre></div>

    <div class="doc doc-contents ">

            <details class="quote">
              <summary>Source code in <code>src/toolbox_pyspark/delta.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1391</span>
<span class="normal">1392</span>
<span class="normal">1393</span>
<span class="normal">1394</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">root</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">spark</span><span class="p">:</span> <span class="n">SparkSession</span><span class="p">,</span> <span class="n">dbutils</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_root</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">root</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_spark_session</span><span class="p">:</span> <span class="n">SparkSession</span> <span class="o">=</span> <span class="n">spark</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_dbutils</span> <span class="o">=</span> <span class="n">dbutils</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>


















<div class="doc doc-object doc-function">


<h5 id="toolbox_pyspark.delta.DeltaLoader.load" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">load</span>


<a href="#toolbox_pyspark.delta.DeltaLoader.load" class="headerlink" title="Permanent link">ðŸ”—</a></h5>
<div class="doc-signature highlight"><pre><span></span><code><span class="nf">load</span><span class="p">(</span><span class="n">folder_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">psDataFrame</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <div class="admonition note">
<p class="admonition-title">Summary</p>
<p>Load a Delta Lake table from the specified folder.</p>
</div>
<details class="abstract" open="open">
<summary>Details</summary>
<p>This method loads a Delta Lake table from the specified folder within the root directory. It uses the <code>read_from_path</code> function to read the data in Delta format.</p>
</details>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>folder_name</code>
            </td>
            <td>
                  <code>str</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The name of the folder from which to load the Delta Lake table.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="pyspark.sql.DataFrame">DataFrame</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The loaded Delta Lake table as a PySpark DataFrame.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>
        <details class="example" open="open">
<summary>Examples</summary>
<div class="python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Set up</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span>
<span class="normal">6</span>
<span class="normal">7</span>
<span class="normal">8</span>
<span class="normal">9</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="c1"># Imports</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">toolbox_pyspark.delta</span> <span class="kn">import</span> <span class="n">DeltaLoader</span>
<span class="o">&gt;&gt;&gt;</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># Instantiate Spark</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="o">.</span><span class="n">builder</span><span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># Create DeltaLoader instance</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">delta_loader</span> <span class="o">=</span> <span class="n">DeltaLoader</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s2">&quot;/path/to/delta/tables&quot;</span><span class="p">,</span> <span class="n">spark</span><span class="o">=</span><span class="n">spark</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<p><div class="python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Example 1: Load a table</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">df</span> <span class="o">=</span> <span class="n">delta_loader</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;folder_name&quot;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">df</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
<div class="result" markdown>
<div class="text highlight"><span class="filename">Terminal</span><pre><span></span><code>+---+---+---+
| a | b | c |
+---+---+---+
| 1 | 2 | 3 |
| 4 | 5 | 6 |
+---+---+---+
</code></pre></div></p>
<div class="admonition success">
<p class="admonition-title">Conclusion: Successfully loaded the table from the specified folder.</p>
</div>
</div>
</details>

            <details class="quote">
              <summary>Source code in <code>src/toolbox_pyspark/delta.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1396</span>
<span class="normal">1397</span>
<span class="normal">1398</span>
<span class="normal">1399</span>
<span class="normal">1400</span>
<span class="normal">1401</span>
<span class="normal">1402</span>
<span class="normal">1403</span>
<span class="normal">1404</span>
<span class="normal">1405</span>
<span class="normal">1406</span>
<span class="normal">1407</span>
<span class="normal">1408</span>
<span class="normal">1409</span>
<span class="normal">1410</span>
<span class="normal">1411</span>
<span class="normal">1412</span>
<span class="normal">1413</span>
<span class="normal">1414</span>
<span class="normal">1415</span>
<span class="normal">1416</span>
<span class="normal">1417</span>
<span class="normal">1418</span>
<span class="normal">1419</span>
<span class="normal">1420</span>
<span class="normal">1421</span>
<span class="normal">1422</span>
<span class="normal">1423</span>
<span class="normal">1424</span>
<span class="normal">1425</span>
<span class="normal">1426</span>
<span class="normal">1427</span>
<span class="normal">1428</span>
<span class="normal">1429</span>
<span class="normal">1430</span>
<span class="normal">1431</span>
<span class="normal">1432</span>
<span class="normal">1433</span>
<span class="normal">1434</span>
<span class="normal">1435</span>
<span class="normal">1436</span>
<span class="normal">1437</span>
<span class="normal">1438</span>
<span class="normal">1439</span>
<span class="normal">1440</span>
<span class="normal">1441</span>
<span class="normal">1442</span>
<span class="normal">1443</span>
<span class="normal">1444</span>
<span class="normal">1445</span>
<span class="normal">1446</span>
<span class="normal">1447</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">load</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">folder_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">psDataFrame</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    !!! note &quot;Summary&quot;</span>
<span class="sd">        Load a Delta Lake table from the specified folder.</span>

<span class="sd">    ???+ abstract &quot;Details&quot;</span>
<span class="sd">        This method loads a Delta Lake table from the specified folder within the root directory. It uses the `read_from_path` function to read the data in Delta format.</span>

<span class="sd">    Params:</span>
<span class="sd">        folder_name (str):</span>
<span class="sd">            The name of the folder from which to load the Delta Lake table.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (psDataFrame):</span>
<span class="sd">            The loaded Delta Lake table as a PySpark DataFrame.</span>

<span class="sd">    ???+ example &quot;Examples&quot;</span>

<span class="sd">        ```{.py .python linenums=&quot;1&quot; title=&quot;Set up&quot;}</span>
<span class="sd">        &gt;&gt;&gt; # Imports</span>
<span class="sd">        &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">        &gt;&gt;&gt; from toolbox_pyspark.delta import DeltaLoader</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Instantiate Spark</span>
<span class="sd">        &gt;&gt;&gt; spark = SparkSession.builder.getOrCreate()</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Create DeltaLoader instance</span>
<span class="sd">        &gt;&gt;&gt; delta_loader = DeltaLoader(root=&quot;/path/to/delta/tables&quot;, spark=spark)</span>
<span class="sd">        ```</span>

<span class="sd">        ```{.py .python linenums=&quot;1&quot; title=&quot;Example 1: Load a table&quot;}</span>
<span class="sd">        &gt;&gt;&gt; df = delta_loader.load(&quot;folder_name&quot;)</span>
<span class="sd">        &gt;&gt;&gt; df.show()</span>
<span class="sd">        ```</span>
<span class="sd">        &lt;div class=&quot;result&quot; markdown&gt;</span>
<span class="sd">        ```{.txt .text title=&quot;Terminal&quot;}</span>
<span class="sd">        +---+---+---+</span>
<span class="sd">        | a | b | c |</span>
<span class="sd">        +---+---+---+</span>
<span class="sd">        | 1 | 2 | 3 |</span>
<span class="sd">        | 4 | 5 | 6 |</span>
<span class="sd">        +---+---+---+</span>
<span class="sd">        ```</span>
<span class="sd">        !!! success &quot;Conclusion: Successfully loaded the table from the specified folder.&quot;</span>
<span class="sd">        &lt;/div&gt;</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">read_from_path</span><span class="p">(</span>
        <span class="n">folder_name</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_root</span><span class="p">,</span>
        <span class="n">spark_session</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_spark_session</span><span class="p">,</span>
        <span class="n">data_format</span><span class="o">=</span><span class="s2">&quot;delta&quot;</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>






<div class="doc doc-object doc-attribute">



<h5 id="toolbox_pyspark.delta.DeltaLoader.folders" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">folders</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#toolbox_pyspark.delta.DeltaLoader.folders" class="headerlink" title="Permanent link">ðŸ”—</a></h5>
<div class="doc-signature highlight"><pre><span></span><code><span class="n">folders</span><span class="p">:</span> <span class="n">str_list</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <div class="admonition note">
<p class="admonition-title">Summary</p>
<p>List the folders in the root directory.</p>
</div>
<details class="abstract" open="open">
<summary>Details</summary>
<p>This property lists the folders in the root directory specified during the instantiation of the <code>DeltaLoader</code> class. It uses the <code>dbutils</code> library if available to list folders, otherwise it falls back to using the <code>os</code> library.</p>
</details>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="toolbox_python.collection_types.str_list">str_list</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A list of folder names in the root directory.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>
        <details class="example" open="open">
<summary>Examples</summary>
<div class="python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Set up</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span>
<span class="normal">6</span>
<span class="normal">7</span>
<span class="normal">8</span>
<span class="normal">9</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="c1"># Imports</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">toolbox_pyspark.delta</span> <span class="kn">import</span> <span class="n">DeltaLoader</span>
<span class="o">&gt;&gt;&gt;</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># Instantiate Spark</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="o">.</span><span class="n">builder</span><span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># Create DeltaLoader instance</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">delta_loader</span> <span class="o">=</span> <span class="n">DeltaLoader</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s2">&quot;/path/to/delta/tables&quot;</span><span class="p">,</span> <span class="n">spark</span><span class="o">=</span><span class="n">spark</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<p><div class="python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Example 1: List folders</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">folders</span> <span class="o">=</span> <span class="n">delta_loader</span><span class="o">.</span><span class="n">folders</span>
<span class="o">&gt;&gt;&gt;</span> <span class="nb">print</span><span class="p">(</span><span class="n">folders</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<div class="result" markdown>
<div class="text highlight"><span class="filename">Terminal</span><pre><span></span><code>[&#39;folder1&#39;, &#39;folder2&#39;, &#39;folder3&#39;]
</code></pre></div></p>
<div class="admonition success">
<p class="admonition-title">Conclusion: Successfully listed the folders in the root directory.</p>
</div>
</div>
</details>
    </div>

</div>






<div class="doc doc-object doc-function">


<h5 id="toolbox_pyspark.delta.DeltaLoader.inspect" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">inspect</span>


<a href="#toolbox_pyspark.delta.DeltaLoader.inspect" class="headerlink" title="Permanent link">ðŸ”—</a></h5>
<div class="doc-signature highlight"><pre><span></span><code><span class="nf">inspect</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">psDataFrame</span>
</code></pre></div>

    <div class="doc doc-contents ">

        <div class="admonition note">
<p class="admonition-title">Summary</p>
<p>Inspect the Delta Lake tables in the root directory and return a DataFrame with information about each table.</p>
</div>
<details class="abstract" open="open">
<summary>Details</summary>
<p>This method inspects the Delta Lake tables in the root directory specified during the instantiation of the <code>DeltaLoader</code> class. It loads each table, checks for specific columns (<code>EDITDATE</code> and <code>ADDDATE</code>), and collects information about each table, including the folder name, the time element, the latest timestamp, and the row count.</p>
</details>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="pyspark.sql.DataFrame">DataFrame</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A DataFrame with information about each Delta Lake table in the root directory.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>
        <details class="example" open="open">
<summary>Examples</summary>
<div class="python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Set up</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span>
<span class="normal">6</span>
<span class="normal">7</span>
<span class="normal">8</span>
<span class="normal">9</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="c1"># Imports</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">toolbox_pyspark.delta</span> <span class="kn">import</span> <span class="n">DeltaLoader</span>
<span class="o">&gt;&gt;&gt;</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># Instantiate Spark</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">spark</span> <span class="o">=</span> <span class="n">SparkSession</span><span class="o">.</span><span class="n">builder</span><span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span>
<span class="o">&gt;&gt;&gt;</span> <span class="c1"># Create DeltaLoader instance</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">delta_loader</span> <span class="o">=</span> <span class="n">DeltaLoader</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s2">&quot;/path/to/delta/tables&quot;</span><span class="p">,</span> <span class="n">spark</span><span class="o">=</span><span class="n">spark</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<p><div class="python highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Example 1: Inspect tables</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="n">inspection_df</span> <span class="o">=</span> <span class="n">delta_loader</span><span class="o">.</span><span class="n">inspect</span><span class="p">()</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">inspection_df</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
<div class="result" markdown>
<div class="text highlight"><span class="filename">Terminal</span><pre><span></span><code>+---------+-------------+---------------------+-------+
| Folder  | TimeElement | TimeStamp           | Count |
+---------+-------------+---------------------+-------+
| folder1 | EDITDATE    | 2023-01-01 00:00:00 |   100 |
| folder2 | ADDDATE     | 2023-01-02 00:00:00 |   200 |
| folder3 | None        | None                |   300 |
+---------+-------------+---------------------+-------+
</code></pre></div></p>
<div class="admonition success">
<p class="admonition-title">Conclusion: Successfully inspected the Delta Lake tables.</p>
</div>
</div>
</details>

            <details class="quote">
              <summary>Source code in <code>src/toolbox_pyspark/delta.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1495</span>
<span class="normal">1496</span>
<span class="normal">1497</span>
<span class="normal">1498</span>
<span class="normal">1499</span>
<span class="normal">1500</span>
<span class="normal">1501</span>
<span class="normal">1502</span>
<span class="normal">1503</span>
<span class="normal">1504</span>
<span class="normal">1505</span>
<span class="normal">1506</span>
<span class="normal">1507</span>
<span class="normal">1508</span>
<span class="normal">1509</span>
<span class="normal">1510</span>
<span class="normal">1511</span>
<span class="normal">1512</span>
<span class="normal">1513</span>
<span class="normal">1514</span>
<span class="normal">1515</span>
<span class="normal">1516</span>
<span class="normal">1517</span>
<span class="normal">1518</span>
<span class="normal">1519</span>
<span class="normal">1520</span>
<span class="normal">1521</span>
<span class="normal">1522</span>
<span class="normal">1523</span>
<span class="normal">1524</span>
<span class="normal">1525</span>
<span class="normal">1526</span>
<span class="normal">1527</span>
<span class="normal">1528</span>
<span class="normal">1529</span>
<span class="normal">1530</span>
<span class="normal">1531</span>
<span class="normal">1532</span>
<span class="normal">1533</span>
<span class="normal">1534</span>
<span class="normal">1535</span>
<span class="normal">1536</span>
<span class="normal">1537</span>
<span class="normal">1538</span>
<span class="normal">1539</span>
<span class="normal">1540</span>
<span class="normal">1541</span>
<span class="normal">1542</span>
<span class="normal">1543</span>
<span class="normal">1544</span>
<span class="normal">1545</span>
<span class="normal">1546</span>
<span class="normal">1547</span>
<span class="normal">1548</span>
<span class="normal">1549</span>
<span class="normal">1550</span>
<span class="normal">1551</span>
<span class="normal">1552</span>
<span class="normal">1553</span>
<span class="normal">1554</span>
<span class="normal">1555</span>
<span class="normal">1556</span>
<span class="normal">1557</span>
<span class="normal">1558</span>
<span class="normal">1559</span>
<span class="normal">1560</span>
<span class="normal">1561</span>
<span class="normal">1562</span>
<span class="normal">1563</span>
<span class="normal">1564</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">inspect</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">psDataFrame</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    !!! note &quot;Summary&quot;</span>
<span class="sd">        Inspect the Delta Lake tables in the root directory and return a DataFrame with information about each table.</span>

<span class="sd">    ???+ abstract &quot;Details&quot;</span>
<span class="sd">        This method inspects the Delta Lake tables in the root directory specified during the instantiation of the `DeltaLoader` class. It loads each table, checks for specific columns (`EDITDATE` and `ADDDATE`), and collects information about each table, including the folder name, the time element, the latest timestamp, and the row count.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (psDataFrame):</span>
<span class="sd">            A DataFrame with information about each Delta Lake table in the root directory.</span>

<span class="sd">    ???+ example &quot;Examples&quot;</span>

<span class="sd">        ```{.py .python linenums=&quot;1&quot; title=&quot;Set up&quot;}</span>
<span class="sd">        &gt;&gt;&gt; # Imports</span>
<span class="sd">        &gt;&gt;&gt; from pyspark.sql import SparkSession</span>
<span class="sd">        &gt;&gt;&gt; from toolbox_pyspark.delta import DeltaLoader</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Instantiate Spark</span>
<span class="sd">        &gt;&gt;&gt; spark = SparkSession.builder.getOrCreate()</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Create DeltaLoader instance</span>
<span class="sd">        &gt;&gt;&gt; delta_loader = DeltaLoader(root=&quot;/path/to/delta/tables&quot;, spark=spark)</span>
<span class="sd">        ```</span>

<span class="sd">        ```{.py .python linenums=&quot;1&quot; title=&quot;Example 1: Inspect tables&quot;}</span>
<span class="sd">        &gt;&gt;&gt; inspection_df = delta_loader.inspect()</span>
<span class="sd">        &gt;&gt;&gt; inspection_df.show()</span>
<span class="sd">        ```</span>
<span class="sd">        &lt;div class=&quot;result&quot; markdown&gt;</span>
<span class="sd">        ```{.txt .text title=&quot;Terminal&quot;}</span>
<span class="sd">        +---------+-------------+---------------------+-------+</span>
<span class="sd">        | Folder  | TimeElement | TimeStamp           | Count |</span>
<span class="sd">        +---------+-------------+---------------------+-------+</span>
<span class="sd">        | folder1 | EDITDATE    | 2023-01-01 00:00:00 |   100 |</span>
<span class="sd">        | folder2 | ADDDATE     | 2023-01-02 00:00:00 |   200 |</span>
<span class="sd">        | folder3 | None        | None                |   300 |</span>
<span class="sd">        +---------+-------------+---------------------+-------+</span>
<span class="sd">        ```</span>
<span class="sd">        !!! success &quot;Conclusion: Successfully inspected the Delta Lake tables.&quot;</span>
<span class="sd">        &lt;/div&gt;</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">data</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">folder</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">folders</span><span class="p">:</span>
        <span class="n">df</span><span class="p">:</span> <span class="n">psDataFrame</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">folder</span><span class="p">)</span>
        <span class="n">cols</span><span class="p">:</span> <span class="n">str_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">col</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">]</span>
        <span class="k">if</span> <span class="s2">&quot;EDITDATE&quot;</span> <span class="ow">in</span> <span class="n">cols</span><span class="p">:</span>
            <span class="n">data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="p">(</span>
                    <span class="n">folder</span><span class="p">,</span>
                    <span class="s2">&quot;EDITDATE&quot;</span><span class="p">,</span>
                    <span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="s2">&quot;EDITDATE&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">first</span><span class="p">()[</span><span class="s2">&quot;max(EDITDATE)&quot;</span><span class="p">],</span>
                    <span class="n">df</span><span class="o">.</span><span class="n">count</span><span class="p">(),</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="s2">&quot;ADDDATE&quot;</span> <span class="ow">in</span> <span class="n">cols</span><span class="p">:</span>
            <span class="n">data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="p">(</span>
                    <span class="n">folder</span><span class="p">,</span>
                    <span class="s2">&quot;ADDDATE&quot;</span><span class="p">,</span>
                    <span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="s2">&quot;ADDDATE&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">first</span><span class="p">()[</span><span class="s2">&quot;max(ADDDATE)&quot;</span><span class="p">],</span>
                    <span class="n">df</span><span class="o">.</span><span class="n">count</span><span class="p">(),</span>
                <span class="p">)</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">data</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">folder</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">count</span><span class="p">()))</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_spark_session</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span>
        <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Folder&quot;</span><span class="p">,</span> <span class="s2">&quot;TimeElement&quot;</span><span class="p">,</span> <span class="s2">&quot;TimeStamp&quot;</span><span class="p">,</span> <span class="s2">&quot;Count&quot;</span><span class="p">])</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>




  </div>

    </div>

</div>




  </div>

    </div>

</div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.tabs", "navigation.tabs.sticky", "navigation.sections", "navigation.expand", "navigation.indexes", "navigation.top", "navigation.instant", "search.highlight", "search.suggest", "toc.follow", "content.action.edit", "content.action.view", "content.code.annotate"], "search": "../../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"default": "latest", "provider": "mike"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.88dd0f4e.min.js"></script>
      
    
  </body>
</html>